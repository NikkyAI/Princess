import lexer
import vector

export type NodeKind = enum {
    ERROR
    PROGRAM
    INTEGER
    CHAR
    STRING
    FLOAT
    IDENTIFIER
    ADD
    SUB
    MUL
    DIV
    MOD
    BAND
    BOR
    BXOR
    SHL
    SHR
    PADD
    PSUB
    VARDECL
    IDDECL
    IDASSIGN
    FUNCTION_T
    WORD_T
    PTR_T
    ARRAY_T
}

export type ShareMarker = enum {
    NONE = 0
    EXPORT = 1
    IMPORT = 2
    BOTH = 3
}

export type VarDecl = enum {
    VAR
    LET
    CONST
}

export type Node

export type NodeTFunction = struct {
    args: *vector::Vector
    ret: *vector::Vector
}

export type NodeIdDecl = struct {
    value: *Node
    tpe: *Node
}

export type NodeVarDecl = struct {
    share: ShareMarker
    kw: VarDecl
    left: *vector::Vector
    right: *vector::Vector
}

export type NodeBinaryOp = struct {
    left: *Node
    right: *Node
}

export type NodeUnaryOp = struct {
    right: *Node
}

export type NodeValue = struct #union {
    bin_op: NodeBinaryOp
    un_op: NodeUnaryOp
    var_decl: NodeVarDecl
    id_decl: NodeIdDecl
    t_func: NodeTFunction

    body: *vector::Vector
    expr: *Node
    i: uint64
    str: string
    f: double
}

export type Node = struct {
    kind: NodeKind

    line: int
    column: int

    value: NodeValue
}

type ParseState = struct {
    lines: [string]
    tokens: **lexer::TokenList
}

def make_bin_op(token: lexer::Token, kind: NodeKind, left: *Node, right: *Node) -> *Node {
    var node = allocate(Node)
    (@node).line = token.line
    (@node).column = token.column
    (@node).kind = kind
    (@node).value.bin_op = {
        left, right
    } !NodeBinaryOp

    return node
}

// TODO: Make this function variadic
def errort(token: lexer::Token, state: *ParseState, msg: string) {
    let line = token.line
    let column = token.column
    error("\n")
    error(line, ":", column, "\n")
    error((@state).lines[line], "\n")
    for var i in 0:column:1 {
        error(" ")
    }
    error("^\n")
    error(msg)
}

def skip_whitespace(state: *ParseState) {
    var list = (@state).tokens
    var tt = (@@list).value.tpe
    while tt == lexer::TokenType::WHITESPACE or 
        tt == lexer::TokenType::COMMENT or
        tt == lexer::TokenType::ERROR {

        if tt == lexer::TokenType::ERROR {
            let token = (@@list).value
            errort(token, state, token.value.str)
        }

        @list = (@@list).next
        tt = (@@list).value.tpe
    }
}

def pop(state: *ParseState) -> lexer::Token {
    skip_whitespace(state)
    let list = (@state).tokens
    let token = (@@list).value
    @list = (@@list).next
    return token
}

def peek(state: *ParseState) -> lexer::Token {
    skip_whitespace(state)
    let list = (@state).tokens
    return (@@list).value
}

def unget_token(state: *ParseState, token: lexer::Token) {
    let list = (@state).tokens
    let prev = @list
    @list = allocate(lexer::TokenList)
    (@@list).value = token
    (@@list).next = prev
}

def expect(state: *ParseState, tpe: lexer::TokenType, msg: string) -> lexer::Token {
    let token = pop(state)
    if token.tpe != tpe {
        errort(token, state, msg)
    }
    return token
}

def skip_newline(state: *ParseState) {
    loop {
        let token = peek(state)
        if token.tpe == lexer::TokenType::NEW_LINE {
            pop(state)
            continue
        }
        break
    }
}

def next_token(state: *ParseState, tpe: lexer::TokenType) -> bool {
    let token = peek(state)
    if token.tpe == tpe {
        pop(state)
        return true
    }
    return false
}

def expect_identifier(parse_state: *ParseState) -> *Node {
    // TODO Handle identifiers with double colons
    let token = pop(parse_state)
    if token.tpe != lexer::TokenType::IDENTIFIER {
        errort(token, parse_state, "Expected identifier\n")
        return null
    }

    var node = allocate(Node)
    (@node).kind = NodeKind::IDENTIFIER
    (@node).value.str = token.value.str
    (@node).line = token.line
    (@node).column = token.column

    return node
}

def parse_type(parse_state: *ParseState) -> *Node
def expect_type(parse_state: *ParseState) -> *Node

def parse_type2(parse_state: *ParseState) -> *Node {
    let tok = pop(parse_state)

    if tok.tpe == lexer::TokenType::O_PAREN {
        var node = expect_type(parse_state)
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
        return node
    } else if tok.tpe == lexer::TokenType::K_TYPE {
        var node = expect_type(parse_state)
        return node
    } else if tok.tpe == lexer::TokenType::K_WORD {
        expect(parse_state, lexer::TokenType::O_PAREN, "Expected '('\n")
        var n = expect(parse_state, lexer::TokenType::INTEGER, "Expected integer\n")
        if n.tpe != lexer::TokenType::INTEGER {
            return null
        }
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
        var node = allocate(Node)
        (@node).kind = NodeKind::WORD_T
        (@node).line = tok.line
        (@node).column = tok.column
        (@node).value.i = n.value.i

        return node
    } else if tok.tpe == lexer::TokenType::O_SQUARE {
        // TODO
    } else if tok.tpe == lexer::TokenType::OP_MUL {
        // TODO  
    } else if tok.tpe == lexer::TokenType::DOUBLE_COLON or
        tok.tpe == lexer::TokenType::IDENTIFIER {
        unget_token(parse_state, tok)
        var node = expect_identifier(parse_state)
        return node
    } else {
        unget_token(parse_state, tok)
        return null
    }
}

def parse_type_list(parse_state: *ParseState, sw: bool) -> *vector::Vector {
    var token = peek(parse_state)
    var vec = vector::make()
    if token.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::C_PAREN {
            pop(parse_state)
            return vec
        }
        loop {
            let node = parse_type(parse_state)
            vector::push(vec, node)
            token = peek(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                continue
            }
            break
        }
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
    } else {
        var node: *Node = null
        if sw {
            node = parse_type(parse_state)
        } else {
            node = parse_type2(parse_state)
        }

        if node {
            vector::push(vec, node)
        }
    }
    return vec
}

def parse_type(parse_state: *ParseState) -> *Node {
    let args = parse_type_list(parse_state, false)
    var token = peek(parse_state)
    if token.tpe == lexer::TokenType::ARROW {
        pop(parse_state)
        let ret = parse_type_list(parse_state, true)
        var node = allocate(Node)
        (@node).kind = NodeKind::FUNCTION_T
        (@node).line = token.line
        (@node).column = token.column
        (@node).value.t_func = {
            args = args,
            ret = ret
        } !NodeTFunction
        return node
    } else if vector::length(args) > 1 {
        errort(token, parse_state, "Expected single type, got multiple\n")
        return null
    } else if vector::length(args) == 1 {
        return vector::get(args, 0)
    } else {
        return null
    }
}

def expect_type(parse_state: *ParseState) -> *Node {
    let token = peek(parse_state)
    let node = parse_type(parse_state)
    if not node {
       errort(token, parse_state, "Expected type\n") 
    }
    return node
}

def expect_expression(parse_state: *ParseState) -> *Node

def parse_term(parse_state: *ParseState) -> *Node {
    let token = pop(parse_state)
    var node = allocate(Node)
    
    if token.tpe == lexer::TokenType::O_PAREN {
        free(node)
        node = expect_expression(parse_state)
        expect(parse_state, lexer::TokenType::C_PAREN, "Expecting ')'")
        return node
    } else if token.tpe == lexer::TokenType::K_TYPE {
        free(node)
        return expect_type(parse_state)
    } else if token.tpe == lexer::TokenType::INTEGER {
        (@node).kind = NodeKind::INTEGER
        (@node).value.i = token.value.i
    } else if token.tpe == lexer::TokenType::FLOAT {
        (@node).kind = NodeKind::FLOAT
        (@node).value.f = token.value.f
    } else if token.tpe == lexer::TokenType::IDENTIFIER or
        token.tpe == lexer::TokenType::DOUBLE_COLON {
        free(node)
        unget_token(parse_state, token)
        return expect_identifier(parse_state)
    } else if token.tpe == lexer::TokenType::STRING {
        (@node).kind = NodeKind::IDENTIFIER
        (@node).value.str = token.value.str
    } else if token.tpe == lexer::TokenType::CHAR {
        (@node).kind = NodeKind::CHAR
        (@node).value.i = token.value.ch
    } else {
        free(node)
        errort(token, parse_state, "Expected literal or identifier\n")
        return null
    }
    (@node).line = token.line
    (@node).column = token.column
    return node
}

def parse_bin_expression(parse_state: *ParseState) -> *Node {
    var node = parse_term(parse_state)
    var token = peek(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_BAND) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::BAND, node, parse_term(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BOR) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::BOR, node, parse_term(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BXOR) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::BXOR, node, parse_term(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHL) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::SHL, node, parse_term(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHR) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::SHR, node, parse_term(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_mul_expression(parse_state: *ParseState) -> *Node {
    var node = parse_bin_expression(parse_state)
    var token = peek(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_MUL) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::MUL, node, parse_bin_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DIV) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::DIV, node, parse_bin_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_MOD) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::MOD, node, parse_bin_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_add_expresson(parse_state: *ParseState) -> *Node {
    var node = parse_mul_expression(parse_state)
    var token = peek(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_ADD) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::ADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SUB) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::SUB, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_INC) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::PADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DEC) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::PSUB, node, parse_mul_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def expect_expression(parse_state: *ParseState) -> *Node {
    let node = parse_add_expresson(parse_state)
    if not node {
        let token = peek(parse_state)
        errort(token, parse_state, "Expected expression\n")
    }
    return node
}

def parse_def(parse_state: *ParseState, share: ShareMarker) -> *Node {

}

def parse_vardecl(parse_state: *ParseState, share: ShareMarker, vardecl: VarDecl) -> *Node {
    var tok = pop(parse_state)
    let line = tok.line
    let column = tok.column

    if not (tok.tpe == lexer::TokenType::K_VAR or 
        tok.tpe == lexer::TokenType::K_CONST or 
        tok.tpe == lexer::TokenType::K_LET) {

        return null
    }
    skip_newline(parse_state)

    var vec_left = vector::make()
    loop {
        tok = pop(parse_state)
        if tok.tpe == lexer::TokenType::O_PAREN {
            // Assignment
            let expr = expect_expression(parse_state)
            expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
            var node = allocate(Node)
            (@node).kind = NodeKind::IDASSIGN
            (@node).line = tok.line
            (@node).column = tok.column
            (@node).value.expr = expr
            vector::push(vec_left, node)
        } else {
            // Id decl
            unget_token(parse_state, tok)
            var ident = expect_identifier(parse_state)

            tok = peek(parse_state)
            var tpe: *Node = null
            if tok.tpe == lexer::TokenType::COLON {
                // Type
                pop(parse_state)
                tpe = expect_type(parse_state)
            }
            var node = allocate(Node)
            (@node).kind = NodeKind::IDDECL
            (@node).line = tok.line
            (@node).column = tok.column
            (@node).value.id_decl = {
                value = ident,
                tpe = tpe
            } !NodeIdDecl
            vector::push(vec_left, node)
        }
        tok = pop(parse_state)
        if tok.tpe == lexer::TokenType::COMMA {
            skip_newline(parse_state)
            continue
        } else if tok.tpe == lexer::TokenType::OP_ASSIGN or
            tok.tpe == lexer::TokenType::NEW_LINE or
            tok.tpe == lexer::TokenType::EOF {
            break
        } else {
            errort(tok, parse_state, "Expected identifier, (expression) or '='\n")
            return null
        }
    }

    skip_newline(parse_state)

    var vec_right = vector::make()
    if tok.tpe == lexer::TokenType::OP_ASSIGN {
        loop {
            var expr = expect_expression(parse_state)
            vector::push(vec_right, expr)
            
            tok = pop(parse_state)
            if tok.tpe == lexer::TokenType::COMMA {
                skip_newline(parse_state)
                continue
            } else if tok.tpe == lexer::TokenType::NEW_LINE or
                tok.tpe == lexer::TokenType::EOF {
                unget_token(parse_state, tok)
                break
            }
        }
        //if vector::length(vec_left) != vector::length(vec_right) {
        //    errort(tok, parse_state, "Unbalanced assignment\n")
        //}
    } else if vardecl == VarDecl::LET or
        vardecl == VarDecl::CONST {
        errort(tok, parse_state, "Expected '='\n")
        return null
    }

    var node = allocate(Node)
    (@node).kind = NodeKind::VARDECL
    (@node).line = line
    (@node).column = column
    (@node).value.var_decl = {
        share = share,
        kw = vardecl,
        left = vec_left,
        right = vec_right
    } !NodeVarDecl

    return node
}

def parse_typedecl(parse_state: *ParseState, share: ShareMarker) -> *Node {
    return null
}

def parse_if_stmt(parse_state: *ParseState) -> *Node {
    return null
}

def parse_import_stmt(parse_state: *ParseState) -> *Node {
    return null
}

def parse_t_term(parse_state: *ParseState) {
    let token = peek(parse_state)
    if token.tpe == lexer::TokenType::SEMICOLON or token.tpe == lexer::TokenType::NEW_LINE {
        pop(parse_state)
    } else if token.tpe != lexer::TokenType::EOF and token.tpe != lexer::TokenType::C_BRACE {
        pop(parse_state)
        errort(token, parse_state, "Missing statement separator\n")
    }
}

def parse_statement2(parse_state: *ParseState, share: ShareMarker) -> *Node {
    let lh = peek(parse_state)
    var node: *Node = null
    if lh.tpe == lexer::TokenType::K_VAR {
        node = parse_vardecl(parse_state, share, VarDecl::VAR)
    } else if lh.tpe == lexer::TokenType::K_LET {
        node = parse_vardecl(parse_state, share, VarDecl::LET)
    } else if lh.tpe == lexer::TokenType::K_CONST {
        node = parse_vardecl(parse_state, share, VarDecl::CONST)
    } else if lh.tpe == lexer::TokenType::K_TYPE {
        node = parse_typedecl(parse_state, share)
    } else if lh.tpe == lexer::TokenType::K_DEF {
        node = parse_def(parse_state, share)
    }
    return node
}

def parse_statement(parse_state: *ParseState) -> *Node {
    let lh = peek(parse_state)
    var node: *Node = null
    if lh.tpe == lexer::TokenType::K_IMPORT {
        let share = ShareMarker::IMPORT
        let tok = pop(parse_state)
        node = parse_statement2(parse_state, share)
        if not node {
            unget_token(parse_state, tok)
            node = parse_import_stmt(parse_state)
        }
    } else if lh.tpe == lexer::TokenType::K_EXPORT {
        var share = ShareMarker::EXPORT
        pop(parse_state)
        let lh = peek(parse_state)
        if lh.tpe == lexer::TokenType::K_IMPORT {
            share = ShareMarker::BOTH
            pop(parse_state)
        }
        node = parse_statement2(parse_state, share)
        if not node {
            errort(peek(parse_state), parse_state, "Expected def, type, var, let, const\n")
            return null
        }
    } else if lh.tpe == lexer::TokenType::K_IF {
        node = parse_if_stmt(parse_state)
    } else {
        node = parse_statement2(parse_state, ShareMarker::NONE)
        if not node {
            node = expect_expression(parse_state)
        }
    }
    parse_t_term(parse_state)
    return node
}

export def parse(list: *lexer::TokenList, lines: [string]) -> *Node {
    var parse_state: ParseState
    parse_state.lines = lines
    parse_state.tokens = *list
    
    var vec = vector::make()

    while list != null and peek(*parse_state).tpe != lexer::TokenType::EOF {
        skip_newline(*parse_state)
        let node = parse_statement(*parse_state)
        if not node {
            // We encountered an error, skip to the next new line
            var lh = pop(*parse_state)
            while not (lh.tpe == lexer::TokenType::NEW_LINE or 
                lh.tpe == lexer::TokenType::EOF) {
                lh = pop(*parse_state)        
            }
            skip_newline(*parse_state)
        } else {
            vector::push(vec, node)
        }
    }

    let program_node = allocate(Node)
    (@program_node).kind = NodeKind::PROGRAM
    (@program_node).line = 0
    (@program_node).column = 0
    (@program_node).value.body = vec

    return program_node
}