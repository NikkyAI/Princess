import lexer

export type NodeKind = enum {
    ERROR
    PROGRAM
    INTEGER
    CHAR
    STRING
    FLOAT
    IDENTIFIER
    ADD
    SUB
    MUL
    DIV
    MOD
}

export type Node

export type NodeList = struct {
    value: *Node 
    next: *NodeList
}

export type NodeBinaryOp = struct {
    left: *Node
    right: *Node
}

export type NodeUnaryOp = struct {
    right: *Node
}

export type NodeValue = struct #union {
    bin_op: NodeBinaryOp
    un_op: NodeUnaryOp 
    body: *NodeList
    i: uint64
    str: string
    f: double
}

export type Node = struct {
    kind: NodeKind

    line: int
    column: int

    value: NodeValue
}

type ParseState = struct {
    lines: [string]
    tokens: **lexer::TokenList
}

def make_bin_op(kind: NodeKind, left: *Node, right: *Node) -> Node {
    var node = allocate(Node)
    (@node).kind = kind
    (@node).value.bin_op = {
        left, right
    } !NodeBinaryOp

    return node
}

// TODO: Make this function variadic
def errort(token: lexer::Token, state: *ParseState, msg: string) {
    let line = token.line
    let column = token.column
    error("\n")
    error((@state).lines[line], "\n")
    for var i in 0:column:1 {
        error(" ")
    }
    error("^\n")
    error(msg)
}

def skip_whitespace(state: *ParseState) {
    let list = (@state).tokens
    var tt = (@@list).value.tpe
    while tt == lexer::TokenType::WHITESPACE or tt == lexer::TokenType::COMMENT {
        @list = (@@list).next
        tt = (@@list).value.tpe
    }
    if tt == lexer::TokenType::ERROR {
        let token = (@@list).value
        errort(token, state, token.value.str)
    }
}

def pop(state: *ParseState) -> lexer::Token {
    let list = (@state).tokens
    skip_whitespace(state)
    let token = (@@list).value
    @list = (@@list).next
    return token
}

def peek(state: *ParseState) -> lexer::Token {
    let list = (@state).tokens
    skip_whitespace(state)
    return (@@list).value
}

def skip_newline(state: *ParseState) {
    loop {
        let token = peek(state)
        if token.tpe == lexer::TokenType::NEW_LINE {
            pop(state)
            continue
        }
        break
    }
}

def next_token(state: *ParseState, tpe: lexer::TokenType) -> bool {
    let token = peek(state)
    if token.tpe == tpe {
        pop(state)
        return true
    }
    return false
}

def parse_term(parse_state: *ParseState) -> *Node {
    let token = pop(parse_state)
    var node = allocate(Node)

    if token.tpe == lexer::TokenType::INTEGER {
        (@node).kind = NodeKind::INTEGER
        (@node).value.i = token.value.i
    } else if token.tpe == lexer::TokenType::FLOAT {
        (@node).kind = NodeKind::FLOAT
        (@node).value.f = token.value.f
    } else if token.tpe == lexer::TokenType::IDENTIFIER {
        (@node).kind = NodeKind::IDENTIFIER
        (@node).value.str = token.value.str
    } else if token.tpe == lexer::TokenType::STRING {
        (@node).kind = NodeKind::STRING
        (@node).value.str = token.value.str
    } else if token.tpe == lexer::TokenType::CHAR {
        (@node).kind = NodeKind::CHAR
        (@node).value.i = token.value.ch
    } else {
        errort(token, parse_state, "Expected literal or identifier\n")
        return null
    }
    return node
}

def parse_mul_expression(parse_state: *ParseState) -> *Node {
    var node = parse_term(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_MUL) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::MUL, node, parse_term(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DIV) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::DIV, node, parse_term(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_MOD) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::MOD, node, parse_term(parse_state))
        } else {
            return node
        }
    }
}

def parse_add_expresson(parse_state: *ParseState) -> *Node {
    var node = parse_mul_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_ADD) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::ADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SUB) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::SUB, node, parse_mul_expression(parse_state))
        } else {
            return node
        }
    }
}

def parse_expression(parse_state: *ParseState) -> *Node {
    let node = parse_add_expresson(parse_state)
    if not node {
        let token = peek(parse_state)
        errort(token, parse_state, "Expected expression\n")
    }
    return node
}

def parse_vardecl(parse_state: *ParseState) -> *Node {

}

def parse_typedecl(parse_state: *ParseState) -> *Node {

}

def parse_if_stmt(parse_state: *ParseState) -> *Node {

}

def parse_t_term(parse_state: *ParseState) {
    let token = peek(parse_state)
    if token.tpe == lexer::TokenType::SEMICOLON or token.tpe == lexer::TokenType::NEW_LINE {
        pop(parse_state)
    } else if token.tpe != lexer::TokenType::EOF and token.tpe != lexer::TokenType::C_BRACE {
        errort(token, parse_state, "Missing statement separator\n")
    }
}

def parse_statement(parse_state: *ParseState) -> *Node {
    let lh = peek(parse_state)
    var node: *Node
    if lh.tpe == lexer::TokenType::K_VAR {
        node = parse_vardecl(parse_state)
    } else if lh.tpe == lexer::TokenType::K_TYPE {
        node = parse_typedecl(parse_state)
    } else if lh.tpe == lexer::TokenType::K_IF {
        node = parse_if_stmt(parse_state)
    } else {
        node = parse_expression(parse_state)
    }
    parse_t_term(parse_state)
    return node
}

export def parse(list: *lexer::TokenList, lines: [string]) -> *Node {
    var parse_state: ParseState
    parse_state.lines = lines
    parse_state.tokens = *list
    
    var node_list = allocate(NodeList)
    var head = node_list

    while list != null and (@list).value.tpe != lexer::TokenType::EOF {
        let node = parse_statement(*parse_state)
        (@node_list).value = node
        (@node_list).next = allocate(NodeList)
        node_list = (@node_list).next
    }

    // Remove last item
    free((@node_list).next)
    (@node_list).next = null

    let program_node = allocate(Node)
    (@program_node).kind = NodeKind::PROGRAM
    (@program_node).value.body = head

    return program_node
}