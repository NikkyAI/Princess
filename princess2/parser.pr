import lexer

export type NodeKind = enum {
    ERROR
    PROGRAM
    INTEGER
    CHAR
    STRING
    FLOAT
    IDENTIFIER
    ADD
    SUB
    MUL
    DIV
    MOD
    BAND
    BOR
    BXOR
    SHL
    SHR
    PADD
    PSUB
}

export type ShareMarker = enum {
    NONE = 0
    EXPORT = 1
    IMPORT = 2
    BOTH = 3
}

export type VarDecl = enum {
    VAR
    LET
    CONST
}

export type Node

export type NodeList = struct {
    value: *Node 
    next: *NodeList
}

export type NodeBinaryOp = struct {
    left: *Node
    right: *Node
}

export type NodeUnaryOp = struct {
    right: *Node
}

export type NodeValue = struct #union {
    bin_op: NodeBinaryOp
    un_op: NodeUnaryOp 
    body: *NodeList
    i: uint64
    str: string
    f: double
}

export type Node = struct {
    kind: NodeKind

    line: int
    column: int

    value: NodeValue
}

type ParseState = struct {
    lines: [string]
    tokens: **lexer::TokenList
}

def make_bin_op(kind: NodeKind, left: *Node, right: *Node) -> Node {
    var node = allocate(Node)
    (@node).kind = kind
    (@node).value.bin_op = {
        left, right
    } !NodeBinaryOp

    return node
}

// TODO: Make this function variadic
def errort(token: lexer::Token, state: *ParseState, msg: string) {
    let line = token.line
    let column = token.column
    error("\n")
    error(line, ":", column, "\n")
    error((@state).lines[line], "\n")
    for var i in 0:column:1 {
        error(" ")
    }
    error("^\n")
    error(msg)
}

def skip_whitespace(state: *ParseState) {
    let list = (@state).tokens
    var tt = (@@list).value.tpe
    while tt == lexer::TokenType::WHITESPACE or 
        tt == lexer::TokenType::COMMENT or
        tt == lexer::TokenType::ERROR {

        if tt == lexer::TokenType::ERROR {
            let token = (@@list).value
            errort(token, state, token.value.str)
        }

        @list = (@@list).next
        tt = (@@list).value.tpe
    }
}

def pop(state: *ParseState) -> lexer::Token {
    let list = (@state).tokens
    skip_whitespace(state)
    let token = (@@list).value
    @list = (@@list).next
    return token
}

def peek(state: *ParseState) -> lexer::Token {
    let list = (@state).tokens
    skip_whitespace(state)
    return (@@list).value
}

def unget_token(state: *ParseState, token: lexer::Token) {
    let list = (@state).tokens
    let prev = @list
    @list = allocate(lexer::TokenList)
    (@@list).value = token
    (@@list).next = prev
}

def skip_newline(state: *ParseState) {
    loop {
        let token = peek(state)
        if token.tpe == lexer::TokenType::NEW_LINE {
            pop(state)
            continue
        }
        break
    }
}

def next_token(state: *ParseState, tpe: lexer::TokenType) -> bool {
    let token = peek(state)
    if token.tpe == tpe {
        pop(state)
        return true
    }
    return false
}

def parse_term(parse_state: *ParseState) -> *Node {
    let token = pop(parse_state)
    var node = allocate(Node)

    if token.tpe == lexer::TokenType::INTEGER {
        (@node).kind = NodeKind::INTEGER
        (@node).value.i = token.value.i
    } else if token.tpe == lexer::TokenType::FLOAT {
        (@node).kind = NodeKind::FLOAT
        (@node).value.f = token.value.f
    } else if token.tpe == lexer::TokenType::IDENTIFIER {
        (@node).kind = NodeKind::IDENTIFIER
        (@node).value.str = token.value.str
    } else if token.tpe == lexer::TokenType::STRING {
        (@node).kind = NodeKind::STRING
        (@node).value.str = token.value.str
    } else if token.tpe == lexer::TokenType::CHAR {
        (@node).kind = NodeKind::CHAR
        (@node).value.i = token.value.ch
    } else {
        errort(token, parse_state, "Expected literal or identifier\n")
        return null
    }
    return node
}

def parse_bin_expression(parse_state: *ParseState) -> *Node {
    var node = parse_term(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_BAND) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::BAND, node, parse_term(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BOR) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::BOR, node, parse_term(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BXOR) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::BXOR, node, parse_term(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHL) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::SHL, node, parse_term(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHR) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::SHR, node, parse_term(parse_state))
        } else {
            return node
        }
    }
}

def parse_mul_expression(parse_state: *ParseState) -> *Node {
    var node = parse_bin_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_MUL) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::MUL, node, parse_bin_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DIV) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::DIV, node, parse_bin_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_MOD) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::MOD, node, parse_bin_expression(parse_state))
        } else {
            return node
        }
    }
}

def parse_add_expresson(parse_state: *ParseState) -> *Node {
    var node = parse_mul_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_ADD) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::ADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SUB) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::SUB, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_INC) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::PADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DEC) {
            skip_newline(parse_state)
            node = make_bin_op(NodeKind::PSUB, node, parse_mul_expression(parse_state))
        } else {
            return node
        }
    }
}

def parse_expression(parse_state: *ParseState) -> *Node {
    let node = parse_add_expresson(parse_state)
    if not node {
        let token = peek(parse_state)
        errort(token, parse_state, "Expected expression\n")
    }
    return node
}

def parse_def(parse_state: *ParseState, share: ShareMarker) -> *Node {

}

def parse_vardecl(parse_state: *ParseState, share: ShareMarker, vardecl: VarDecl) -> *Node {

}

def parse_typedecl(parse_state: *ParseState, share: ShareMarker) -> *Node {

}

def parse_if_stmt(parse_state: *ParseState) -> *Node {

}

def parse_import_stmt(parse_state: *ParseState) -> *Node {

}

def parse_t_term(parse_state: *ParseState) {
    let token = peek(parse_state)
    if token.tpe == lexer::TokenType::SEMICOLON or token.tpe == lexer::TokenType::NEW_LINE {
        pop(parse_state)
    } else if token.tpe != lexer::TokenType::EOF and token.tpe != lexer::TokenType::C_BRACE {
        errort(token, parse_state, "Missing statement separator\n")
    }
}

def parse_statement2(parse_state: *ParseState, share: ShareMarker) -> *Node {
    let lh = peek(parse_state)
    var node: *Node = null
    if lh.tpe == lexer::TokenType::K_VAR {
        node = parse_vardecl(parse_state, share, VarDecl::VAR)
    } else if lh.tpe == lexer::TokenType::K_LET {
        node = parse_vardecl(parse_state, share, VarDecl::LET)
    } else if lh.tpe == lexer::TokenType::K_CONST {
        node = parse_vardecl(parse_state, share, VarDecl::CONST)
    } else if lh.tpe == lexer::TokenType::K_TYPE {
        node = parse_typedecl(parse_state, share)
    } else if lh.tpe == lexer::TokenType::K_DEF {
        node = parse_def(parse_state, share)
    }
    return node
}

def parse_statement(parse_state: *ParseState) -> *Node {
    let lh = peek(parse_state)
    var node: *Node = null
    if lh.tpe == lexer::TokenType::K_IMPORT {
        let share = ShareMarker::IMPORT
        let tok = pop(parse_state)
        node = parse_statement2(parse_state, share)
        if not node {
            unget_token(parse_state, tok)
            node = parse_import_stmt(parse_state)
        }
    } else if lh.tpe == lexer::TokenType::K_EXPORT {
        var share = ShareMarker::EXPORT
        pop(parse_state)
        let lh = peek(parse_state)
        if lh.tpe == lexer::TokenType::K_IMPORT {
            share = ShareMarker::BOTH
            pop(parse_state)
        }
        node = parse_statement2(parse_state, share)
        if not node {
            errort(peek(parse_state), parse_state, "Expected def, type, var, let, const\n")
        }
    } else if lh.tpe == lexer::TokenType::K_IF {
        node = parse_if_stmt(parse_state)
    } else {
        node = parse_statement2(parse_state, ShareMarker::NONE)
        if not node {
            node = parse_expression(parse_state)
        }
    }
    parse_t_term(parse_state)
    return node
}

export def parse(list: *lexer::TokenList, lines: [string]) -> *Node {
    var parse_state: ParseState
    parse_state.lines = lines
    parse_state.tokens = *list
    
    var node_list = allocate(NodeList)
    var head = node_list

    while list != null and (@list).value.tpe != lexer::TokenType::EOF {
        let node = parse_statement(*parse_state)
        if not node {
            // We encountered an error, skip to the next new line
            var lh = pop(*parse_state)
            while not (lh.tpe == lexer::TokenType::NEW_LINE or 
                lh.tpe == lexer::TokenType::EOF) {
                lh = pop(*parse_state)        
            }
            skip_newline(*parse_state)
        } else {
            (@node_list).value = node
            (@node_list).next = allocate(NodeList)
            node_list = (@node_list).next
        }
    }

    // Remove last item
    free((@node_list).next)
    (@node_list).next = null

    let program_node = allocate(Node)
    (@program_node).kind = NodeKind::PROGRAM
    (@program_node).value.body = head

    return program_node
}