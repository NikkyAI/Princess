import lexer
import vector
import util

export type NodeKind = enum {
    PROGRAM
    INTEGER
    CHAR
    STRING
    FLOAT
    BOOLEAN
    IDENTIFIER
    CAST
    ADD
    SUB
    MUL
    DIV
    MOD
    AND
    OR
    UADD
    USUB
    PTR
    DEREF
    BNOT
    NOT
    BAND
    BOR
    BXOR
    SHL
    SHR
    PADD
    PSUB
    EQ
    NEQ
    GT
    LT
    GEQ
    LEQ
    ARRAY_SUBSCRIPT
    FUNC_CALL
    VAR_DECL
    ID_DECL
    ID_ASSIGN
    NAMED_ARG
    FUNCTION_T
    WORD_T
    PTR_T
    REF_T
    ARRAY_T
    ARRAY_STATIC_T
}

export type ShareMarker = enum {
    NONE = 0
    EXPORT = 1
    IMPORT = 2
    BOTH = 3
}

export type VarDecl = enum {
    VAR
    LET
    CONST
    TYPE
}

export type Node

export type NodeArrayStaticT = struct {
    n: *Node
    kw: VarDecl
    tpe: *Node
}

export type NodePtrArrayT = struct {
    kw: VarDecl
    tpe: *Node
}

export type NodeFunctionT = struct {
    args: *vector::Vector
    ret: *vector::Vector
}

export type NodeIdDecl = struct {
    value: *Node
    tpe: *Node
}

export type NodeVarDecl = struct {
    share: ShareMarker
    kw: VarDecl
    left: *vector::Vector
    right: *vector::Vector
}

export type NodeNamedArg = struct {
    name: string
    value: *Node
}

export type NodeFuncCall = struct {
    left: *Node
    args: *vector::Vector
    kwargs: *vector::Vector
}

export type NodeBinaryOp = struct {
    left: *Node
    right: *Node
}

export type NodeValue = struct #union {
    bin_op: NodeBinaryOp
    var_decl: NodeVarDecl
    id_decl: NodeIdDecl
    named_arg: NodeNamedArg
    t_func: NodeFunctionT
    t_parr: NodePtrArrayT
    t_arrs: NodeArrayStaticT
    func_call: NodeFuncCall

    body: *vector::Vector
    expr: *Node
    i: uint64
    str: string
    f: double
}

export type Node = struct {
    kind: NodeKind

    line: int
    column: int

    value: NodeValue
}

type ParseState = struct {
    has_error: bool
    lines: [string]
    tokens: **lexer::TokenList
}

def make_bin_op(token: lexer::Token, kind: NodeKind, left: *Node, right: *Node) -> *Node {
    var node = allocate(Node)
    (@node).line = token.line
    (@node).column = token.column
    (@node).kind = kind
    (@node).value.bin_op = {
        left, right
    } !NodeBinaryOp

    return node
}

def make_un_op(token: lexer::Token, kind: NodeKind, right: *Node) -> *Node {
    var node = allocate(Node)
    (@node).line = token.line
    (@node).column = token.column
    (@node).kind = kind
    (@node).value.expr = right

    return node
}

// TODO: Make this function variadic
def errort(token: lexer::Token, state: *ParseState, msg: string) {
    if not (@state).has_error {
        let line = token.line
        let column = token.column
        error("\n")
        error(line, ":", column, "\n")
        error((@state).lines[line], "\n")
        for var i in 0..column {
            error(" ")
        }
        error("^\n")
        error(msg)
        (@state).has_error = true
    }
}

def skip_whitespace(state: *ParseState) {
    var list = (@state).tokens
    if not @list { return }
    var tt = (@@list).value.tpe
    while tt == lexer::TokenType::WHITESPACE or 
        tt == lexer::TokenType::COMMENT or
        tt == lexer::TokenType::ERROR {

        if tt == lexer::TokenType::ERROR {
            let token = (@@list).value
            errort(token, state, token.value.str)
        }

        @list = (@@list).next
        tt = (@@list).value.tpe
    }
}

def pop(state: *ParseState) -> lexer::Token {
    skip_whitespace(state)
    let list = (@state).tokens
    if not @list {
        return {
            lexer::TokenType::EOF
        } !lexer::Token
    }
    let token = (@@list).value
    @list = (@@list).next
    return token
}

def peek(state: *ParseState) -> lexer::Token {
    skip_whitespace(state)
    let list = (@state).tokens
    if not @list {
        return {
            lexer::TokenType::EOF
        } !lexer::Token
    }
    return (@@list).value
}

def unget_token(state: *ParseState, token: lexer::Token) {
    let list = (@state).tokens
    let prev = @list
    @list = allocate(lexer::TokenList)
    (@@list).value = token
    (@@list).next = prev
}

def expect(state: *ParseState, tpe: lexer::TokenType, msg: string) -> lexer::Token {
    let token = pop(state)
    if token.tpe != tpe {
        errort(token, state, msg)
    }
    return token
}

def skip_newline(state: *ParseState) {
    loop {
        let token = peek(state)
        if token.tpe == lexer::TokenType::NEW_LINE {
            pop(state)
            continue
        }
        break
    }
}

def next_token(state: *ParseState, tpe: lexer::TokenType) -> bool {
    let token = peek(state)
    if token.tpe == tpe {
        pop(state)
        return true
    }
    return false
}

def expect_identifier(parse_state: *ParseState) -> *Node {
    var token = pop(parse_state)
    
    var vec = vector::make()
    while token.tpe == lexer::TokenType::IDENTIFIER {
        vector::push(vec, util::copy_string(token.value.str))
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::DOUBLE_COLON {
            pop(parse_state)
            token = pop(parse_state)
            continue
        }
        break
    }

    if vector::length(vec) == 0 {
        errort(token, parse_state, "Expected identifier\n")
        return null
    }

    var node = allocate(Node)
    (@node).kind = NodeKind::IDENTIFIER
    (@node).value.body = vec
    (@node).line = token.line
    (@node).column = token.column

    return node
}

def parse_type(parse_state: *ParseState) -> *Node
def expect_type(parse_state: *ParseState) -> *Node
def parse_expression(parse_state: *ParseState) -> *Node
def expect_expression(parse_state: *ParseState) -> *Node

def parse_array_n(parse_state: *ParseState) -> *Node {
    var tok = peek(parse_state)
    let line = tok.line
    let column = tok.column

    if tok.tpe != lexer::TokenType::O_SQUARE {
        return null
    }
    pop(parse_state)
    tok = peek(parse_state)

    var n: *Node = null
    if tok.tpe == lexer::TokenType::QUESTION_MARK {
        pop(parse_state)
    } else {
        n = parse_expression(parse_state)
        if not n {
            return null
        }
    }

    tok = pop(parse_state)
    if tok.tpe != lexer::TokenType::SEMICOLON {
        return null
    }

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
    }
    let tpe = parse_type(parse_state)
    if not tpe {
        return null
    }

    tok = peek(parse_state)
    if tok.tpe != lexer::TokenType::C_SQUARE {
        return null
    }
    pop(parse_state)

    var node = allocate(Node)
    (@node).kind = NodeKind::ARRAY_STATIC_T
    (@node).line = line
    (@node).column = column
    (@node).value.t_arrs = {
        n = n,
        kw = kw,
        tpe = tpe
    } !NodeArrayStaticT

    return node
}

def expect_array(parse_state: *ParseState) -> *Node {
    var tok = peek(parse_state)
    let line = tok.line
    let column = tok.column

    // [N let T], [N var T] and [N T]
    var tokens = @(@parse_state).tokens
    var node = parse_array_n(parse_state)
    if node {
        return node
    }
    @(@parse_state).tokens = tokens

    tok = expect(parse_state, lexer::TokenType::O_SQUARE, "Expected '['\n")

    // [let T], [var T] and [T]

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
    }

    let tpe = expect_type(parse_state)

    tok = expect(parse_state, lexer::TokenType::C_SQUARE, "Expected ']'\n")

    node = allocate(Node)
    (@node).kind = NodeKind::ARRAY_T
    (@node).line = line
    (@node).column = column
    (@node).value.t_parr = {
        kw = kw,
        tpe = tpe
    } !NodePtrArrayT

    
    return node
}

def expect_ptr_ref(parse_state: *ParseState, ref: bool) -> *Node {
    var kind: NodeKind
    var tok: lexer::Token
    if ref {
        kind = NodeKind::REF_T
        tok = expect(parse_state, lexer::TokenType::OP_BAND, "Expected '&'\n")
    } else {
        kind = NodeKind::PTR_T
        tok = expect(parse_state, lexer::TokenType::OP_MUL, "Expected '*'\n")
    }
    let line = tok.line
    let column = tok.column

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
    }

    var tokens = @(@parse_state).tokens
    var tpe = parse_type(parse_state)
    if not tpe {
        @(@parse_state).tokens = tokens
    }

    var node = allocate(Node)
    (@node).kind = kind
    (@node).line = line
    (@node).column = column
    (@node).value.t_parr = {
        kw = kw,
        tpe = tpe
    } !NodePtrArrayT

    return node
}

def parse_type2(parse_state: *ParseState) -> *Node {
    var tok = pop(parse_state)

    if tok.tpe == lexer::TokenType::O_PAREN {
        var node = expect_type(parse_state)
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
        return node
    } else if tok.tpe == lexer::TokenType::K_TYPE {
        var node = expect_type(parse_state)
        return node
    } else if tok.tpe == lexer::TokenType::K_WORD {
        expect(parse_state, lexer::TokenType::O_PAREN, "Expected '('\n")
        var n = expect(parse_state, lexer::TokenType::INTEGER, "Expected integer\n")
        if n.tpe != lexer::TokenType::INTEGER {
            return null
        }
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
        var node = allocate(Node)
        (@node).kind = NodeKind::WORD_T
        (@node).line = tok.line
        (@node).column = tok.column
        (@node).value.i = n.value.i

        return node
    } else if tok.tpe == lexer::TokenType::O_SQUARE {
        unget_token(parse_state, tok)
        return expect_array(parse_state)
    } else if tok.tpe == lexer::TokenType::OP_MUL or
        tok.tpe == lexer::TokenType::OP_BAND {
        unget_token(parse_state, tok)
        return expect_ptr_ref(parse_state, tok.tpe == lexer::TokenType::OP_BAND)
    } else if tok.tpe == lexer::TokenType::DOUBLE_COLON or
        tok.tpe == lexer::TokenType::IDENTIFIER {
        unget_token(parse_state, tok)
        var node = expect_identifier(parse_state)
        return node
    } else {
        unget_token(parse_state, tok)
        return null
    }
}

def parse_type_list(parse_state: *ParseState, sw: bool) -> *vector::Vector {
    var token = peek(parse_state)
    var vec = vector::make()
    if token.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::C_PAREN {
            pop(parse_state)
            return vec
        }
        loop {
            let node = parse_type(parse_state)
            vector::push(vec, node)
            token = peek(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                continue
            }
            break
        }
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
    } else {
        var node: *Node = null
        if sw {
            node = parse_type(parse_state)
        } else {
            node = parse_type2(parse_state)
        }

        if node {
            vector::push(vec, node)
        }
    }
    return vec
}

// TODO Allow things like (A, B) -> (C, D) -> (E, F)
def parse_type(parse_state: *ParseState) -> *Node {
    let args = parse_type_list(parse_state, false)
    var token = peek(parse_state)
    if token.tpe == lexer::TokenType::ARROW {
        pop(parse_state)
        let ret = parse_type_list(parse_state, true)
        var node = allocate(Node)
        (@node).kind = NodeKind::FUNCTION_T
        (@node).line = token.line
        (@node).column = token.column
        (@node).value.t_func = {
            args = args,
            ret = ret
        } !NodeFunctionT
        return node
    } else if vector::length(args) > 1 {
        errort(token, parse_state, "Expected single type, got multiple\n")
        return null
    } else if vector::length(args) == 1 {
        return vector::get(args, 0)
    } else {
        return null
    }
}

def expect_type(parse_state: *ParseState) -> *Node {
    let token = peek(parse_state)
    let node = parse_type(parse_state)
    if not node {
       errort(token, parse_state, "Expected type\n") 
    }
    return node
}

def parse_term(parse_state: *ParseState) -> *Node {
    let token = pop(parse_state)
    var node = allocate(Node)
    
    if token.tpe == lexer::TokenType::O_PAREN {
        free(node)
        node = parse_expression(parse_state)
        expect(parse_state, lexer::TokenType::C_PAREN, "Expecting ')'")
        return node
    } else if token.tpe == lexer::TokenType::K_TYPE {
        free(node)
        return expect_type(parse_state)
    } else if token.tpe == lexer::TokenType::INTEGER {
        (@node).kind = NodeKind::INTEGER
        (@node).value.i = token.value.i
    } else if token.tpe == lexer::TokenType::FLOAT {
        (@node).kind = NodeKind::FLOAT
        (@node).value.f = token.value.f
    } else if token.tpe == lexer::TokenType::IDENTIFIER or
        token.tpe == lexer::TokenType::DOUBLE_COLON {
        free(node)
        unget_token(parse_state, token)
        return expect_identifier(parse_state)
    } else if token.tpe == lexer::TokenType::STRING {
        (@node).kind = NodeKind::STRING
        (@node).value.str = token.value.str
    } else if token.tpe == lexer::TokenType::CHAR {
        (@node).kind = NodeKind::CHAR
        (@node).value.i = token.value.ch
    } else if token.tpe == lexer::TokenType::K_TRUE or
        token.tpe == lexer::TokenType::K_FALSE {
        
        var value = 0
        if token.tpe == lexer::TokenType::K_TRUE {
            value = 1
        }

        (@node).kind = NodeKind::BOOLEAN
        (@node).value.i = value
    } else {
        free(node)
        // errort(token, parse_state, "Expected literal or identifier\n")
        return null
    }
    (@node).line = token.line
    (@node).column = token.column
    return node
}

def parse_func_args(parse_state: *ParseState, node: *Node) -> *Node {
    var token = peek(parse_state)
    var args = vector::make()
    while token.tpe != lexer::TokenType::C_PAREN {
        if token.tpe == lexer::TokenType::IDENTIFIER {
            token = pop(parse_state)
            if peek(parse_state).tpe == lexer::TokenType::OP_ASSIGN {
                unget_token(parse_state, token)
                break // Start list of named arguments
            }
            unget_token(parse_state, token)
        }

        vector::push(args, expect_expression(parse_state))

        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_PAREN {
            if token.tpe != lexer::TokenType::COMMA {
                errort(token, parse_state, "Expected ','\n")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    var kwargs = vector::make()
    while token.tpe != lexer::TokenType::C_PAREN {

        token = expect(parse_state, lexer::TokenType::IDENTIFIER, "expected identifier\n")
        if token.tpe != lexer::TokenType::IDENTIFIER { return null }
        expect(parse_state, lexer::TokenType::OP_ASSIGN, "expected '='\n")
        let expr = expect_expression(parse_state)

        let named_arg = allocate(Node)
        (@named_arg).kind = NodeKind::NAMED_ARG
        (@named_arg).value.named_arg = {
            name = token.value.str,
            value = expr
        } !NodeNamedArg
        vector::push(kwargs, named_arg)

        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_PAREN {
            if token.tpe != lexer::TokenType::COMMA {
                errort(token, parse_state, "Expected ','\n")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    var call = allocate(Node)
    (@call).kind = NodeKind::FUNC_CALL
    (@call).value.func_call = {
        left = node,
        args = args,
        kwargs = kwargs
    } !NodeFuncCall
}

def parse_post_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_term(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::O_PAREN) {
            node = parse_func_args(parse_state, node)
            expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
        } else if next_token(parse_state, lexer::TokenType::O_SQUARE) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::ARRAY_SUBSCRIPT, node, parse_term(parse_state))
            skip_newline(parse_state)
            expect(parse_state, lexer::TokenType::C_SQUARE, "Expected ']'\n")
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_pre_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    if next_token(parse_state, lexer::TokenType::OP_ADD) {
        skip_newline(parse_state)
        return make_un_op(token, NodeKind::UADD, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SUB) {
        skip_newline(parse_state)
        return make_un_op(token, NodeKind::USUB, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_MUL) {
        skip_newline(parse_state)
        return make_un_op(token, NodeKind::PTR, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_DEREF) {
        skip_newline(parse_state)
        return make_un_op(token, NodeKind::DEREF, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_BNOT) {
        skip_newline(parse_state)
        return make_un_op(token, NodeKind::BNOT, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::K_NOT) {
        skip_newline(parse_state)
        return make_un_op(token, NodeKind::NOT, parse_pre_expression(parse_state))
    } else {
        return parse_post_expression(parse_state)
    }
}

def parse_cast_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)    
    var node = parse_pre_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_CAST) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::CAST, node, parse_type(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_bin_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)    
    var node = parse_cast_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_BAND) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::BAND, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BOR) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::BOR, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BXOR) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::BXOR, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHL) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::SHL, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHR) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::SHR, node, parse_cast_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_mul_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_bin_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_MUL) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::MUL, node, parse_bin_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DIV) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::DIV, node, parse_bin_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_MOD) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::MOD, node, parse_bin_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_add_expresson(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_mul_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_ADD) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::ADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SUB) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::SUB, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_INC) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::PADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DEC) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::PSUB, node, parse_mul_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_cmp_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_add_expresson(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_EQ) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::EQ, node, parse_add_expresson(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_NEQ) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::NEQ, node, parse_add_expresson(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_GEQ) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::GEQ, node, parse_add_expresson(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_LEQ) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::LEQ, node, parse_add_expresson(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_GT) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::GT, node, parse_add_expresson(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_LT) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::LT, node, parse_add_expresson(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_and_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_cmp_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::K_AND) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::AND, node, parse_cmp_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_or_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_and_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::K_OR) {
            skip_newline(parse_state)
            node = make_bin_op(token, NodeKind::OR, node, parse_and_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_expression(parse_state: *ParseState) -> *Node {
    return parse_or_expression(parse_state)
}

def expect_expression(parse_state: *ParseState) -> *Node {
    let node = parse_expression(parse_state)
    if not node {
        let token = peek(parse_state)
        errort(token, parse_state, "Expected expression\n")
    }
    return node
}

def parse_def(parse_state: *ParseState, share: ShareMarker) -> *Node {

}

def parse_vardecl(parse_state: *ParseState, share: ShareMarker, vardecl: VarDecl) -> *Node {
    var tok = pop(parse_state)
    let line = tok.line
    let column = tok.column

    if not (tok.tpe == lexer::TokenType::K_VAR or 
        tok.tpe == lexer::TokenType::K_CONST or 
        tok.tpe == lexer::TokenType::K_LET) {

        return null
    }
    skip_newline(parse_state)

    var vec_left = vector::make()
    loop {
        tok = pop(parse_state)
        if tok.tpe == lexer::TokenType::O_PAREN {
            // Assignment
            let expr = expect_expression(parse_state)
            expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
            var node = allocate(Node)
            (@node).kind = NodeKind::ID_ASSIGN
            (@node).line = tok.line
            (@node).column = tok.column
            (@node).value.expr = expr
            vector::push(vec_left, node)
        } else {
            // Id decl
            unget_token(parse_state, tok)
            var ident = expect_identifier(parse_state)

            tok = peek(parse_state)
            var tpe: *Node = null
            if tok.tpe == lexer::TokenType::COLON {
                // Type
                pop(parse_state)
                tpe = expect_type(parse_state)
            }
            var node = allocate(Node)
            (@node).kind = NodeKind::ID_DECL
            (@node).line = tok.line
            (@node).column = tok.column
            (@node).value.id_decl = {
                value = ident,
                tpe = tpe
            } !NodeIdDecl
            vector::push(vec_left, node)
        }
        tok = pop(parse_state)
        if tok.tpe == lexer::TokenType::COMMA {
            skip_newline(parse_state)
            continue
        } else if tok.tpe == lexer::TokenType::OP_ASSIGN or
            tok.tpe == lexer::TokenType::NEW_LINE or
            tok.tpe == lexer::TokenType::EOF {
            break
        } else {
            errort(tok, parse_state, "Expected identifier, (expression) or '='\n")
            return null
        }
    }

    skip_newline(parse_state)

    var vec_right = vector::make()
    if tok.tpe == lexer::TokenType::OP_ASSIGN {
        loop {
            var expr = expect_expression(parse_state)
            vector::push(vec_right, expr)
            
            tok = pop(parse_state)
            if tok.tpe == lexer::TokenType::COMMA {
                skip_newline(parse_state)
                continue
            } else if tok.tpe == lexer::TokenType::NEW_LINE or
                tok.tpe == lexer::TokenType::EOF {
                unget_token(parse_state, tok)
                break
            }
        }
        //if vector::length(vec_left) != vector::length(vec_right) {
        //    errort(tok, parse_state, "Unbalanced assignment\n")
        //}
    } else if vardecl == VarDecl::LET or
        vardecl == VarDecl::CONST {
        errort(tok, parse_state, "Expected '='\n")
        return null
    }

    var node = allocate(Node)
    (@node).kind = NodeKind::VAR_DECL
    (@node).line = line
    (@node).column = column
    (@node).value.var_decl = {
        share = share,
        kw = vardecl,
        left = vec_left,
        right = vec_right
    } !NodeVarDecl

    return node
}

def parse_typedecl(parse_state: *ParseState, share: ShareMarker) -> *Node {
    return null
}

def parse_if_stmt(parse_state: *ParseState) -> *Node {
    return null
}

def parse_import_stmt(parse_state: *ParseState) -> *Node {
    return null
}

def parse_t_term(parse_state: *ParseState) {
    let token = peek(parse_state)
    if token.tpe == lexer::TokenType::SEMICOLON or token.tpe == lexer::TokenType::NEW_LINE {
        pop(parse_state)
    } else if token.tpe != lexer::TokenType::EOF and token.tpe != lexer::TokenType::C_BRACE {
        pop(parse_state)
        errort(token, parse_state, "Missing statement separator\n")
    }
}

def parse_statement2(parse_state: *ParseState, share: ShareMarker) -> *Node {
    let lh = peek(parse_state)
    var node: *Node = null
    if lh.tpe == lexer::TokenType::K_VAR {
        node = parse_vardecl(parse_state, share, VarDecl::VAR)
    } else if lh.tpe == lexer::TokenType::K_LET {
        node = parse_vardecl(parse_state, share, VarDecl::LET)
    } else if lh.tpe == lexer::TokenType::K_CONST {
        node = parse_vardecl(parse_state, share, VarDecl::CONST)
    } else if lh.tpe == lexer::TokenType::K_TYPE {
        node = parse_typedecl(parse_state, share)
    } else if lh.tpe == lexer::TokenType::K_DEF {
        node = parse_def(parse_state, share)
    }
    return node
}

def parse_statement(parse_state: *ParseState) -> *Node {
    let lh = peek(parse_state)
    var node: *Node = null
    if lh.tpe == lexer::TokenType::K_IMPORT {
        let share = ShareMarker::IMPORT
        let tok = pop(parse_state)
        node = parse_statement2(parse_state, share)
        if not node {
            unget_token(parse_state, tok)
            node = parse_import_stmt(parse_state)
        }
    } else if lh.tpe == lexer::TokenType::K_EXPORT {
        var share = ShareMarker::EXPORT
        pop(parse_state)
        let lh = peek(parse_state)
        if lh.tpe == lexer::TokenType::K_IMPORT {
            share = ShareMarker::BOTH
            pop(parse_state)
        }
        node = parse_statement2(parse_state, share)
        if not node {
            errort(peek(parse_state), parse_state, "Expected def, type, var, let, const\n")
            return null
        }
    } else if lh.tpe == lexer::TokenType::K_IF {
        node = parse_if_stmt(parse_state)
    } else {
        node = parse_statement2(parse_state, ShareMarker::NONE)
        if not node {
            node = expect_expression(parse_state)
        }
    }
    parse_t_term(parse_state)
    return node
}

export def parse(list: *lexer::TokenList, lines: [string]) -> *Node {
    var parse_state: ParseState
    parse_state.lines = lines
    parse_state.tokens = *list
    
    var vec = vector::make()

    while list != null and peek(*parse_state).tpe != lexer::TokenType::EOF {
        skip_newline(*parse_state)
        let node = parse_statement(*parse_state)
        parse_state.has_error = false
        if not node {
            // We encountered an error, skip to the next newline
            var lh = pop(*parse_state)
            while not (lh.tpe == lexer::TokenType::NEW_LINE or 
                lh.tpe == lexer::TokenType::EOF) {
                lh = pop(*parse_state)        
            }
            skip_newline(*parse_state)
        } else {
            vector::push(vec, node)
        }
    }

    let program_node = allocate(Node)
    (@program_node).kind = NodeKind::PROGRAM
    (@program_node).line = 0
    (@program_node).column = 0
    (@program_node).value.body = vec

    return program_node
}