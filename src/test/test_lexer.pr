import lexer
import test::testsuite

def next_value(list: **lexer::TokenList, tpe: lexer::TokenType) -> lexer::Token {
    let value = (@@list).value
    if value.tpe == lexer::TokenType::ERROR {
        error("Error: ", value.value.str, "\n")
        exit(2)
    }
    tassert(value.tpe == tpe)
    @list = (@@list).next
    return value
}

def next_char(list: **lexer::TokenList) -> char {
    return next_value(list, lexer::TokenType::CHAR).value.ch
}

def next_long(list: **lexer::TokenList) -> uint64 {
    return next_value(list, lexer::TokenType::INTEGER).value.i
}

def next_double(list: **lexer::TokenList) -> double {
    return next_value(list, lexer::TokenType::FLOAT).value.f
}

def next_string(list: **lexer::TokenList) -> &string {
    return next_value(list, lexer::TokenType::STRING).value.str
}

def next_identifier(list: **lexer::TokenList) -> &string {
    return next_value(list, lexer::TokenType::IDENTIFIER).value.str
}

def next_comment(list: **lexer::TokenList) -> &string {
    return next_value(list, lexer::TokenType::COMMENT).value.str
}

def next_pragma(list: **lexer::TokenList) -> &string {
    return next_value(list, lexer::TokenType::PRAGMA).value.str
}

def next_error(list: **lexer::TokenList) -> &string {
    let value = (@@list).value
    if value.tpe != lexer::TokenType::ERROR {
        error("Error: Invalid token type: ", value.tpe, "\n")
        exit(2)
    }
    let s = value.value.str
    @list = (@@list).next
    return s
}

def test_float_literal {
    var str = "10.5"
    var result = lexer::lex(str)
    tassert(next_double(*result) == 10.5)

    str = ".5"
    result = lexer::lex(str)
    tassert(next_double(*result) == .5)

    str = "10."
    result = lexer::lex(str)
    tassert(next_double(*result) == 10.)

    str = "10E10"
    result = lexer::lex(str)
    tassert(next_double(*result) == 10E10) 

    str = "10.e10"
    result = lexer::lex(str)
    tassert(next_double(*result) == 10.e10) 

    /*str = "10E-4"
    result = lexer::lex(str)
    tassert(next_double(*result) == 10E-4)*/ // TODO This doesnt work

    str = "10E+10"
    result = lexer::lex(str)
    tassert(next_double(*result) == 10E+10) 
}

def test_int_literal {
    var str = "156"
    var result = lexer::lex(str)
    tassert(next_long(*result) == 156)

    str = "0b100100"
    result = lexer::lex(str)
    tassert(next_long(*result) == 0b100100)

    str = "0xDEADBABE"
    result = lexer::lex(str)
    tassert(next_long(*result) == 0xDEADBABE)

    str = "0o172"
    result = lexer::lex(str)
    tassert(next_long(*result) == 0o172)
}

def test_char_literal {
    var str = "'A'"
    var result = lexer::lex(str)
    tassert(next_char(*result) == 'A')

    str = "'A' 'B'"
    result = lexer::lex(str)
    tassert(next_char(*result) == 'A')
    next_value(*result, lexer::TokenType::WHITESPACE)
    tassert(next_char(*result) == 'B')

    str = "'\\a'"
    result = lexer::lex(str)
    tassert(next_char(*result) == '\a')

    str = "'\\xFF'"
    result = lexer::lex(str)
    tassert(next_char(*result) == '\xFF')

}

def test_char_literal_error {
    var str = "'A"
    var result = lexer::lex(str)
    tassert(next_error(*result) == "Unexpected end of file while parsing character")

    str = "'\\d'"
    result = lexer::lex(str)
    tassert(next_error(*result) == "Invalid escape sequence")

    str = "'\\x"
    result = lexer::lex(str)
    tassert(next_error(*result) == "Invalid escape sequence")

    //TODO Test more corner cases
}

def test_string_literal {
    var str = "\"this is a test\""
    var result = lexer::lex(str)
    tassert(next_string(*result) == "this is a test")

    str = "\"test\" \"more\""
    result = lexer::lex(str)
    tassert(next_string(*result) == "test")
    next_value(*result, lexer::TokenType::WHITESPACE)
    tassert(next_string(*result) == "more")

    str = "\"\\a\\b\\f\\n\\r\\t\\v\\'\\\"\\\\\""
    result = lexer::lex(str)
    tassert(next_string(*result) == "\a\b\f\n\r\t\v\'\"\\")

    str = "\"\\xFF\""
    result = lexer::lex(str)
    tassert(next_string(*result) == "\xFF")

    str = "\"\\u01FF\""
    result = lexer::lex(str)
    tassert(next_string(*result) == "\u01FF")

    str = "\"\\u88AA\""
    result = lexer::lex(str)
    tassert(next_string(*result) == "\u88AA")

    str = "\"\\U0010FFFF\""
    result = lexer::lex(str)
    tassert(next_string(*result) == "\U0010FFFF")

    str = "\"\n\n\""
    result = lexer::lex(str)
    tassert(next_string(*result) == "\n\n")
}

def test_string_literal_error {
    var str = "\"this is a test"
    var result = lexer::lex(str)
    tassert(next_error(*result) == "Unexpected end of file while parsing string literal")

    str = "\"test \\d \""
    result = lexer::lex(str)
    tassert(next_error(*result) == "Invalid escape sequence")

    str = "\"\\UGHRR\""
    result = lexer::lex(str)
    tassert(next_error(*result) == "Invalid escape sequence")

    str = "\"\\UFF0000FF\""
    result = lexer::lex(str)
    tassert(next_error(*result) == "Invalid unicode sequence")
}

def test_identifier {
    var str = "foo_bar"
    var result = lexer::lex(str)
    tassert(next_identifier(*result) == "foo_bar")

    str = "foo bar"
    result = lexer::lex(str)
    tassert(next_identifier(*result) == "foo")
    next_value(*result, lexer::TokenType::WHITESPACE)
    tassert(next_identifier(*result) == "bar")

    str = "def foo"
    result = lexer::lex(str)
    next_value(*result, lexer::TokenType::K_DEF)
    next_value(*result, lexer::TokenType::WHITESPACE)
    tassert(next_identifier(*result) == "foo")
}

def test_pragma {
    var str = "#union"
    var result = lexer::lex(str)
    tassert(next_pragma(*result) == "#union")

    str = "##compiler_dep"
    result = lexer::lex(str)
    tassert(next_pragma(*result) == "##compiler_dep")
}

def test_comment {
    var str = "//This is a test"
    var result = lexer::lex(str)
    tassert(next_comment(*result) == "//This is a test")

    str = "//This
           //Test
    "
    result = lexer::lex(str)
    tassert(next_comment(*result) == "//This")
    next_value(*result, lexer::TokenType::NEW_LINE)
    next_value(*result, lexer::TokenType::WHITESPACE)
    tassert(next_comment(*result) == "//Test")

    str = "/*This*/"
    result = lexer::lex(str)
    tassert(next_comment(*result) == "/*This*/")

    str = "/*Nested/*Comment*/*/"
    result = lexer::lex(str)
    tassert(next_comment(*result) == "/*Nested/*Comment*/*/")
}

def test_symbols {
    var str = "foo+bar"
    var result = lexer::lex(str)
    tassert(next_identifier(*result) == "foo")
    next_value(*result, lexer::TokenType::OP_ADD)
    tassert(next_identifier(*result) == "bar")

    str = "1..2"
    result = lexer::lex(str)
    tassert(next_long(*result) == 1)
    next_value(*result, lexer::TokenType::OP_RANGE)
    tassert(next_long(*result) == 2)

    // TODO add more tests
}

def test_complex {
    var str = "
        type T = struct {
            a: int
            b: string
        }

        def main(a: int, b: unsigned word) -> T {
            print(\"A: \", a, \" B: \", b)
            var t: T = {
                a = 0, b = \"Test string\"
            } !T
        }
    "
    var result = lexer::lex(str)
    //lexer::print_token_list(result)
}

export def run_tests {
    print("Running tests on Lexer...\n")
    run_test("test_string_literal", *test_string_literal)
    run_test("test_string_literal_error", *test_string_literal_error)
    run_test("test_char_literal", *test_char_literal)
    run_test("test_char_literal_error", *test_char_literal_error)
    run_test("test_int_literal", *test_int_literal)
    run_test("test_float_literal", *test_float_literal)
    run_test("test_identifier", *test_identifier)
    run_test("test_pragma", *test_pragma)
    run_test("test_comment", *test_comment)
    run_test("test_symbols", *test_symbols)
    run_test("test_complex", *test_complex)
}