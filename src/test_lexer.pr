import lexer

def next_value(list: **lexer::TokenList, tpe: lexer::TokenType) -> lexer::Token {
    let value = (@@list).value
    if value.tpe == lexer::TokenType::ERROR {
        error("Error: ", value.value.str, "\n")
        exit(-1)
    }
    assert(value.tpe == tpe)
    @list = (@@list).next
    return value
}

def next_char(list: **lexer::TokenList) -> char {
    return next_value(list, lexer::TokenType::CHAR).value.ch
}

def next_long(list: **lexer::TokenList) -> uint64 {
    return next_value(list, lexer::TokenType::INTEGER).value.i
}

def next_double(list: **lexer::TokenList) -> double {
    return next_value(list, lexer::TokenType::FLOAT).value.f
}

def next_string(list: **lexer::TokenList) -> string {
    return next_value(list, lexer::TokenType::STRING).value.str
}

def next_identifier(list: **lexer::TokenList) -> string {
    return next_value(list, lexer::TokenType::IDENTIFIER).value.str
}

def next_comment(list: **lexer::TokenList) -> string {
    return next_value(list, lexer::TokenType::COMMENT).value.str
}

def next_pragma(list: **lexer::TokenList) -> string {
    return next_value(list, lexer::TokenType::PRAGMA).value.str
}

def next_error(list: **lexer::TokenList) -> string {
    let value = (@@list).value
    if value.tpe != lexer::TokenType::ERROR {
        error("Error: Invalid token type: ", value.tpe, "\n")
        exit(-1)
    }
    let s = value.value.str
    @list = (@@list).next
    return s
}

def test_float_literal {
    print(">Test float literal... ")

    var str = "10.5"
    var result = lexer::lex(str)
    assert(next_double(*result) == 10.5)

    str = ".5"
    result = lexer::lex(str)
    assert(next_double(*result) == .5)

    str = "10."
    result = lexer::lex(str)
    assert(next_double(*result) == 10.)

    str = "10E10"
    result = lexer::lex(str)
    assert(next_double(*result) == 10E10) 

    str = "10.e10"
    result = lexer::lex(str)
    assert(next_double(*result) == 10.e10) 

    /*str = "10E-4"
    result = lexer::lex(str)
    assert(next_double(*result) == 10E-4)*/ // TODO This doesnt work

    str = "10E+10"
    result = lexer::lex(str)
    assert(next_double(*result) == 10E+10) 
    
    print("OK\n")
}

def test_int_literal {
    print(">Test int literal... ")

    var str = "156"
    var result = lexer::lex(str)
    assert(next_long(*result) == 156)

    str = "0b100100"
    result = lexer::lex(str)
    assert(next_long(*result) == 0b100100)

    str = "0xDEADBABE"
    result = lexer::lex(str)
    assert(next_long(*result) == 0xDEADBABE)

    str = "0o172"
    result = lexer::lex(str)
    assert(next_long(*result) == 0o172)

    print("OK\n")
}

def test_char_literal {
    print(">Test char literal... ")

    var str = "'A'"
    var result = lexer::lex(str)
    assert(next_char(*result) == 'A')

    str = "'A' 'B'"
    result = lexer::lex(str)
    assert(next_char(*result) == 'A')
    next_value(*result, lexer::TokenType::WHITESPACE)
    assert(next_char(*result) == 'B')

    str = "'\\a'"
    result = lexer::lex(str)
    assert(next_char(*result) == '\a')

    str = "'\\xFF'"
    result = lexer::lex(str)
    assert(next_char(*result) == '\xFF')

    print("OK\n")
}

def test_char_literal_error {
    print(">Test char literal error... ")

    var str = "'A"
    var result = lexer::lex(str)
    assert(next_error(*result) == "Unexpected end of file while parsing character\n")

    str = "'\\d'"
    result = lexer::lex(str)
    assert(next_error(*result) == "Invalid escape sequence\n")

    str = "'\\x"
    result = lexer::lex(str)
    assert(next_error(*result) == "Invalid escape sequence\n")

    //TODO Test more corner cases

    print("OK\n")
}

def test_string_literal {
    print(">Test string literal... ")

    var str = "\"this is a test\""
    var result = lexer::lex(str)
    assert(next_string(*result) == "this is a test")

    str = "\"test\" \"more\""
    result = lexer::lex(str)
    assert(next_string(*result) == "test")
    next_value(*result, lexer::TokenType::WHITESPACE)
    assert(next_string(*result) == "more")

    str = "\"\\a\\b\\f\\n\\r\\t\\v\\'\\\"\\\\\""
    result = lexer::lex(str)
    assert(next_string(*result) == "\a\b\f\n\r\t\v\'\"\\")

    str = "\"\\xFF\""
    result = lexer::lex(str)
    assert(next_string(*result) == "\xFF")

    str = "\"\\u01FF\""
    result = lexer::lex(str)
    assert(next_string(*result) == "\u01FF")

    str = "\"\\u88AA\""
    result = lexer::lex(str)
    assert(next_string(*result) == "\u88AA")

    str = "\"\\U0010FFFF\""
    result = lexer::lex(str)
    assert(next_string(*result) == "\U0010FFFF")

    str = "\"\n\n\""
    result = lexer::lex(str)
    assert(next_string(*result) == "\n\n")

    print("OK\n")
}

def test_string_literal_error {
    print(">Test string literal error... ")

    var str = "\"this is a test"
    var result = lexer::lex(str)
    assert(next_error(*result) == "Unexpected end of file while parsing string literal\n")

    str = "\"test \\d \""
    result = lexer::lex(str)
    assert(next_error(*result) == "Invalid escape sequence\n")

    str = "\"\\UGHRR\""
    result = lexer::lex(str)
    assert(next_error(*result) == "Invalid escape sequence\n")

    str = "\"\\UFF0000FF\""
    result = lexer::lex(str)
    assert(next_error(*result) == "Invalid unicode sequence\n")

    print("OK\n")
}

def test_identifier {
    print(">Test identifier... ")

    var str = "foo_bar"
    var result = lexer::lex(str)
    assert(next_identifier(*result) == "foo_bar")

    str = "foo bar"
    result = lexer::lex(str)
    assert(next_identifier(*result) == "foo")
    next_value(*result, lexer::TokenType::WHITESPACE)
    assert(next_identifier(*result) == "bar")

    str = "def foo"
    result = lexer::lex(str)
    next_value(*result, lexer::TokenType::K_DEF)
    next_value(*result, lexer::TokenType::WHITESPACE)
    assert(next_identifier(*result) == "foo")

    print("OK\n")
}

def test_pragma {
    print(">Test pragma... ")

    var str = "#union"
    var result = lexer::lex(str)
    assert(next_pragma(*result) == "#union")

    str = "##compiler_dep"
    result = lexer::lex(str)
    assert(next_pragma(*result) == "##compiler_dep")

    print("OK\n")
}

def test_comment {
    print(">Test comment... ")

    var str = "//This is a test"
    var result = lexer::lex(str)
    assert(next_comment(*result) == "//This is a test")

    str = "//This
           //Test
    "
    result = lexer::lex(str)
    assert(next_comment(*result) == "//This")
    next_value(*result, lexer::TokenType::NEW_LINE)
    next_value(*result, lexer::TokenType::WHITESPACE)
    assert(next_comment(*result) == "//Test")

    str = "/*This*/"
    result = lexer::lex(str)
    assert(next_comment(*result) == "/*This*/")

    str = "/*Nested/*Comment*/*/"
    result = lexer::lex(str)
    assert(next_comment(*result) == "/*Nested/*Comment*/*/")

    print("OK\n")
}

def test_symbols {
    print(">Test symbols... ")

    var str = "foo+bar"
    var result = lexer::lex(str)
    assert(next_identifier(*result) == "foo")
    next_value(*result, lexer::TokenType::OP_ADD)
    assert(next_identifier(*result) == "bar")

    str = "1..2"
    result = lexer::lex(str)
    assert(next_long(*result) == 1)
    next_value(*result, lexer::TokenType::OP_RANGE)
    assert(next_long(*result) == 2)

    // TODO add more tests

    print("OK\n")
}

def test_complex {
    print(">Test complex example... ")

    var str = "
        type T = struct {
            a: int
            b: string
        }

        def main(a: int, b: unsigned word) -> T {
            print(\"A: \", a, \" B: \", b)
            var t: T = {
                a = 0, b = \"Test string\"
            } !T
        }
    "
    var result = lexer::lex(str)
    //lexer::print_token_list(result)

    print("OK\n")
}

export def test {
    print("Running tests on Lexer...\n")
    test_string_literal()
    test_string_literal_error()
    test_char_literal()
    test_char_literal_error()
    test_int_literal()
    test_float_literal()
    test_identifier()
    test_pragma()
    test_comment()
    test_symbols()
    test_complex()
}