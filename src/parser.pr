import lexer
import vector
import map
import util
import buffer
import toolchain
import typechecking
import scope

export type NodeKind = enum {
    PROGRAM
    INTEGER
    CHAR
    STRING
    FLOAT
    BOOLEAN
    IDENTIFIER
    ERROR
    DEFINED
    NULL
    RANGE
    RANGE_INC
    ARRAY_LIT
    STRUCT_LIT
    MEMBER_ACCESS
    CAST
    SIZE_OF
    ALIGN_OF
    DEFER
    ADD
    SUB
    MUL
    DIV
    MOD
    AND
    OR
    UADD
    USUB
    PTR
    DEREF
    BNOT
    NOT
    BAND
    BOR
    BXOR
    SHL
    SHR
    PADD
    PSUB
    EQ
    NEQ
    GT
    LT
    GEQ
    LEQ
    PADD_EQ
    PSUB_EQ
    ADD_EQ
    SUB_EQ
    MUL_EQ
    DIV_EQ
    MOD_EQ
    AND_EQ
    OR_EQ
    XOR_EQ
    SHL_EQ
    SHR_EQ
    IMPORT
    IMPORT_MODULE
    ASSIGN
    DEF
    PARAMETER
    SWITCH
    CASE
    IF
    IF_EXPR
    STATIC_IF
    ELSE_IF
    ELSE
    LOOP
    WHILE
    FOR
    FOR_ID_DECL
    BREAK
    CONTINUE
    RETURN
    ARRAY_SUBSCRIPT
    FUNC_CALL
    TYPE_DECL
    VAR_DECL
    ID_DECL
    ID_ASSIGN
    NAMED_ARG
    ID_DECL_STRUCT
    ID_DECL_ENUM
    ENUM_T
    STRUCT_T
    UNION_T
    FUNCTION_T
    UNSIGNED_T
    WORD_T
    PTR_T
    REF_T
    ARRAY_T
    ARRAY_STATIC_T
}

export type ShareMarker = enum {
    NONE = 0
    EXPORT = 1
    IMPORT = 2
    BOTH = 3
}

export type VarDecl = enum {
    VAR
    LET
    CONST
    TYPE
}

export type NodeDef = struct {
    extern: bool
    share: ShareMarker
    name: *Node
    params: *vector::Vector
    returns: *vector::Vector
    body: *vector::Vector
    is_used: bool
    // Map of typechecking::Type
    locals: *map::Map
    has_defer: bool
}

export type NodeParam = struct {
    varargs: bool
    kw: VarDecl
    name: *Node
    tpe: *Node
    value: *Node
}

export type NodeImportModule = struct {
    name: *Node
    alias: *Node
}

export type NodeSwitch = struct {
    expr: *Node
    body: *vector::Vector
}

export type NodeCase = struct {
    expr: *vector::Vector
    body: *vector::Vector
}

export type NodeIf = struct {
    cond: *Node
    body: *vector::Vector
    else_if: *vector::Vector
    else_: *Node
}

export type NodeElseIf = struct {
    cond: *Node
    body: *vector::Vector
}

export type NodeArrayStaticT = struct {
    n: *Node
    kw: VarDecl
    tpe: *Node
}

export type NodePtrArrayT = struct {
    kw: VarDecl
    tpe: *Node
}

export type NodeFunctionT = struct {
    args: *vector::Vector
    ret: *vector::Vector
}

export type NodeIdDecl = struct {
    value: *Node
    tpe: *Node
}

export type NodeVarDecl = struct {
    extern: bool
    share: ShareMarker
    kw: VarDecl
    left: *vector::Vector
    right: *vector::Vector
}

export type NodeTypeDecl = struct {
    share: ShareMarker
    left: *vector::Vector
    right: *vector::Vector
}

export type NodeNamedArg = struct {
    name: *Node
    value: *Node
}

export type NodeFuncCall = struct {
    left: *Node
    args: *vector::Vector
    kwargs: *vector::Vector
}

export type NodeStructLit = struct {
    args: *vector::Vector
    kwargs: *vector::Vector
}

export type NodeBinaryOp = struct {
    left: *Node
    right: *Node
}

export type NodeAssign = struct {
    left: *vector::Vector
    right: *vector::Vector
}

export type NodeForIdDecl = struct {
    kw: VarDecl
    ident: *Node
}

export type NodeFor = struct {
    iddecl: *Node
    expr: *Node
    body: *vector::Vector
}

export type NodeWhile = struct {
    expr: *Node
    body: *vector::Vector
}

export type NodeIdDeclStruct = struct {
    ident: *Node
    tpe: *Node
}

export type NodeEnumT = struct {
    tpe: *Node
    body: *vector::Vector
}

export type NodeIdDeclEnum = struct {
    ident: *Node
    value: *Node
}

export type NodeIfExpr = struct {
    cond: *Node
    if_true: *Node
    if_false: *Node
}

export type NodeValue = struct #union {
    bin_op: NodeBinaryOp
    var_decl: NodeVarDecl
    type_decl: NodeTypeDecl
    id_decl: NodeIdDecl
    id_decl_struct: NodeIdDeclStruct
    id_decl_enum: NodeIdDeclEnum
    named_arg: NodeNamedArg
    struct_lit: NodeStructLit
    t_enum: NodeEnumT
    t_func: NodeFunctionT
    t_parr: NodePtrArrayT
    t_arrs: NodeArrayStaticT
    func_call: NodeFuncCall
    assign: NodeAssign
    if_expr: NodeIfExpr
    if_: NodeIf
    else_if: NodeElseIf
    switch_: NodeSwitch
    case_: NodeCase
    while_loop: NodeWhile
    for_loop: NodeFor
    for_id_decl: NodeForIdDecl
    import_module: NodeImportModule
    def_: NodeDef
    param: NodeParam

    body: *vector::Vector
    expr: *Node
    i: uint64
    str: string
    f: double
}

export type SourceLoc = struct {
    filename: string
    module: string
    line: int
    column: int
    end_line: int
    end_column: int
    lines: [string]
}

export type Node = struct {
    kind: NodeKind

    loc: SourceLoc

    tpe: *typechecking::Type
    // This is for passing on a function from typechecking to the compiler
    // TODO There might be better ways of doing this
    function: *typechecking::Type
    svalue: *scope::Value
    scope: *scope::Scope
    // For things like if statements or functions
    inner_scope: *scope::Scope
    value: NodeValue
    parent: *Node

    // This is so that we have a consistent layout, this refers to the
    // actual data in value
    // TODO remove body from the NodeValue union
    body: *vector::Vector
}

type ParseState = struct {
    filename: string
    module: string
    has_error: bool
    lines: [string]
    tokens: **lexer::TokenList
}

def errort(token: lexer::Token, state: *ParseState, msg: string)

export def make_identifier(s: [string]) -> *Node {
    let node = allocate(Node)
    let vec = vector::make()
    for var i in 0..s.size {
        vector::push(vec, util::copy_string(s[i]))
    }
    (@node).kind = NodeKind::IDENTIFIER
    (@node).loc.filename = "builtins"
    (@node).loc.module = "builtins"
    (@node).loc.line = -1
    (@node).loc.column = -1
    (@node).loc.module = ""
    (@node).value.body = vec
    (@node).tpe = null
    (@node).scope = null
    return node
}

// This copies a node, all the contents are the same
export def copy_node(node: *Node) -> *Node {
    let copy = allocate(Node)
    @copy = @node
    return copy
}

export def identifier_to_str(node: *Node) -> string {
    assert((@node).kind == NodeKind::IDENTIFIER)
    let buf = buffer::make_buffer()
    let len = vector::length((@node).value.body)
    for var i in 0..len {
        buffer::append_str(*buf, @(vector::get((@node).value.body, i) !*string))
        if i < len - 1 {
            buffer::append_str(*buf, "::")
        }
    }

    return buffer::to_string(*buf)
}

def make_node(kind: NodeKind, line: int, column: int, state: *ParseState) -> *Node {
    let current_token = peek(state)
    var node = allocate(Node)
    (@node).tpe = null
    (@node).function = null
    (@node).scope = null
    (@node).kind = kind
    (@node).parent = null
    (@node).loc = {
        (@state).filename,
        (@state).module,
        line,
        column,
        current_token.end_line,
        current_token.end_column,
        (@state).lines
    } !SourceLoc
    return node
}

def make_bin_op(state: *ParseState, token: lexer::Token, kind: NodeKind, left: *Node, right: *Node) -> *Node {
    var node = make_node(kind, token.line, token.column, state)
    (@node).value.bin_op = {
        left, right
    } !NodeBinaryOp

    return node
}

def make_un_op(state: *ParseState, token: lexer::Token, kind: NodeKind, right: *Node) -> *Node {
    var node = make_node(kind, token.line, token.column, state)
    (@node).value.expr = right

    return node
}

def skip_whitespace(state: *ParseState) {
    var list = (@state).tokens
    if not @list { return }
    var tt = (@@list).value.tpe
    while tt == lexer::TokenType::WHITESPACE or 
        tt == lexer::TokenType::COMMENT or
        tt == lexer::TokenType::ERROR {

        if tt == lexer::TokenType::ERROR {
            let token = (@@list).value
            errort(token, state, token.value.str)
        }

        @list = (@@list).next
        tt = (@@list).value.tpe
    }
}

def pop(state: *ParseState) -> lexer::Token {
    skip_whitespace(state)
    let list = (@state).tokens
    if not @list {
        return {
            lexer::TokenType::EOF
        } !lexer::Token
    }
    let token = (@@list).value
    @list = (@@list).next
    return token
}

def peek(state: *ParseState) -> lexer::Token {
    skip_whitespace(state)
    let list = (@state).tokens
    if not @list {
        return {
            lexer::TokenType::EOF
        } !lexer::Token
    }
    return (@@list).value
}

def unget_token(state: *ParseState, token: lexer::Token) {
    let list = (@state).tokens
    let prev = @list
    @list = allocate(lexer::TokenList)
    (@@list).value = token
    (@@list).next = prev
}

def expect(state: *ParseState, tpe: lexer::TokenType, msg: string) -> lexer::Token {
    let token = pop(state)
    if token.tpe != tpe {
        errort(token, state, msg)
    }
    return token
}

def skip_newline(state: *ParseState) {
    loop {
        let token = peek(state)
        if token.tpe == lexer::TokenType::NEW_LINE {
            pop(state)
            continue
        }
        break
    }
}

def next_token(state: *ParseState, tpe: lexer::TokenType) -> bool {
    let token = peek(state)
    if token.tpe == tpe {
        pop(state)
        return true
    }
    return false
}

def expect_identifier(parse_state: *ParseState) -> *Node {
    var token = pop(parse_state)
    let line = token.line
    let column = token.column
    
    var vec = vector::make()
    while token.tpe == lexer::TokenType::IDENTIFIER {
        vector::push(vec, util::copy_string(token.value.str))
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::DOUBLE_COLON {
            pop(parse_state)
            token = pop(parse_state)
            continue
        }
        break
    }

    if vector::length(vec) == 0 {
        errort(token, parse_state, "Expected identifier\n")
        return null
    }

    var node = make_node(NodeKind::IDENTIFIER, line, column, parse_state)
    (@node).value.body = vec

    return node
}

def parse_array_n(parse_state: *ParseState) -> *Node {
    var tok = peek(parse_state)
    let line = tok.line
    let column = tok.column

    if tok.tpe != lexer::TokenType::O_SQUARE {
        return null
    }
    pop(parse_state)
    tok = peek(parse_state)

    var n: *Node = null
    if tok.tpe == lexer::TokenType::QUESTION_MARK {
        pop(parse_state)
    } else {
        n = parse_expression(parse_state)
        if not n {
            return null
        }
    }

    tok = pop(parse_state)
    if tok.tpe != lexer::TokenType::SEMICOLON {
        return null
    }

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
    }
    let tpe = parse_type(parse_state)
    if not tpe {
        return null
    }

    tok = peek(parse_state)
    if tok.tpe != lexer::TokenType::C_SQUARE {
        return null
    }
    pop(parse_state)

    var node = make_node(NodeKind::ARRAY_STATIC_T, line, column, parse_state)
    (@node).value.t_arrs = {
        n = n,
        kw = kw,
        tpe = tpe
    } !NodeArrayStaticT

    return node
}

def expect_array(parse_state: *ParseState) -> *Node {
    var tok = peek(parse_state)
    let line = tok.line
    let column = tok.column

    // [N; let T], [N; var T] and [N; T]
    var tokens = @(@parse_state).tokens
    var node = parse_array_n(parse_state)
    if node {
        return node
    }
    @(@parse_state).tokens = tokens

    tok = expect(parse_state, lexer::TokenType::O_SQUARE, "Expected '['\n")

    // [let T], [var T] and [T]

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
    }

    let tpe = expect_type(parse_state)

    tok = expect(parse_state, lexer::TokenType::C_SQUARE, "Expected ']'\n")

    node = make_node(NodeKind::ARRAY_T, line, column, parse_state)
    (@node).value.t_parr = {
        kw = kw,
        tpe = tpe
    } !NodePtrArrayT

    
    return node
}

def expect_ptr_ref(parse_state: *ParseState, ref: bool) -> *Node {
    var kind: NodeKind
    var tok: lexer::Token
    if ref {
        kind = NodeKind::REF_T
        tok = expect(parse_state, lexer::TokenType::OP_BAND, "Expected '&'\n")
    } else {
        kind = NodeKind::PTR_T
        tok = expect(parse_state, lexer::TokenType::OP_MUL, "Expected '*'\n")
    }
    let line = tok.line
    let column = tok.column

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
    }

    var tokens = @(@parse_state).tokens
    var tpe = parse_type(parse_state)
    if not tpe {
        @(@parse_state).tokens = tokens
    }

    var node = make_node(kind, line, column, parse_state)
    (@node).value.t_parr = {
        kw = kw,
        tpe = tpe
    } !NodePtrArrayT

    return node
}

def parse_id_decl_struct(parse_state: *ParseState) -> *Node {
    let lh = peek(parse_state)
    
    var node: *Node = null
    if lh.tpe == lexer::TokenType::K_STRUCT {
        node = expect_struct(parse_state)
    } else {
        var ident = expect_identifier(parse_state)
        skip_newline(parse_state)
        expect(parse_state, lexer::TokenType::COLON, "Expected ':'\n")
        skip_newline(parse_state)
        var tpe = expect_type(parse_state)

        node = make_node(NodeKind::ID_DECL_STRUCT, lh.line, lh.column, parse_state)
        (@node).value.id_decl_struct = {
            ident = ident,
            tpe = tpe
        } !NodeIdDeclStruct
    }
    
    parse_t_term(parse_state)
    return node
}

def expect_struct(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var kind = NodeKind::STRUCT_T

    expect(parse_state, lexer::TokenType::K_STRUCT, "Expected struct\n")
    skip_newline(parse_state)
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::PRAGMA {
        pop(parse_state)
        if token.value.str == "#union" {
            kind = NodeKind::UNION_T
        } else {
            errort(token, parse_state, "Unexpected pragma, only #union allowed\n")
            return null
        }
    }
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'\n")
    skip_newline(parse_state)

    var body = vector::make()

    token = peek(parse_state)
    while token.tpe != lexer::TokenType::C_BRACE and
        token.tpe != lexer::TokenType::EOF {
        vector::push(body, parse_id_decl_struct(parse_state))
        skip_newline(parse_state)
        token = peek(parse_state)
    }

    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'\n")

    var node = make_node(kind, line, column, parse_state)
    (@node).value.body = body
    return node
}

def parse_id_decl_enum(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var ident = expect_identifier(parse_state)
    var value: *Node = null
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::OP_ASSIGN {
        pop(parse_state)
        skip_newline(parse_state)
        value = expect_expression(parse_state)
    }

    var node = make_node(NodeKind::ID_DECL_ENUM, line, column, parse_state)
    (@node).value.id_decl_enum = {
        ident = ident,
        value = value
    } !NodeIdDeclEnum
    
    parse_t_term(parse_state)
    return node
}

def expect_enum(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_ENUM, "Expected enum\n")
    skip_newline(parse_state)

    token = peek(parse_state)
    var tpe: *Node = null
    if token.tpe == lexer::TokenType::COLON {
        pop(parse_state)
        skip_newline(parse_state)
        tpe = expect_type(parse_state)
    }

    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    skip_newline(parse_state)

    var body = vector::make()

    token = peek(parse_state)
    while token.tpe != lexer::TokenType::C_BRACE and
        token.tpe != lexer::TokenType::EOF {
        vector::push(body, parse_id_decl_enum(parse_state))
        skip_newline(parse_state)
        token = peek(parse_state)
    }

    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'\n")

    var node = make_node(NodeKind::ENUM_T, line, column, parse_state)
    (@node).value.t_enum = {
        tpe = tpe,
        body = body
    } !NodeEnumT
    return node
}

def parse_type2(parse_state: *ParseState) -> *Node {
    var tok = pop(parse_state)

    if tok.tpe == lexer::TokenType::O_PAREN {
        var node = expect_type(parse_state)
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
        return node
    } else if tok.tpe == lexer::TokenType::K_TYPE {
        var node = expect_type(parse_state)
        return node
    } else if tok.tpe == lexer::TokenType::K_WORD {
        expect(parse_state, lexer::TokenType::O_PAREN, "Expected '('\n")
        var n = expect(parse_state, lexer::TokenType::INTEGER, "Expected integer\n")
        if n.tpe != lexer::TokenType::INTEGER {
            return null
        }
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
        var node = make_node(NodeKind::WORD_T, tok.line, tok.column, parse_state)
        (@node).value.i = n.value.i

        return node
    } else if tok.tpe == lexer::TokenType::K_UNSIGNED {
        var node = make_node(NodeKind::UNSIGNED_T, tok.line, tok.column, parse_state)
        (@node).value.expr = expect_type(parse_state)

        return node
    } else if tok.tpe == lexer::TokenType::O_SQUARE {
        unget_token(parse_state, tok)
        return expect_array(parse_state)
    } else if tok.tpe == lexer::TokenType::OP_MUL or
        tok.tpe == lexer::TokenType::OP_BAND {
        unget_token(parse_state, tok)
        return expect_ptr_ref(parse_state, tok.tpe == lexer::TokenType::OP_BAND)
    } else if tok.tpe == lexer::TokenType::DOUBLE_COLON or
        tok.tpe == lexer::TokenType::IDENTIFIER {
        unget_token(parse_state, tok)
        var node = expect_identifier(parse_state)
        return node
    } else if tok.tpe == lexer::TokenType::K_STRUCT {
        unget_token(parse_state, tok)
        return expect_struct(parse_state)
    } else if tok.tpe == lexer::TokenType::K_ENUM {
        unget_token(parse_state, tok)
        return expect_enum(parse_state)
    } else {
        unget_token(parse_state, tok)
        return null
    }
}

def parse_type_list(parse_state: *ParseState, sw: bool) -> *vector::Vector {
    var token = peek(parse_state)
    var vec = vector::make()
    if token.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::C_PAREN {
            pop(parse_state)
            return vec
        }
        loop {
            let node = parse_type(parse_state)
            vector::push(vec, node)
            token = peek(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                continue
            }
            break
        }
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
    } else {
        var node: *Node = null
        if sw {
            node = parse_type(parse_state)
        } else {
            node = parse_type2(parse_state)
        }

        if node {
            vector::push(vec, node)
        }
    }
    return vec
}

// TODO Allow things like (A, B) -> (C, D) -> (E, F)
def parse_type(parse_state: *ParseState) -> *Node {
    let args = parse_type_list(parse_state, false)
    var token = peek(parse_state)
    if token.tpe == lexer::TokenType::ARROW {
        pop(parse_state)
        let ret = parse_type_list(parse_state, true)
        var node = make_node(NodeKind::FUNCTION_T, token.line, token.column, parse_state)
        (@node).value.t_func = {
            args = args,
            ret = ret
        } !NodeFunctionT
        return node
    } else if vector::length(args) > 1 {
        errort(token, parse_state, "Expected single type, got multiple\n")
        return null
    } else if vector::length(args) == 1 {
        return vector::get(args, 0) !*Node
    } else {
        return null
    }
}

def expect_type(parse_state: *ParseState) -> *Node {
    let token = peek(parse_state)
    let node = parse_type(parse_state)
    if not node {
       errort(token, parse_state, "Expected type\n") 
    }
    return node
}

def expect_array_lit(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column
    
    expect(parse_state, lexer::TokenType::O_SQUARE, "Expecting '['\n")
    var body = vector::make()
    skip_newline(parse_state)
    token = peek(parse_state)
    if token.tpe != lexer::TokenType::C_SQUARE {
        loop {
            var expr = expect_expression_no_assign(parse_state)
            vector::push(body, expr)
            skip_newline(parse_state)
            token = peek(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                continue
            } else {
                break
            }
        }
    }
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::C_SQUARE, "Expecting ']'\n")

    var node = make_node(NodeKind::ARRAY_LIT, line, column, parse_state)
    (@node).value.body = body

    return node
}

// TODO: Remove duplicated code, see expect_func_args
def expect_struct_lit(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::O_BRACE, "Expecting '{'\n")
    skip_newline(parse_state)
    token = peek(parse_state)

    var args = vector::make()
    while token.tpe != lexer::TokenType::C_BRACE and
        token.tpe != lexer::TokenType::EOF {
        
        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::IDENTIFIER {
            var tokens = @(@parse_state).tokens
            pop(parse_state)
            skip_newline(parse_state)
            if peek(parse_state).tpe == lexer::TokenType::OP_ASSIGN {
                @(@parse_state).tokens = tokens
                break // Start list of named arguments
            }
            @(@parse_state).tokens = tokens
        }

        vector::push(args, expect_expression_no_assign(parse_state))

        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_BRACE {
            if token.tpe != lexer::TokenType::COMMA {
                errort(token, parse_state, "Expected ','\n")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    var kwargs = vector::make()
    while token.tpe != lexer::TokenType::C_BRACE and
        token.tpe != lexer::TokenType::EOF {

        skip_newline(parse_state)
        token = peek(parse_state)
        let line = token.line
        let column = token.column

        let ident = expect_identifier(parse_state)
        skip_newline(parse_state)

        expect(parse_state, lexer::TokenType::OP_ASSIGN, "expected '='\n")
        skip_newline(parse_state)
        let expr = expect_expression_no_assign(parse_state)

        let named_arg = make_node(NodeKind::NAMED_ARG, line, column, parse_state)
        (@named_arg).value.named_arg = {
            name = ident,
            value = expr
        } !NodeNamedArg
        vector::push(kwargs, named_arg)

        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_BRACE {
            if token.tpe != lexer::TokenType::COMMA {
                errort(token, parse_state, "Expected ','\n")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    expect(parse_state, lexer::TokenType::C_BRACE, "Expecting '}'\n")

    var call = make_node(NodeKind::STRUCT_LIT, line, column, parse_state)
    (@call).value.struct_lit = {
        args = args,
        kwargs = kwargs
    } !NodeStructLit

    return call
}

def parse_term(parse_state: *ParseState) -> *Node {
    let token = pop(parse_state)
    var node = allocate(Node)
    
    if token.tpe == lexer::TokenType::O_PAREN {
        free(node)
        node = parse_expression(parse_state)
        expect(parse_state, lexer::TokenType::C_PAREN, "Expecting ')'\n")
        return node
    } else if token.tpe == lexer::TokenType::K_TYPE {
        free(node)
        skip_newline(parse_state)
        return expect_type(parse_state)
    } else if token.tpe == lexer::TokenType::K_DEFINED {
        skip_newline(parse_state)
        (@node).kind = NodeKind::DEFINED
        (@node).value.expr = expect_identifier(parse_state)
    } else if token.tpe == lexer::TokenType::INTEGER {
        (@node).kind = NodeKind::INTEGER
        (@node).value.i = token.value.i
    } else if token.tpe == lexer::TokenType::FLOAT {
        (@node).kind = NodeKind::FLOAT
        (@node).value.f = token.value.f
    } else if token.tpe == lexer::TokenType::IDENTIFIER or
        token.tpe == lexer::TokenType::DOUBLE_COLON {
        free(node)
        unget_token(parse_state, token)
        return expect_identifier(parse_state)
    } else if token.tpe == lexer::TokenType::STRING {
        (@node).kind = NodeKind::STRING
        (@node).value.str = token.value.str
    } else if token.tpe == lexer::TokenType::CHAR {
        (@node).kind = NodeKind::CHAR
        (@node).value.i = token.value.ch
    } else if token.tpe == lexer::TokenType::K_TRUE or
        token.tpe == lexer::TokenType::K_FALSE {
        
        var value = 0
        if token.tpe == lexer::TokenType::K_TRUE {
            value = 1
        }

        (@node).kind = NodeKind::BOOLEAN
        (@node).value.i = value
    } else if token.tpe == lexer::TokenType::K_NULL {
        (@node).kind = NodeKind::NULL
    } else if token.tpe == lexer::TokenType::O_SQUARE {
        free(node)
        unget_token(parse_state, token)
        return expect_array_lit(parse_state)
    } else if token.tpe == lexer::TokenType::O_BRACE {
        free(node)
        unget_token(parse_state, token)
        return expect_struct_lit(parse_state)
    } else {
        free(node)
        // errort(token, parse_state, "Expected literal or identifier\n")
        return null
    }

    let current_token = peek(parse_state)

    (@node).tpe = null
    (@node).scope = null
    (@node).loc = {
        (@parse_state).filename,
        (@parse_state).module,
        token.line,
        token.column,
        current_token.end_line,
        current_token.end_column,
        (@parse_state).lines
    } !SourceLoc
    return node
}

def expect_func_args(parse_state: *ParseState, node: *Node) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var args = vector::make()
    while token.tpe != lexer::TokenType::C_PAREN and
        token.tpe != lexer::TokenType::EOF {
        if token.tpe == lexer::TokenType::IDENTIFIER {
            token = pop(parse_state)
            if peek(parse_state).tpe == lexer::TokenType::OP_ASSIGN {
                unget_token(parse_state, token)
                break // Start list of named arguments
            }
            unget_token(parse_state, token)
        }

        vector::push(args, expect_expression_no_assign(parse_state))

        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_PAREN {
            if token.tpe != lexer::TokenType::COMMA {
                errort(token, parse_state, "Expected ','\n")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    var kwargs = vector::make()
    while token.tpe != lexer::TokenType::C_PAREN and
        token.tpe != lexer::TokenType::EOF {

        token = peek(parse_state)
        let line = token.line
        let column = token.column

        let ident = expect_identifier(parse_state)

        expect(parse_state, lexer::TokenType::OP_ASSIGN, "expected '='\n")
        let expr = expect_expression_no_assign(parse_state)

        let named_arg = make_node(NodeKind::NAMED_ARG, line, column, parse_state)
        (@named_arg).value.named_arg = {
            name = ident,
            value = expr
        } !NodeNamedArg
        vector::push(kwargs, named_arg)

        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_PAREN {
            if token.tpe != lexer::TokenType::COMMA {
                errort(token, parse_state, "Expected ','\n")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    var call = make_node(NodeKind::FUNC_CALL, line, column, parse_state)
    (@call).value.func_call = {
        left = node,
        args = args,
        kwargs = kwargs
    } !NodeFuncCall

    return call
}

def parse_post_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_term(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::O_PAREN) {
            node = expect_func_args(parse_state, node)
            expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
        } else if next_token(parse_state, lexer::TokenType::O_SQUARE) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::ARRAY_SUBSCRIPT, node, parse_expression(parse_state))
            skip_newline(parse_state)
            expect(parse_state, lexer::TokenType::C_SQUARE, "Expected ']'\n")
        } else if next_token(parse_state, lexer::TokenType::DOT) {
            node = make_bin_op(parse_state, token, NodeKind::MEMBER_ACCESS, node, expect_identifier(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_pre_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    if next_token(parse_state, lexer::TokenType::OP_ADD) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::UADD, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SUB) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::USUB, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_MUL) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::PTR, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_DEREF) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::DEREF, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_BNOT) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::BNOT, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::K_NOT) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::NOT, parse_pre_expression(parse_state))
    } else {
        return parse_post_expression(parse_state)
    }
}

def parse_cast_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)    
    var node = parse_pre_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_CAST) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::CAST, node, parse_type(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_bin_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)    
    var node = parse_cast_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_BAND) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::BAND, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BOR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::BOR, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BXOR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::BXOR, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHL) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::SHL, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::SHR, node, parse_cast_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_mul_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_bin_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_MUL) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::MUL, node, parse_bin_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DIV) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::DIV, node, parse_bin_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_MOD) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::MOD, node, parse_bin_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_add_expresson(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_mul_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_ADD) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::ADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SUB) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::SUB, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_INC) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::PADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DEC) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::PSUB, node, parse_mul_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_cmp_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_add_expresson(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_EQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::EQ, node, parse_add_expresson(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_NEQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::NEQ, node, parse_add_expresson(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_GEQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::GEQ, node, parse_add_expresson(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_LEQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::LEQ, node, parse_add_expresson(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_GT) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::GT, node, parse_add_expresson(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_LT) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::LT, node, parse_add_expresson(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_and_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_cmp_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::K_AND) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::AND, node, parse_cmp_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_or_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_and_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::K_OR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::OR, node, parse_and_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_range_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_or_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_RANGE) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::RANGE, node, parse_or_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_RANGE_INC) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::RANGE_INC, node, parse_or_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_assign_and_op(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var node = parse_range_expression(parse_state)
    if next_token(parse_state, lexer::TokenType::OP_PADD_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::PADD_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_PSUB_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::PSUB_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_ADD_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::ADD_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SUB_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::SUB_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_MUL_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::MUL_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_DIV_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::DIV_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_MOD_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::MOD_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_AND_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::AND_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_OR_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::OR_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_XOR_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::XOR_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SHL_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::SHL_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SHR_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::SHR_EQ, node, parse_assign_and_op(parse_state))
    }
    return node
}

def parse_size_of_align_of(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)

    if next_token(parse_state, lexer::TokenType::K_SIZE_OF) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::SIZE_OF, parse_size_of_align_of(parse_state))
    } else if next_token(parse_state, lexer::TokenType::K_ALIGN_OF) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::ALIGN_OF, parse_size_of_align_of(parse_state))
    } else {
        return parse_assign_and_op(parse_state)
    }
}


def parse_assign(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var node = parse_size_of_align_of(parse_state)
    var left = vector::make()
    var right = vector::make()

    vector::push(left, node)
    
    token = peek(parse_state)
    while token.tpe == lexer::TokenType::COMMA {
        pop(parse_state)
        skip_newline(parse_state)
        node = parse_size_of_align_of(parse_state)
        vector::push(left, node)
        token = peek(parse_state)
    }

    if token.tpe != lexer::TokenType::OP_ASSIGN {
        if vector::length(left) == 1 {
            return vector::get(left, 0) !*Node
        }
    } else {
        pop(parse_state)
        
        node = parse_assign(parse_state)
        if node and (@node).kind == NodeKind::ASSIGN and vector::length((@node).value.assign.right) == 0 {
            right = (@node).value.assign.left
        } else {
            vector::push(right, node)
            token = peek(parse_state)
            while token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                node = parse_assign(parse_state)
                vector::push(right, node)
                token = peek(parse_state)
            }
        }
    }
    
    var result = make_node(NodeKind::ASSIGN, line, column, parse_state)
    (@result).value.assign = {
        left = left,
        right = right
    } !NodeAssign

    return result
}

def parse_expression(parse_state: *ParseState) -> *Node {
    let node = parse_assign(parse_state)
    let token = peek(parse_state)
    if token.tpe == lexer::TokenType::K_IF {
        return expect_if_expr(parse_state, node)
    }
    return node
}

def expect_expression(parse_state: *ParseState) -> *Node {
    let node = parse_expression(parse_state)
    if not node {
        let token = peek(parse_state)
        errort(token, parse_state, "Expected expression\n")
    }
    return node
}

def parse_expression_no_assign(parse_state: *ParseState) -> *Node {
    let node = parse_size_of_align_of(parse_state)
    let token = peek(parse_state)
    if token.tpe == lexer::TokenType::K_IF {
        return expect_if_expr(parse_state, node)
    }
    return node
}

def expect_expression_no_assign(parse_state: *ParseState) -> *Node {
    let node = parse_expression_no_assign(parse_state)
    if not node {
        let token = peek(parse_state)
        errort(token, parse_state, "Expected expression\n")
    }
    return node
}

// TODO Make sure varargs can only be in the last position
def parse_def(parse_state: *ParseState, share: ShareMarker) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_DEF, "Expected def\n")
    skip_newline(parse_state)

    token = peek(parse_state)
    var extern = false
    while token.tpe == lexer::TokenType::PRAGMA {
        pop(parse_state)
        if token.value.str == "#extern" {
            extern = true
        } else {
            errort(token, parse_state, "Invalid pragma\n")
        }
        skip_newline(parse_state)
        token = peek(parse_state)
    }

    let name = expect_identifier(parse_state)
    //skip_newline(parse_state)
    var params = vector::make()
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_PAREN {
            var varargs = false
            var default = false

            loop {
                token = peek(parse_state)

                let line = token.line
                let column = token.column

                var kw = VarDecl::VAR
                var name: *Node = null
                var tpe: *Node = null
                var value: *Node = null

                if token.tpe == lexer::TokenType::OP_VARARGS {
                    if varargs {
                        errort(token, parse_state, "Only the last parameter is allowed to be varargs\n")
                    }
                    varargs = true
                    pop(parse_state)
                } else {
                    if token.tpe == lexer::TokenType::K_LET {
                        kw = VarDecl::LET
                        pop(parse_state)
                    } else if token.tpe == lexer::TokenType::K_VAR {
                        kw = VarDecl::VAR
                        pop(parse_state)
                    } else if token.tpe == lexer::TokenType::K_TYPE {
                        kw = VarDecl::TYPE
                        pop(parse_state)
                    }

                    skip_newline(parse_state)
                    name = expect_identifier(parse_state)
                    skip_newline(parse_state)
                    
                    token = peek(parse_state)
                    if token.tpe == lexer::TokenType::COLON {
                        pop(parse_state)
                        tpe = expect_type(parse_state)
                        token = peek(parse_state)
                        if token.tpe == lexer::TokenType::OP_VARARGS {
                            if varargs {
                                errort(token, parse_state, "Only the last parameter is allowed to be varargs\n")
                            }
                            varargs = true
                            pop(parse_state)
                        }
                    }
                    
                    skip_newline(parse_state)
                    token = peek(parse_state)
                    
                    if token.tpe == lexer::TokenType::OP_ASSIGN {
                        default = true
                        pop(parse_state)
                        if kw == VarDecl::TYPE {
                            value = expect_type(parse_state)
                        } else {
                            value = expect_expression_no_assign(parse_state)
                        }
                    } else {
                        if default {
                            errort(token, parse_state, "Argument needs to have a default value\n")
                        }
                    }
                }

                let param = make_node(NodeKind::PARAMETER, line, column, parse_state)
                (@param).value.param = {
                    varargs = varargs,
                    kw = kw,
                    name = name,
                    tpe = tpe,
                    value = value
                } !NodeParam

                vector::push(params, param)

                token = peek(parse_state)
                if token.tpe == lexer::TokenType::COMMA {
                    pop(parse_state)
                    continue
                } else {
                    expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
                    break
                }
            }
        } else {
            pop(parse_state)
        }     
    }

    var returns = vector::make()
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::ARROW {
        pop(parse_state)
        loop {
            let tpe = expect_type(parse_state)
            vector::push(returns, tpe)

            token = peek(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                continue
            } else {
                break
            }
        }
    }
    
    var body: *vector::Vector = null
    var tokens = @(@parse_state).tokens
    skip_newline(parse_state)
    token = peek(parse_state)
    if token.tpe != lexer::TokenType::O_BRACE {
        @(@parse_state).tokens = tokens
    } else {
        pop(parse_state)
        body = vector::make()
        parse_block(parse_state, body)
        expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'\n")
    }
    
    var node = make_node(NodeKind::DEF, line, column, parse_state)
    (@node).value.def_ = {
        extern = extern,
        share = share,
        name = name,
        params = params,
        returns = returns,
        body = body
    } !NodeDef
    node.body = body
    return node
}

def parse_vardecl(parse_state: *ParseState, share: ShareMarker, vardecl: VarDecl) -> *Node {
    var tok = pop(parse_state)
    let line = tok.line
    let column = tok.column

    if not (tok.tpe == lexer::TokenType::K_VAR or 
        tok.tpe == lexer::TokenType::K_CONST or 
        tok.tpe == lexer::TokenType::K_LET) {

        return null
    }
    skip_newline(parse_state)
    tok = peek(parse_state)

    var extern = false
    while tok.tpe == lexer::TokenType::PRAGMA {
        pop(parse_state)
        if tok.value.str == "#extern" {
            extern = true
        } else {
            errort(tok, parse_state, "Invalid pragma\n")
        }
        skip_newline(parse_state)
        tok = peek(parse_state)
    }

    var vec_left = vector::make()
    loop {
        tok = pop(parse_state)
        if tok.tpe == lexer::TokenType::O_PAREN {
            // Assignment
            let expr = expect_expression_no_assign(parse_state)
            expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'\n")
            var node = make_node(NodeKind::ID_ASSIGN, tok.line, tok.column, parse_state)
            (@node).value.expr = expr
            vector::push(vec_left, node)
        } else {
            // Id decl
            unget_token(parse_state, tok)
            var ident = expect_identifier(parse_state)

            tok = peek(parse_state)
            var tpe: *Node = null
            if tok.tpe == lexer::TokenType::COLON {
                // Type
                pop(parse_state)
                tpe = expect_type(parse_state)
            }
            var node = make_node(NodeKind::ID_DECL, tok.line, tok.column, parse_state)
            (@node).value.id_decl = {
                value = ident,
                tpe = tpe
            } !NodeIdDecl
            vector::push(vec_left, node)
        }
        tok = pop(parse_state)
        if tok.tpe == lexer::TokenType::COMMA {
            skip_newline(parse_state)
            continue
        } else if tok.tpe == lexer::TokenType::OP_ASSIGN or
            tok.tpe == lexer::TokenType::NEW_LINE or
            tok.tpe == lexer::TokenType::EOF {
            unget_token(parse_state, tok)
            break
        } else {
            errort(tok, parse_state, "Expected identifier, (expression) or '='\n")
            return null
        }
    }

    var vec_right = vector::make()
    if tok.tpe == lexer::TokenType::OP_ASSIGN {
        pop(parse_state)
        loop {
            var expr = expect_expression_no_assign(parse_state)
            vector::push(vec_right, expr)
            
            tok = pop(parse_state)
            if tok.tpe == lexer::TokenType::COMMA {
                skip_newline(parse_state)
                continue
            } else if tok.tpe == lexer::TokenType::NEW_LINE or
                tok.tpe == lexer::TokenType::EOF or
                tok.tpe == lexer::TokenType::SEMICOLON {
                unget_token(parse_state, tok)
                break
            }
        }
        //if vector::length(vec_left) != vector::length(vec_right) {
        //    errort(tok, parse_state, "Unbalanced assignment\n")
        //}
    } else if vardecl == VarDecl::LET or
        vardecl == VarDecl::CONST {
        errort(tok, parse_state, "Expected '='\n")
        return null
    }

    var node = make_node(NodeKind::VAR_DECL, line, column, parse_state)
    (@node).value.var_decl = {
        extern = extern,
        share = share,
        kw = vardecl,
        left = vec_left,
        right = vec_right
    } !NodeVarDecl

    return node
}

def parse_typedecl(parse_state: *ParseState, share: ShareMarker) -> *Node {
    var token = pop(parse_state)
    let line = token.line
    let column = token.column

    if token.tpe != lexer::TokenType::K_TYPE {
        return null
    }
    var vec_left = vector::make()
    loop {
        var ident = expect_identifier(parse_state)
        vector::push(vec_left, ident)

        token = pop(parse_state)
        if token.tpe == lexer::TokenType::COMMA {
            skip_newline(parse_state)
            continue
        } else if token.tpe == lexer::TokenType::OP_ASSIGN or
            token.tpe == lexer::TokenType::NEW_LINE or
            token.tpe == lexer::TokenType::EOF {
            unget_token(parse_state, token)
            break
        }
    }
    
    var vec_right = vector::make()
    if token.tpe == lexer::TokenType::OP_ASSIGN {
        pop(parse_state)
        loop {
            var tpe = expect_type(parse_state)
            vector::push(vec_right, tpe)

            token = pop(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                skip_newline(parse_state)
                continue
            } else if token.tpe == lexer::TokenType::NEW_LINE or
                token.tpe == lexer::TokenType::EOF {
                unget_token(parse_state, token)
                break
            }
        }
    }

    var node = make_node(NodeKind::TYPE_DECL, line, column, parse_state)
    (@node).value.type_decl = {
        share = share,
        left = vec_left,
        right = vec_right
    } !NodeTypeDecl

    return node
}

def expect_loop_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_LOOP, "Expected loop\n")
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'\n")
    var body = vector::make()
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'\n")

    var node = make_node(NodeKind::LOOP, line, column, parse_state)
    (@node).value.body = body
    node.body = body

    return node
}

def expect_while_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_WHILE, "Expected while\n")
    skip_newline(parse_state)
    let expr = expect_expression(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'\n")
    var body = vector::make()
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'\n")

    var node = make_node(NodeKind::WHILE, line, column, parse_state)
    (@node).value.while_loop = {
        expr = expr,
        body = body
    } !NodeWhile
    node.body = body

    return node
}

def expect_for_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_FOR, "Expected for\n")
    skip_newline(parse_state)

    var iddecl: *Node = null
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::K_VAR or
        token.tpe == lexer::TokenType::K_LET {
        
        var kw = VarDecl::VAR
        if token.tpe == lexer::TokenType::K_LET {
            kw = VarDecl::LET
        }

        pop(parse_state)
        let ident = expect_identifier(parse_state)
        iddecl = make_node(NodeKind::FOR_ID_DECL, token.line, token.column, parse_state)
        // TODO Have an optional type here
        (@iddecl).value.for_id_decl = {
            kw = kw,
            ident = ident
        } !NodeForIdDecl
    } else {
        iddecl = expect_identifier(parse_state)
    }

    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::K_IN, "Expected in\n")
    skip_newline(parse_state)
    var expr = expect_expression(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'\n")
    var body = vector::make()
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'\n")

    var node = make_node(NodeKind::FOR, line, column, parse_state)
    (@node).value.for_loop = {
        iddecl = iddecl,
        expr = expr,
        body = body
    } !NodeFor
    node.body = body

    return node
}

def expect_if_expr(parse_state: *ParseState, if_true: *Node) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_IF, "Expected if\n")
    let cond = expect_expression_no_assign(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::K_ELSE, "Expected else\n")
    skip_newline(parse_state)
    let if_false = expect_expression_no_assign(parse_state)

    var node = make_node(NodeKind::IF_EXPR, line, column, parse_state)
    (@node).value.if_expr = {
        cond = cond,
        if_true = if_true,
        if_false = if_false
    } !NodeIfExpr

    return node
}

def expect_if_stmt(parse_state: *ParseState, static_if: bool) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    if static_if {
        if not (token.tpe == lexer::TokenType::PRAGMA and token.value.str == "#if") {
            errort(token, parse_state, "Expected #if\n")
            return null
        }
        pop(parse_state)
    } else {
        expect(parse_state, lexer::TokenType::K_IF, "Expected if\n")
    }
    
    skip_newline(parse_state)
    let cond = expect_expression(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'\n")
    var body = vector::make()
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'\n")
    
    var tokens = @(@parse_state).tokens
    skip_newline(parse_state)

    var else_if = vector::make()
    var else_node: *Node = null

    token = peek(parse_state)
    if token.tpe != lexer::TokenType::K_ELSE {
        @(@parse_state).tokens = tokens
    }
    loop {
        if token.tpe == lexer::TokenType::K_ELSE {
            pop(parse_state)
            skip_newline(parse_state)
            token = peek(parse_state)
            if token.tpe == lexer::TokenType::K_IF {
                pop(parse_state)
                var cond = expect_expression(parse_state)
                
                skip_newline(parse_state)
                expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'\n")
                var body = vector::make()
                parse_block(parse_state, body)
                expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'\n")

                tokens = @(@parse_state).tokens
                skip_newline(parse_state)

                let elif_node = make_node(NodeKind::ELSE_IF, token.line, token.column, parse_state)
                (@elif_node).value.else_if = {
                    cond = cond,
                    body = body
                } !NodeElseIf
                elif_node.body = body

                vector::push(else_if, elif_node)

                token = peek(parse_state)
            
                if token.tpe != lexer::TokenType::K_ELSE {
                    @(@parse_state).tokens = tokens
                }
            } else {
                skip_newline(parse_state)

                expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'\n")
                var body = vector::make()
                parse_block(parse_state, body)
                expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'\n")

                else_node = make_node(NodeKind::ELSE, token.line, token.column, parse_state)
                (@else_node).value.body = body
                else_node.body = body
                    
                break
            }
        } else {
            break
        }
    }

    var node_kind = NodeKind::IF
    if static_if {
        node_kind = NodeKind::STATIC_IF
    }

    var node = make_node(node_kind, line, column, parse_state)
    (@node).value.if_ = {
        cond = cond,
        body = body,
        else_if = else_if,
        else_ = else_node
    } !NodeIf
    node.body = body

    return node
}

def expect_switch_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column   

    expect(parse_state, lexer::TokenType::K_SWITCH, "Expected switch\n")
    skip_newline(parse_state)
    let expr = expect_expression(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'\n")
    var body = vector::make()
    loop {
        skip_newline(parse_state)
        token = pop(parse_state)
        if token.tpe == lexer::TokenType::C_BRACE or
            token.tpe == lexer::TokenType::EOF {
            break        
        } else if token.tpe == lexer::TokenType::K_CASE {
            let line = token.line
            let column = token.column
            skip_newline(parse_state)

            var body2 = vector::make()
            var expr2 = vector::make()

            loop {
                token = peek(parse_state)
                if token.tpe == lexer::TokenType::COLON {
                    pop(parse_state)
                    break
                } else if token.tpe == lexer::TokenType::COMMA {
                    pop(parse_state)
                } else {
                    vector::push(expr2, expect_expression_no_assign(parse_state))
                }
                skip_newline(parse_state)
            }
            
            skip_newline(parse_state)
            token = peek(parse_state)
            while token.tpe != lexer::TokenType::K_CASE and
                token.tpe != lexer::TokenType::C_BRACE and
                token.tpe != lexer::TokenType::EOF {
                parse_block_stmt(parse_state, body2)
                token = peek(parse_state)
            }
            var node = make_node(NodeKind::CASE, line, column, parse_state)
            (@node).value.case_ = {
                expr = expr2,
                body = body2
            } !NodeCase
            node.body = body

            vector::push(body, node)
        } else {
            errort(token, parse_state, "Expected case\n")
        }
    }
    if token.tpe != lexer::TokenType::C_BRACE {
        errort(token, parse_state, "Expected '}'\n")
    }

    var node = make_node(NodeKind::SWITCH, line, column, parse_state)
    (@node).value.switch_ = {
        expr = expr,
        body = body
    } !NodeSwitch
    node.body = body

    return node
}

def expect_import_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var body = vector::make()
    expect(parse_state, lexer::TokenType::K_IMPORT, "Expected import\n")
    skip_newline(parse_state)

    loop {
        let line = token.line
        let column = token.column

        let name = expect_identifier(parse_state)
        token = peek(parse_state)
        var alias: *Node = null
        if token.tpe == lexer::TokenType::K_AS {
            pop(parse_state)
            alias = expect_identifier(parse_state) 
        }

        var module = make_node(NodeKind::IMPORT_MODULE, line, column, parse_state)
        (@module).value.import_module = {
            name = name,
            alias = alias
        } !NodeImportModule

        vector::push(body, module)

        token = peek(parse_state)
        if token.tpe == lexer::TokenType::COMMA {
            pop(parse_state)
            skip_newline(parse_state)
            continue
        } else {
            break
        }
    }

    var node = make_node(NodeKind::IMPORT, line, column, parse_state)
    (@node).value.body = body

    return node
}

def expect_return_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_RETURN, "Expected return\n")

    var body = vector::make()
    token = peek(parse_state)
    while token.tpe != lexer::TokenType::NEW_LINE and
        token.tpe != lexer::TokenType::EOF and
        token.tpe != lexer::TokenType::C_BRACE {

        vector::push(body, expect_expression_no_assign(parse_state))
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::COMMA {
            pop(parse_state)
            skip_newline(parse_state)
            continue
        } else {
            break
        }
    }

    var node = make_node(NodeKind::RETURN, line, column, parse_state)
    (@node).value.body = body
    
    return node
}

def parse_t_term(parse_state: *ParseState) {
    let token = peek(parse_state)
    if token.tpe == lexer::TokenType::SEMICOLON or token.tpe == lexer::TokenType::NEW_LINE {
        pop(parse_state)
    } else if token.tpe != lexer::TokenType::EOF and token.tpe != lexer::TokenType::C_BRACE {
        pop(parse_state)
        errort(token, parse_state, "Missing statement separator\n")
    }
}

def parse_statement2(parse_state: *ParseState, share: ShareMarker) -> *Node {
    let lh = peek(parse_state)
    var node: *Node = null
    if lh.tpe == lexer::TokenType::K_VAR {
        node = parse_vardecl(parse_state, share, VarDecl::VAR)
    } else if lh.tpe == lexer::TokenType::K_LET {
        node = parse_vardecl(parse_state, share, VarDecl::LET)
    } else if lh.tpe == lexer::TokenType::K_CONST {
        node = parse_vardecl(parse_state, share, VarDecl::CONST)
    } else if lh.tpe == lexer::TokenType::K_TYPE {
        node = parse_typedecl(parse_state, share)
    } else if lh.tpe == lexer::TokenType::K_DEF {
        node = parse_def(parse_state, share)
    }
    return node
}

def expect_defer_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_DEFER, "Expected defer\n")
    skip_newline(parse_state)
    token = peek(parse_state)
    let body = vector::make()
    if token.tpe == lexer::TokenType::O_BRACE {
        // Multiline defer
        pop(parse_state)
        parse_block(parse_state, body)
        expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'\n")
    } else {
        // Single line defer
        let expr = expect_expression(parse_state)
        vector::push(body, expr)
    }
    let node = make_node(NodeKind::DEFER, line, column, parse_state)
    node.value.body = body
    node.body = body
    return node
}

def parse_statement(parse_state: *ParseState) -> *Node {
    let lh = peek(parse_state)
    var node: *Node = null
    if lh.tpe == lexer::TokenType::K_IMPORT {
        let share = ShareMarker::IMPORT
        let tok = pop(parse_state)
        node = parse_statement2(parse_state, share)
        if not node {
            unget_token(parse_state, tok)
            node = expect_import_stmt(parse_state)
        }
    } else if lh.tpe == lexer::TokenType::K_EXPORT {
        var share = ShareMarker::EXPORT
        pop(parse_state)
        let lh = peek(parse_state)
        if lh.tpe == lexer::TokenType::K_IMPORT {
            share = ShareMarker::BOTH
            pop(parse_state)
        }
        node = parse_statement2(parse_state, share)
        if not node {
            errort(peek(parse_state), parse_state, "Expected def, type, var, let, const\n")
            return null
        }
    } else if lh.tpe == lexer::TokenType::K_IF {
        node = expect_if_stmt(parse_state, false)
    } else if lh.tpe == lexer::TokenType::PRAGMA and lh.value.str == "#if" {
        node = expect_if_stmt(parse_state, true)
    } else if lh.tpe == lexer::TokenType::K_SWITCH {
        node = expect_switch_stmt(parse_state)  
    } else if lh.tpe == lexer::TokenType::K_LOOP {
        node = expect_loop_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_FOR {
        node = expect_for_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_WHILE {
        node = expect_while_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_RETURN {
        node = expect_return_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_DEFER {
        node = expect_defer_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_BREAK {
        pop(parse_state)
        node = make_node(NodeKind::BREAK, lh.line, lh.column, parse_state)
    } else if lh.tpe == lexer::TokenType::K_CONTINUE {
        pop(parse_state)
        node = make_node(NodeKind::CONTINUE, lh.line, lh.column, parse_state)
    } else if lh.tpe == lexer::TokenType::PRAGMA and lh.value.str == "#error" {
        pop(parse_state)
        node = make_un_op(parse_state, lh, NodeKind::ERROR, expect_expression(parse_state))
    } else {
        node = parse_statement2(parse_state, ShareMarker::NONE)
        if not node {
            node = parse_expression(parse_state)
        }
    }
    parse_t_term(parse_state)
    return node
}

def parse_block_stmt(parse_state: *ParseState, vec: *vector::Vector) {
    let node = parse_statement(parse_state)
    (@parse_state).has_error = false
    if not node {
        // We encountered an error, skip to the next newline
        var lh = peek(parse_state)
        while lh.tpe != lexer::TokenType::NEW_LINE and 
            lh.tpe != lexer::TokenType::EOF and
            lh.tpe != lexer::TokenType::C_BRACE {

            lh = pop(parse_state)
        }
    } else {
        vector::push(vec, node)
    }
}

def parse_block(parse_state: *ParseState, vec: *vector::Vector) {
    skip_newline(parse_state)
    var token = peek(parse_state)
    while token.tpe != lexer::TokenType::EOF and
        token.tpe != lexer::TokenType::C_BRACE {
        parse_block_stmt(parse_state, vec)
        skip_newline(parse_state)
        token = peek(parse_state)
    }
}

export var time_spent: int64 = 0

export def parse(list: *lexer::TokenList, lines: [string], filename: string, module: string) -> *Node {
    let start = util::millis()

    var parse_state: ParseState
    parse_state.filename = filename
    parse_state.module = module
    parse_state.lines = lines
    parse_state.tokens = *list
    
    var vec = vector::make()
    parse_block(*parse_state, vec)
    var token = peek(*parse_state)
    if token.tpe != lexer::TokenType::EOF {
        errort(token, *parse_state, "Unexpected closing '}'\n")
    }

    let program_node = make_node(NodeKind::PROGRAM, 0, 0, *parse_state)
    (@program_node).value.body = vec
    program_node.body = vec

    let end = util::millis()
    time_spent += end - start
    return program_node
}

// TODO: Make this function variadic
def errort(token: lexer::Token, state: *ParseState, msg: string) {
    if not (@state).has_error {
        let filename = (@state).filename
        let line = token.line
        let column = token.column
        let end_line = token.end_line
        var end_column = token.end_column
        let str = (@state).lines[line]

        error("\n")
        error(filename, "@", line + 1, ":", column + 1, "\n")
        error(str, "\n")
        for var i in 0..column {
            error(" ")
        }
        error("^")
        if end_line > line {
            end_column = length(str) !int - 1
        }
        for var i in 0..(end_column - column - 1) {
            error("~")
        }
        error("\n")
        error(msg)
        (@state).has_error = true

        toolchain::error_count += 1
    }
}