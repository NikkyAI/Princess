import lexer
import vector
import map
import util
import buffer
import toolchain
import typechecking
import scope
import errors
import debug

export type NodeKind = enum {
    PROGRAM
    INTEGER
    CHAR
    STRING
    FLOAT
    BOOLEAN
    IDENTIFIER
    ERROR
    DEFINED
    NULL
    UNDEF
    RANGE
    RANGE_INC
    ARRAY_LIT
    STRUCT_LIT
    MEMBER_ACCESS
    CAST
    SIZE_OF
    ALIGN_OF
    DEFER
    ASSERT
    ADD
    SUB
    MUL
    DIV
    MOD
    AND
    OR
    UADD
    USUB
    PTR
    DEREF
    BNOT
    NOT
    BAND
    BOR
    BXOR
    SHL
    SHR
    PADD
    PSUB
    EQ
    NEQ
    GT
    LT
    GEQ
    LEQ
    PADD_EQ
    PSUB_EQ
    ADD_EQ
    SUB_EQ
    MUL_EQ
    DIV_EQ
    MOD_EQ
    AND_EQ
    OR_EQ
    XOR_EQ
    SHL_EQ
    SHR_EQ
    IMPORT
    IMPORT_MODULE
    ASSIGN
    DEF
    PARAMETER
    SWITCH
    CASE
    IF
    IF_EXPR
    STATIC_IF
    ELSE_IF
    ELSE
    LOOP
    WHILE
    FOR
    FOR_ID_DECL
    BREAK
    CONTINUE
    RETURN
    ARRAY_SUBSCRIPT
    FUNC_CALL
    TYPE_DECL
    VAR_DECL
    ID_DECL
    ID_ASSIGN
    NAMED_ARG
    ID_DECL_STRUCT
    ID_DECL_ENUM
    ENUM_T
    STRUCT_T
    UNION_T
    FUNCTION_T
    UNSIGNED_T
    WORD_T
    PTR_T
    REF_T
    WEAK_REF_T
    ARRAY_T
    ARRAY_STATIC_T
    TYPE_T
    TYPE_OF_T
    STRUCTURAL_T
    STRUCTURAL_T_MEMBER
    TYPE_CONSTRUCTOR
}

export type ShareMarker = enum {
    NONE = 0
    EXPORT = 1
    IMPORT = 2
    BOTH = 3
}

export type VarDecl = enum {
    VAR
    LET
    CONST
    TYPE
}

// TODO Use flags for the boolean values
export type NodeDef = struct {
    dllimport: bool
    extern: bool
    share: ShareMarker
    name: *Node
    params: *vector::Vector
    returns: *vector::Vector
    body: *vector::Vector
    has_lookup: bool
    // Map of typechecking::Type
    locals: *map::Map
    has_defer: bool
}

export type NodeParam = struct {
    varargs: bool
    kw: VarDecl
    name: *Node
    tpe: *Node
    value: *Node
}

export type NodeImportModule = struct {
    name: *Node
    alias: *Node
}

export type NodeSwitch = struct {
    expr: *Node
    body: *vector::Vector
}

export type NodeCase = struct {
    expr: *vector::Vector
    body: *vector::Vector
}

export type NodeIf = struct {
    cond: *Node
    body: *vector::Vector
    else_if: *vector::Vector
    else_: *Node
}

export type NodeElseIf = struct {
    cond: *Node
    body: *vector::Vector
}

export type NodeArrayStaticT = struct {
    n: *Node
    kw: VarDecl
    tpe: *Node
}

export type NodePtrArrayT = struct {
    kw: VarDecl
    tpe: *Node
}

export type NodeFunctionT = struct {
    args: *vector::Vector
    ret: *vector::Vector
}

export type NodeIdDecl = struct {
    value: *Node
    tpe: *Node
}

export type NodeVarDecl = struct {
    extern: bool
    dllimport: bool
    share: ShareMarker
    kw: VarDecl
    left: *vector::Vector
    right: *vector::Vector
}

export type NodeTypeConstructor = struct {
    name: *Node
    args: *vector::Vector
}

export type NodeTypeDecl = struct {
    share: ShareMarker
    left: *vector::Vector
    right: *vector::Vector
}

export type NodeNamedArg = struct {
    name: *Node
    value: *Node
}

export type NodeFuncCall = struct {
    left: *Node
    args: *vector::Vector
    kwargs: *vector::Vector
}

export type NodeStructLit = struct {
    args: *vector::Vector
    kwargs: *vector::Vector
}

export type NodeBinaryOp = struct {
    left: *Node
    right: *Node
}

export type NodeAssign = struct {
    left: *vector::Vector
    right: *vector::Vector
}

export type NodeForIdDecl = struct {
    kw: VarDecl
    ident: *Node
}

export type NodeFor = struct {
    iddecl: *Node
    expr: *Node
    body: *vector::Vector
}

export type NodeWhile = struct {
    expr: *Node
    body: *vector::Vector
}

export type NodeIdDeclStruct = struct {
    ident: *Node
    tpe: *Node
    is_bitfield: bool
    bit_size: size_t
}

export type NodeEnumT = struct {
    tpe: *Node
    body: *vector::Vector
}

export type NodeIdDeclEnum = struct {
    ident: *Node
    value: *Node
}

export type NodeIfExpr = struct {
    cond: *Node
    if_true: *Node
    if_false: *Node
}

export type NodeIdentifier = struct {
    path: *vector::Vector
    args: *vector::Vector
    // Vector of typechecking::NamedParameter
    types: *vector::Vector
}

export type NodeAssert = struct {
    cond: *Node
    message: *Node
}

export type NodeStructuralMember = struct {
    name: *Node
    params: *vector::Vector
    returns: *vector::Vector
}

export type NodeProgram = struct {
    // Map of typechecking::Type
    locals: *map::Map
    has_defer: bool
}

export type NodeValue = struct #union {
    bin_op: NodeBinaryOp
    var_decl: NodeVarDecl
    type_decl: NodeTypeDecl
    id_decl: NodeIdDecl
    id_decl_struct: NodeIdDeclStruct
    id_decl_enum: NodeIdDeclEnum
    named_arg: NodeNamedArg
    struct_lit: NodeStructLit
    t_enum: NodeEnumT
    t_func: NodeFunctionT
    t_parr: NodePtrArrayT
    t_arrs: NodeArrayStaticT
    structural_member: NodeStructuralMember
    func_call: NodeFuncCall
    assign: NodeAssign
    if_expr: NodeIfExpr
    if_: NodeIf
    else_if: NodeElseIf
    switch_: NodeSwitch
    case_: NodeCase
    while_loop: NodeWhile
    for_loop: NodeFor
    for_id_decl: NodeForIdDecl
    import_module: NodeImportModule
    def_: NodeDef
    param: NodeParam
    identifier: NodeIdentifier
    assert_: NodeAssert
    program: NodeProgram
    type_constructor: NodeTypeConstructor

    body: *vector::Vector
    expr: *Node
    i: uint64
    str: string
    f: double
}

export type SourceLoc = struct {
    filename: string
    module: string
    line: int
    column: int
    end_line: int
    end_column: int
    lines: [string]
}

export type Node = struct {
    kind: NodeKind

    loc: SourceLoc

    tpe: *typechecking::Type
    // This is for passing on a function from typechecking to the compiler
    // TODO There might be better ways of doing this
    function: *typechecking::Type
    svalue: *scope::Value
    scope: *scope::Scope
    // For things like if statements or functions
    inner_scope: *scope::Scope
    value: NodeValue
    parent: *Node

    // Set to prevent destructors being called on uninitalized values
    is_initializer: bool

    // This is so that we have a consistent layout, this refers to the
    // actual data in value
    // TODO remove body from the NodeValue union
    body: *vector::Vector
    // This is used by assignment to track let
    kw: VarDecl
    module: *toolchain::Module
    is_recursive_type: bool
}

export type ParseState = struct {
    filename: string
    module: string
    has_error: bool
    lines: [string]
    tokens: **lexer::TokenList
}

export def make_identifier(s: [string]) -> *Node {
    let vec = vector::make()
    for var i in 0..s.size {
        vector::push(vec, util::copy_string(s[i]))
    }

    let node = allocate(Node)
    @node = {
        kind = NodeKind::IDENTIFIER,
        loc = {
            filename = "builtins",
            module = "",
            line = -1,
            column = -1            
        } !SourceLoc
    } !Node
    node.value.identifier.path = vec
    return node
}

// This copies a node, all the contents are the same
export def copy_node(node: *Node) -> *Node {
    let copy = allocate(Node)
    @copy = @node
    return copy
}

def deep_copy_vector_of_nodes(v: *vector::Vector) -> *vector::Vector {
    if not v { return null }
    let copy = vector::make()
    for var i in 0..vector::length(v) {
        var node = vector::get(v, i) !*Node
        node = deep_copy_node(node)
        vector::push(copy, node)
    }
    return copy
}

export def deep_copy_node(node: *Node) -> *Node {
    if not node { return null }
    let copy = allocate(Node)
    @copy = @node
    copy.tpe = typechecking::copy(node.tpe)

    switch node.kind {
        case NodeKind::PROGRAM, NodeKind::LOOP, NodeKind::ELSE, NodeKind::DEFER:
            copy.value.body = deep_copy_vector_of_nodes(node.value.body)
            copy.body = copy.value.body
        case NodeKind::RETURN, NodeKind::IMPORT, NodeKind::ARRAY_LIT,
            NodeKind::STRUCT_T, NodeKind::UNION_T, NodeKind::STRUCTURAL_T:
            copy.value.body = deep_copy_vector_of_nodes(node.value.body)
        case NodeKind::ASSERT:
            copy.value.assert_.cond = deep_copy_node(node.value.assert_.cond)
            copy.value.assert_.message = deep_copy_node(node.value.assert_.message)
        case NodeKind::IF, NodeKind::STATIC_IF:
            copy.value.if_.cond = deep_copy_node(node.value.if_.cond)
            copy.value.if_.else_if = deep_copy_vector_of_nodes(node.value.if_.else_if)
            copy.value.if_.else_ = deep_copy_node(node.value.if_.else_)
            copy.value.if_.body = deep_copy_vector_of_nodes(node.value.if_.body)
            copy.body = copy.value.if_.body
        case NodeKind::ELSE_IF:
            copy.value.else_if.cond = deep_copy_node(node.value.else_if.cond)
            copy.value.else_if.body = deep_copy_vector_of_nodes(node.value.else_if.body)
            copy.body = copy.value.else_if.body
        case NodeKind::IF_EXPR:
            copy.value.if_expr.cond = deep_copy_node(node.value.if_expr.cond)
            copy.value.if_expr.if_true = deep_copy_node(node.value.if_expr.if_true)
            copy.value.if_expr.if_false = deep_copy_node(node.value.if_expr.if_false)
        case NodeKind::WHILE:
            copy.value.while_loop.expr = deep_copy_node(node.value.while_loop.expr)
            copy.value.while_loop.body = deep_copy_vector_of_nodes(node.value.while_loop.body)
            copy.body = copy.value.while_loop.body
        case NodeKind::FOR:
            copy.value.for_loop.iddecl = deep_copy_node(node.value.for_loop.iddecl)
            copy.value.for_loop.expr = deep_copy_node(node.value.for_loop.expr)
            copy.value.for_loop.body = deep_copy_vector_of_nodes(node.value.for_loop.body)
            copy.body = copy.value.while_loop.body
        case NodeKind::FOR_ID_DECL:
            copy.value.for_id_decl.ident = deep_copy_node(node.value.for_id_decl.ident)
        case NodeKind::DEF:
            copy.value.def_.params = deep_copy_vector_of_nodes(node.value.def_.params)
            copy.value.def_.returns = deep_copy_vector_of_nodes(node.value.def_.returns)
            copy.value.def_.body = deep_copy_vector_of_nodes(node.value.def_.body)
            copy.body = copy.value.def_.body
        case NodeKind::CASE:
            copy.value.case_.expr = deep_copy_vector_of_nodes(node.value.case_.expr)
            copy.value.case_.body = deep_copy_vector_of_nodes(node.value.case_.body)
            copy.body = copy.value.case_.body
        case NodeKind::SWITCH:
            copy.value.switch_.expr = deep_copy_node(node.value.switch_.expr)
            copy.value.switch_.body = deep_copy_vector_of_nodes(node.value.switch_.body)
            copy.body = copy.value.switch_.body
        case NodeKind::STRING:
            copy.value.str = @util::copy_string(node.value.str)
        case NodeKind::IDENTIFIER:
            // TODO This is not actually a deep copy
            copy.value.identifier.path = vector::copy(node.value.identifier.path)
            copy.value.identifier.args = deep_copy_vector_of_nodes(node.value.identifier.args)
        case NodeKind::STRUCT_LIT:
            copy.value.struct_lit.args = deep_copy_vector_of_nodes(node.value.struct_lit.args)
            copy.value.struct_lit.kwargs = deep_copy_vector_of_nodes(node.value.struct_lit.kwargs)
        case NodeKind::IMPORT_MODULE:
            copy.value.import_module.name = deep_copy_node(node.value.import_module.name)
            copy.value.import_module.alias = deep_copy_node(node.value.import_module.alias)
        case NodeKind::ASSIGN:
            copy.value.assign.left = deep_copy_vector_of_nodes(node.value.assign.left)
            copy.value.assign.right = deep_copy_vector_of_nodes(node.value.assign.right)
        case NodeKind::PARAMETER:
            copy.value.param.name = deep_copy_node(node.value.param.name)
            copy.value.param.tpe = deep_copy_node(node.value.param.tpe)
            copy.value.param.value = deep_copy_node(node.value.param.value)
        case NodeKind::FUNC_CALL:
            copy.value.func_call.left = deep_copy_node(node.value.func_call.left)
            copy.value.func_call.args = deep_copy_vector_of_nodes(node.value.func_call.args)
            copy.value.func_call.kwargs = deep_copy_vector_of_nodes(node.value.func_call.kwargs)
        case NodeKind::TYPE_DECL:
            copy.value.type_decl.left = deep_copy_vector_of_nodes(node.value.type_decl.left)
            copy.value.type_decl.right = deep_copy_vector_of_nodes(node.value.type_decl.right)
        case NodeKind::VAR_DECL:
            copy.value.var_decl.left = deep_copy_vector_of_nodes(node.value.var_decl.left)
            copy.value.var_decl.right = deep_copy_vector_of_nodes(node.value.var_decl.right)
        case NodeKind::ID_DECL:
            copy.value.id_decl.value = deep_copy_node(node.value.id_decl.value)
            copy.value.id_decl.tpe = deep_copy_node(node.value.id_decl.tpe)
        case NodeKind::NAMED_ARG:
            copy.value.named_arg.name = deep_copy_node(node.value.named_arg.name)
            copy.value.named_arg.value = deep_copy_node(node.value.named_arg.value)
        case NodeKind::ID_DECL_STRUCT:
            copy.value.id_decl_struct.ident = deep_copy_node(node.value.id_decl_struct.ident)
            copy.value.id_decl_struct.tpe = deep_copy_node(node.value.id_decl_struct.tpe)
        case NodeKind::ID_DECL_ENUM:
            copy.value.id_decl_enum.ident = deep_copy_node(node.value.id_decl_enum.ident)
            copy.value.id_decl_enum.value = deep_copy_node(node.value.id_decl_enum.value)
        case NodeKind::ENUM_T:
            copy.value.t_enum.tpe = deep_copy_node(node.value.t_enum.tpe)
            copy.value.t_enum.body = deep_copy_vector_of_nodes(node.value.t_enum.body)
        case NodeKind::FUNCTION_T:
            copy.value.t_func.args = deep_copy_vector_of_nodes(node.value.t_func.args)
            copy.value.t_func.ret = deep_copy_vector_of_nodes(node.value.t_func.ret)
        case NodeKind::REF_T, NodeKind::PTR_T, NodeKind::ARRAY_T, NodeKind::WEAK_REF_T:
            copy.value.t_parr.tpe = deep_copy_node(node.value.t_parr.tpe)
        case NodeKind::ARRAY_STATIC_T:
            copy.value.t_arrs.tpe = deep_copy_node(node.value.t_arrs.tpe)
        case NodeKind::STRUCTURAL_T_MEMBER:
            copy.value.structural_member.name = deep_copy_node(node.value.structural_member.name)
            copy.value.structural_member.params = deep_copy_vector_of_nodes(node.value.structural_member.params)
            copy.value.structural_member.returns = deep_copy_vector_of_nodes(node.value.structural_member.returns)
        case NodeKind::ERROR, NodeKind::DEFINED, NodeKind::SIZE_OF, NodeKind::ALIGN_OF, NodeKind::TYPE_OF_T,
            NodeKind::UADD..=NodeKind::NOT, NodeKind::ID_ASSIGN, NodeKind::UNSIGNED_T, NodeKind::TYPE_T:
            // Unary op
            copy.value.expr = deep_copy_node(node.value.expr)
        case NodeKind::RANGE, NodeKind::RANGE_INC, NodeKind::MEMBER_ACCESS,
            NodeKind::CAST, NodeKind::ADD..=NodeKind::OR,
            NodeKind::BAND..=NodeKind::SHR_EQ, NodeKind::ARRAY_SUBSCRIPT:
            // Binary op
            copy.value.bin_op.left = deep_copy_node(node.value.bin_op.left)
            copy.value.bin_op.right = deep_copy_node(node.value.bin_op.right)
        case NodeKind::TYPE_CONSTRUCTOR:
            copy.value.type_constructor.name = deep_copy_node(node.value.type_constructor.name)
            copy.value.type_constructor.args = deep_copy_vector_of_nodes(node.value.type_constructor.args)
        case NodeKind::INTEGER, NodeKind::CHAR, NodeKind::FLOAT,
            NodeKind::BOOLEAN, NodeKind::NULL, NodeKind::UNDEF, NodeKind::BREAK, NodeKind::CONTINUE,
            NodeKind::WORD_T:
        case:
            error(node.kind, "\n")
            assert(false)
    }

    return copy
}

export def identifier_to_str(node: *Node, types: bool) -> string {
    assert((@node).kind == NodeKind::IDENTIFIER)
    let buf = buffer::make_buffer()
    let len = vector::length((@node).value.identifier.path)
    for var i in 0..len {
        buffer::append_str(*buf, @(vector::get((@node).value.identifier.path, i) !*string))
        if i < len - 1 {
            buffer::append_str(*buf, "::")
        }
    }
    if types and node.value.identifier.types {
        let len = vector::length(node.value.identifier.types)
        buffer::append_str(*buf, "::")
        if len > 0 {
            buffer::append_char(*buf, '(')
            for var i in 0..len {
                let np = vector::get(node.value.identifier.types, i) !*typechecking::NamedParameter
                buffer::append_str(*buf, debug::type_to_str(np.tpe))
                if i < len - 1 {
                    buffer::append_str(*buf, ", ")
                }
            }
            buffer::append_char(*buf, ')')
        }
    }

    return buffer::to_string(*buf)
}

export def identifier_to_str(node: *Node) -> string {
    return identifier_to_str(node, true)
}

def make_node(kind: NodeKind, line: int, column: int, state: *ParseState) -> *Node {
    let current_token = peek(state)
    var node = allocate(Node)
    @node = {
        kind = kind,
        loc = {
            (@state).filename,
            (@state).module,
            line,
            column,
            current_token.line,
            current_token.column,
            (@state).lines
        } !SourceLoc
    }
    return node
}

def make_bin_op(state: *ParseState, token: lexer::Token, kind: NodeKind, left: *Node, right: *Node) -> *Node {
    var node = make_node(kind, token.line, token.column, state)
    (@node).value.bin_op = {
        left, right
    } !NodeBinaryOp

    return node
}

def make_un_op(state: *ParseState, token: lexer::Token, kind: NodeKind, right: *Node) -> *Node {
    var node = make_node(kind, token.line, token.column, state)
    (@node).value.expr = right

    return node
}

def skip_whitespace(state: *ParseState) {
    var list = (@state).tokens
    if not @list { return }
    var tt = (@@list).value.tpe
    while tt == lexer::TokenType::WHITESPACE or 
        tt == lexer::TokenType::COMMENT or
        tt == lexer::TokenType::ERROR {

        if tt == lexer::TokenType::ERROR {
            let token = (@@list).value
            errors::errort(token, state, token.value.str)
        }

        @list = (@@list).next
        tt = (@@list).value.tpe
    }
}

def pop(state: *ParseState) -> lexer::Token {
    skip_whitespace(state)
    let list = (@state).tokens
    if not @list {
        return {
            lexer::TokenType::EOF
        } !lexer::Token
    }
    let token = (@@list).value
    @list = (@@list).next
    return token
}

def peek(state: *ParseState) -> lexer::Token {
    skip_whitespace(state)
    let list = (@state).tokens
    if not @list {
        return {
            lexer::TokenType::EOF
        } !lexer::Token
    }
    return (@@list).value
}

def unget_token(state: *ParseState, token: lexer::Token) {
    let list = (@state).tokens
    let prev = @list
    @list = allocate(lexer::TokenList)
    (@@list).value = token
    (@@list).next = prev
}

def expect(state: *ParseState, tpe: lexer::TokenType, msg: string) -> lexer::Token {
    let token = pop(state)
    if token.tpe != tpe {
        errors::errort(token, state, msg)
    }
    return token
}

def skip_newline(state: *ParseState) {
    loop {
        let token = peek(state)
        if token.tpe == lexer::TokenType::NEW_LINE {
            pop(state)
            continue
        }
        break
    }
}

def next_token(state: *ParseState, tpe: lexer::TokenType) -> bool {
    let token = peek(state)
    if token.tpe == tpe {
        pop(state)
        return true
    }
    return false
}

def expect_identifier(parse_state: *ParseState) -> *Node {
    var token = pop(parse_state)
    let line = token.line
    let column = token.column
    
    let path = vector::make()
    loop {
        vector::push(path, util::copy_string(token.value.str))
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::DOUBLE_COLON {
            token = pop(parse_state)
            var ident = peek(parse_state)
            if ident.tpe == lexer::TokenType::IDENTIFIER {
                token = pop(parse_state)
                continue
            } else {
                unget_token(parse_state, token)
            }
        }
        break
    }

    if vector::length(path) == 0 {
        errors::errort(token, parse_state, "Expected identifier")
        return null
    }

    var args: *vector::Vector = null
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::DOUBLE_COLON {
        pop(parse_state)
        args = vector::make()
        // We have a function reference
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::O_PAREN {
            pop(parse_state)
            token = peek(parse_state)
            while token.tpe != lexer::TokenType::C_PAREN and 
                token.tpe != lexer::TokenType::EOF {
                let expr = expect_type(parse_state)
                vector::push(args, expr)
                token = peek(parse_state)
                if token.tpe == lexer::TokenType::COMMA {
                    pop(parse_state)
                    token = peek(parse_state)
                    continue
                }
                break
            }
            expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
        }
    }

    var node = make_node(NodeKind::IDENTIFIER, line, column, parse_state)
    node.value.identifier.path = path
    node.value.identifier.args = args

    return node
}

def parse_array_n(parse_state: *ParseState) -> *Node {
    var tok = peek(parse_state)
    let line = tok.line
    let column = tok.column

    if tok.tpe != lexer::TokenType::O_SQUARE {
        return null
    }
    pop(parse_state)
    tok = peek(parse_state)

    var n: *Node = null
    if tok.tpe == lexer::TokenType::QUESTION_MARK {
        pop(parse_state)
    } else {
        n = parse_expression(parse_state)
        if not n {
            return null
        }
    }

    tok = pop(parse_state)
    if tok.tpe != lexer::TokenType::SEMICOLON {
        return null
    }

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
    }
    let tpe = parse_type(parse_state)
    if not tpe {
        return null
    }

    tok = peek(parse_state)
    if tok.tpe != lexer::TokenType::C_SQUARE {
        return null
    }
    pop(parse_state)

    var node = make_node(NodeKind::ARRAY_STATIC_T, line, column, parse_state)
    (@node).value.t_arrs = {
        n = n,
        kw = kw,
        tpe = tpe
    } !NodeArrayStaticT

    return node
}

def expect_array(parse_state: *ParseState) -> *Node {
    var tok = peek(parse_state)
    let line = tok.line
    let column = tok.column

    // [N; let T], [N; var T] and [N; T]
    var tokens = @(@parse_state).tokens
    var node = parse_array_n(parse_state)
    if node {
        return node
    }
    @(@parse_state).tokens = tokens

    tok = expect(parse_state, lexer::TokenType::O_SQUARE, "Expected '['")

    // [let T], [var T] and [T]

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
    }

    let tpe = expect_type(parse_state)

    tok = expect(parse_state, lexer::TokenType::C_SQUARE, "Expected ']'")

    node = make_node(NodeKind::ARRAY_T, line, column, parse_state)
    (@node).value.t_parr = {
        kw = kw,
        tpe = tpe
    } !NodePtrArrayT

    
    return node
}

def expect_weak_ref(parse_state: *ParseState, inline_types: bool) -> *Node {
    var tok = expect(parse_state, lexer::TokenType::K_WEAK_REF, "Expected weak_ref")

    let line = tok.line
    let column = tok.column

    var tpe: *Node = null
    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        skip_newline(parse_state)
        tok = peek(parse_state)
        if tok.tpe == lexer::TokenType::K_VAR {
            pop(parse_state)
            skip_newline(parse_state)
        } else if tok.tpe == lexer::TokenType::K_LET {
            pop(parse_state)
            kw = VarDecl::LET
            skip_newline(parse_state)
        }

        var tokens = @(@parse_state).tokens
        tpe = parse_type(parse_state, inline_types)
        if not tpe {
            @(@parse_state).tokens = tokens
        }
        
        skip_newline(parse_state)
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
    }

    var node = make_node(NodeKind::WEAK_REF_T, line, column, parse_state)
    node.value.t_parr = {
        kw = kw,
        tpe = tpe
    } !NodePtrArrayT

    return node
}

def expect_ptr_ref(parse_state: *ParseState, ref: bool, inline_types: bool) -> *Node {
    var kind: NodeKind
    var tok: lexer::Token
    if ref {
        kind = NodeKind::REF_T
        tok = expect(parse_state, lexer::TokenType::OP_BAND, "Expected '&'")
    } else {
        kind = NodeKind::PTR_T
        tok = expect(parse_state, lexer::TokenType::OP_MUL, "Expected '*'")
    }
    let line = tok.line
    let column = tok.column

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
    }

    var tokens = @(@parse_state).tokens
    var tpe = parse_type(parse_state, inline_types)
    if not tpe {
        @(@parse_state).tokens = tokens
    }

    var node = make_node(kind, line, column, parse_state)
    (@node).value.t_parr = {
        kw = kw,
        tpe = tpe
    } !NodePtrArrayT

    return node
}

def parse_id_decl_struct(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column
    
    var node: *Node = null
    if token.tpe == lexer::TokenType::K_STRUCT {
        node = expect_struct(parse_state)
    } else {
        var bit_size: uint64 = 0
        var is_bitfield = false
        if token.tpe == lexer::TokenType::PRAGMA {
            pop(parse_state)
            if token.value.str == "#bits" {
                is_bitfield = true
                expect(parse_state, lexer::TokenType::O_PAREN, "Expected '('")
                var n = expect(parse_state, lexer::TokenType::INTEGER, "Expected integer")
                if n.tpe != lexer::TokenType::INTEGER {
                    return null
                }
                bit_size = n.value.i
                expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
            } else {
                errors::errort(token, parse_state, "Invalid pragma")
            }
        }
        skip_newline(parse_state)
        token = peek(parse_state)

        var ident: *Node = null
        var tpe: *Node = null

        if token.tpe == lexer::TokenType::COLON {
            pop(parse_state)
            skip_newline(parse_state)
            tpe = expect_type(parse_state)
        } else {
            ident = expect_identifier(parse_state)
            skip_newline(parse_state)
            expect(parse_state, lexer::TokenType::COLON, "Expected ':'")
            skip_newline(parse_state)
            tpe = expect_type(parse_state)
        }

        if not ident and not is_bitfield {
            errors::errort(token, parse_state, "Expected identifier")
        }
        
        node = make_node(NodeKind::ID_DECL_STRUCT, line, column, parse_state)
        (@node).value.id_decl_struct = {
            ident = ident,
            tpe = tpe,
            is_bitfield = is_bitfield,
            bit_size = bit_size
        } !NodeIdDeclStruct
    }
    
    parse_t_term(parse_state)
    return node
}

def expect_struct(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var kind = NodeKind::STRUCT_T

    expect(parse_state, lexer::TokenType::K_STRUCT, "Expected struct")
    skip_newline(parse_state)
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::PRAGMA {
        pop(parse_state)
        if token.value.str == "#union" {
            kind = NodeKind::UNION_T
        } else {
            errors::errort(token, parse_state, "Unexpected pragma, only #union allowed")
            return null
        }
    }
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    skip_newline(parse_state)

    var body = vector::make()

    token = peek(parse_state)
    while token.tpe != lexer::TokenType::C_BRACE and
        token.tpe != lexer::TokenType::EOF {
        vector::push(body, parse_id_decl_struct(parse_state))
        skip_newline(parse_state)
        token = peek(parse_state)
    }

    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

    var node = make_node(kind, line, column, parse_state)
    (@node).value.body = body
    return node
}

def parse_id_decl_enum(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var ident = expect_identifier(parse_state)
    var value: *Node = null
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::OP_ASSIGN {
        pop(parse_state)
        skip_newline(parse_state)
        value = expect_expression(parse_state)
    }

    var node = make_node(NodeKind::ID_DECL_ENUM, line, column, parse_state)
    (@node).value.id_decl_enum = {
        ident = ident,
        value = value
    } !NodeIdDeclEnum
    
    parse_t_term(parse_state)
    return node
}

def expect_enum(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_ENUM, "Expected enum")
    skip_newline(parse_state)

    token = peek(parse_state)
    var tpe: *Node = null
    if token.tpe == lexer::TokenType::COLON {
        pop(parse_state)
        skip_newline(parse_state)
        tpe = expect_type(parse_state)
    }

    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    skip_newline(parse_state)

    var body = vector::make()

    token = peek(parse_state)
    while token.tpe != lexer::TokenType::C_BRACE and
        token.tpe != lexer::TokenType::EOF {
        vector::push(body, parse_id_decl_enum(parse_state))
        skip_newline(parse_state)
        token = peek(parse_state)
    }

    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

    var node = make_node(NodeKind::ENUM_T, line, column, parse_state)
    (@node).value.t_enum = {
        tpe = tpe,
        body = body
    } !NodeEnumT
    return node
}

def expect_type_of(parse_state: *ParseState) -> *Node {
    let tok = expect(parse_state, lexer::TokenType::K_TYPE_OF, "Expected type_of")
    skip_newline(parse_state)
    let expr = expect_expression(parse_state)
    var node = make_node(NodeKind::TYPE_OF_T, tok.line, tok.column, parse_state)
    node.value.expr = expr
    return node
}

def expect_structural_type(parse_state: *ParseState) -> *Node {
    var tok = peek(parse_state)
    let line = tok.line
    let column = tok.column

    expect(parse_state, lexer::TokenType::K_INTERFACE, "Expected interface")
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")

    let defs = vector::make()
    loop {
        skip_newline(parse_state)
        tok = peek(parse_state)
        if tok.tpe == lexer::TokenType::K_DEF {
            tok = pop(parse_state)
            let line = tok.line
            let column = tok.column
        	
            skip_newline(parse_state)
            let name = expect_identifier(parse_state)
            skip_newline(parse_state)
            
            let params = vector::make()
            let returns = vector::make()

            tok = peek(parse_state)
            if tok.tpe == lexer::TokenType::O_PAREN {
                pop(parse_state)
                tok = peek(parse_state)
                if tok.tpe != lexer::TokenType::C_PAREN and tok.tpe != lexer::TokenType::EOF {
                    loop {
                        skip_newline(parse_state)
                        tok = peek(parse_state)
                        let line = tok.line
                        let column = tok.column

                        let name = expect_identifier(parse_state)
                        skip_newline(parse_state)
                        expect(parse_state, lexer::TokenType::COLON, "Expected ':'")
                        skip_newline(parse_state)
                        let tpe = expect_type(parse_state)

                        let param = make_node(NodeKind::PARAMETER, line, column, parse_state)
                        param.value.param = {
                            name = name,
                            tpe = tpe
                        } !NodeParam

                        vector::push(params, param)

                        tok = peek(parse_state)
                        if tok.tpe == lexer::TokenType::COMMA {
                            pop(parse_state)
                            continue
                        } else {
                            break
                        }
                    }
                }
                expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
                tok = peek(parse_state)
            }

            skip_newline(parse_state)
            tok = peek(parse_state)
            if tok.tpe == lexer::TokenType::ARROW {
                pop(parse_state)
                skip_newline(parse_state)
                loop {
                    let tpe = expect_type(parse_state)
                    vector::push(returns, tpe)

                    tok = peek(parse_state)
                    if tok.tpe == lexer::TokenType::COMMA {
                        pop(parse_state)
                        skip_newline(parse_state)
                        continue
                    } else {
                        break
                    }
                }
            }

            let member = make_node(NodeKind::STRUCTURAL_T_MEMBER, line, column, parse_state)
            member.value.structural_member = {
                name = name,
                params = params,
                returns = returns
            } !NodeStructuralMember

            vector::push(defs, member)
        } else if tok.tpe == lexer::TokenType::C_BRACE or tok.tpe == lexer::TokenType::EOF {
            tok = pop(parse_state)
            break
        } else {
            tok = pop(parse_state)
            errors::errort(tok, parse_state, "Expected def")
        }
    }
    if tok.tpe != lexer::TokenType::C_BRACE {
        errors::errort(tok, parse_state, "Expected '}'")
    }

    let node = make_node(NodeKind::STRUCTURAL_T, line, column, parse_state)
    node.value.body = defs
    return node
}

def parse_type_identifier(parse_state: *ParseState, inline_types: bool) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column
    var name = expect_identifier(parse_state)
    
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::C_PAREN {
            pop(parse_state)
            return name
        } else {
            let args = vector::make()
            while token.tpe != lexer::TokenType::C_PAREN and 
                token.tpe != lexer::TokenType::EOF {
                let tpe = expect_type(parse_state, inline_types)
                vector::push(args, tpe)

                token = peek(parse_state)
                if token.tpe == lexer::TokenType::COMMA {
                    skip_newline(parse_state)
                    pop(parse_state)
                    continue
                } else {
                    expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
                    break
                }
            }
            let node = make_node(NodeKind::TYPE_CONSTRUCTOR, line, column, parse_state)
            node.value.type_constructor = {
                name = name,
                args = args
            }
            return node
        }
    }

    return name
}

def parse_type2(parse_state: *ParseState, inline_types: bool) -> *Node {
    var tok = pop(parse_state)

    if tok.tpe == lexer::TokenType::K_INTERFACE {
        unget_token(parse_state, tok)
        return expect_structural_type(parse_state)
    } else if tok.tpe == lexer::TokenType::O_PAREN {
        var node = expect_type(parse_state, inline_types)
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
        return node
    } else if tok.tpe == lexer::TokenType::K_TYPE {
        var tpe_node = expect_type(parse_state, inline_types)
        if inline_types { return tpe_node }
        let node = make_node(NodeKind::TYPE_T, tok.line, tok.column, parse_state)
        node.value.expr = tpe_node
        return node
    } else if tok.tpe == lexer::TokenType::K_WORD {
        expect(parse_state, lexer::TokenType::O_PAREN, "Expected '('")
        var n = expect(parse_state, lexer::TokenType::INTEGER, "Expected integer")
        if n.tpe != lexer::TokenType::INTEGER {
            return null
        }
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
        var node = make_node(NodeKind::WORD_T, tok.line, tok.column, parse_state)
        (@node).value.i = n.value.i

        return node
    } else if tok.tpe == lexer::TokenType::K_TYPE_OF {
        unget_token(parse_state, tok)
        return expect_type_of(parse_state)
    } else if tok.tpe == lexer::TokenType::K_UNSIGNED {
        var node = make_node(NodeKind::UNSIGNED_T, tok.line, tok.column, parse_state)
        (@node).value.expr = expect_type(parse_state)

        return node
    } else if tok.tpe == lexer::TokenType::O_SQUARE {
        unget_token(parse_state, tok)
        return expect_array(parse_state)
    } else if tok.tpe == lexer::TokenType::OP_MUL or
        tok.tpe == lexer::TokenType::OP_BAND {
        unget_token(parse_state, tok)
        return expect_ptr_ref(parse_state, tok.tpe == lexer::TokenType::OP_BAND, inline_types)
    } else if tok.tpe == lexer::TokenType::K_WEAK_REF {
        unget_token(parse_state, tok)
        return expect_weak_ref(parse_state, inline_types)
    } else if tok.tpe == lexer::TokenType::DOUBLE_COLON or
        tok.tpe == lexer::TokenType::IDENTIFIER {
        unget_token(parse_state, tok)
        return parse_type_identifier(parse_state, inline_types)
    } else if tok.tpe == lexer::TokenType::K_STRUCT {
        unget_token(parse_state, tok)
        return expect_struct(parse_state)
    } else if tok.tpe == lexer::TokenType::K_ENUM {
        unget_token(parse_state, tok)
        return expect_enum(parse_state)
    } else {
        unget_token(parse_state, tok)
        return null
    }
}

def parse_type_list(parse_state: *ParseState, sw: bool, inline_types: bool) -> *vector::Vector {
    var token = peek(parse_state)
    var vec = vector::make()
    if token.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::C_PAREN {
            pop(parse_state)
            return vec
        }
        loop {
            let node = parse_type(parse_state, inline_types)
            vector::push(vec, node)
            token = peek(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                continue
            }
            break
        }
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
    } else {
        var node: *Node = null
        if sw {
            node = parse_type(parse_state, inline_types)
        } else {
            node = parse_type2(parse_state, inline_types)
        }

        if node {
            vector::push(vec, node)
        }
    }
    return vec
}

// TODO Allow things like (A, B) -> (C, D) -> (E, F)
def parse_type(parse_state: *ParseState, inline_types: bool = true) -> *Node {
    let args = parse_type_list(parse_state, false, inline_types)
    var token = peek(parse_state)
    if token.tpe == lexer::TokenType::ARROW {
        pop(parse_state)
        let ret = parse_type_list(parse_state, true, inline_types)
        var node = make_node(NodeKind::FUNCTION_T, token.line, token.column, parse_state)
        (@node).value.t_func = {
            args = args,
            ret = ret
        } !NodeFunctionT
        return node
    } else if vector::length(args) > 1 {
        errors::errort(token, parse_state, "Expected single type, got multiple")
        return null
    } else if vector::length(args) == 1 {
        return vector::get(args, 0) !*Node
    } else {
        return null
    }
}

// inline_types is a flag to wrap type expressions in Type
def expect_type(parse_state: *ParseState, inline_types: bool = true) -> *Node {
    let token = peek(parse_state)
    let node = parse_type(parse_state, inline_types)
    if not node {
        errors::errort(token, parse_state, "Expected type") 
    }
    return node
}

def expect_array_lit(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column
    
    expect(parse_state, lexer::TokenType::O_SQUARE, "Expecting '['")
    var body = vector::make()
    skip_newline(parse_state)
    token = peek(parse_state)
    if token.tpe != lexer::TokenType::C_SQUARE {
        loop {
            var expr = expect_expression_no_assign(parse_state)
            vector::push(body, expr)
            skip_newline(parse_state)
            token = peek(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                continue
            } else {
                break
            }
        }
    }
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::C_SQUARE, "Expecting ']'")

    var node = make_node(NodeKind::ARRAY_LIT, line, column, parse_state)
    (@node).value.body = body

    return node
}

// TODO: Remove duplicated code, see expect_func_args
def expect_struct_lit(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::O_BRACE, "Expecting '{'")
    skip_newline(parse_state)
    token = peek(parse_state)

    var args = vector::make()
    while token.tpe != lexer::TokenType::C_BRACE and
        token.tpe != lexer::TokenType::EOF {
        
        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::IDENTIFIER {
            var tokens = @(@parse_state).tokens
            pop(parse_state)
            skip_newline(parse_state)
            if peek(parse_state).tpe == lexer::TokenType::OP_ASSIGN {
                @(@parse_state).tokens = tokens
                break // Start list of named arguments
            }
            @(@parse_state).tokens = tokens
        }

        vector::push(args, expect_expression_no_assign(parse_state))

        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_BRACE {
            if token.tpe != lexer::TokenType::COMMA {
                errors::errort(token, parse_state, "Expected ','")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    var kwargs = vector::make()
    while token.tpe != lexer::TokenType::C_BRACE and
        token.tpe != lexer::TokenType::EOF {

        skip_newline(parse_state)
        token = peek(parse_state)
        let line = token.line
        let column = token.column

        let ident = expect_identifier(parse_state)
        skip_newline(parse_state)

        expect(parse_state, lexer::TokenType::OP_ASSIGN, "expected '='")
        skip_newline(parse_state)
        let expr = expect_expression_no_assign(parse_state)

        let named_arg = make_node(NodeKind::NAMED_ARG, line, column, parse_state)
        (@named_arg).value.named_arg = {
            name = ident,
            value = expr
        } !NodeNamedArg
        vector::push(kwargs, named_arg)

        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_BRACE {
            if token.tpe != lexer::TokenType::COMMA {
                errors::errort(token, parse_state, "Expected ','")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    expect(parse_state, lexer::TokenType::C_BRACE, "Expecting '}'")

    var call = make_node(NodeKind::STRUCT_LIT, line, column, parse_state)
    (@call).value.struct_lit = {
        args = args,
        kwargs = kwargs
    } !NodeStructLit

    return call
}

def parse_term(parse_state: *ParseState) -> *Node {
    let token = pop(parse_state)
    var node = zero_allocate(Node)
    
    if token.tpe == lexer::TokenType::O_PAREN {
        free(node)
        node = parse_expression(parse_state)
        let end_token = expect(parse_state, lexer::TokenType::C_PAREN, "Expecting ')'")
        if node {
            // Set start and end token to include the parens
            node.loc.line = token.line
            node.loc.column = token.column
            node.loc.end_line = end_token.end_line
            node.loc.end_column = end_token.end_column
        }
        return node
    } else if token.tpe == lexer::TokenType::K_TYPE {
        free(node)
        skip_newline(parse_state)
        return expect_type(parse_state)
    } else if token.tpe == lexer::TokenType::K_DEFINED {
        skip_newline(parse_state)
        (@node).kind = NodeKind::DEFINED
        (@node).value.expr = expect_identifier(parse_state)
    } else if token.tpe == lexer::TokenType::INTEGER {
        (@node).kind = NodeKind::INTEGER
        (@node).value.i = token.value.i
    } else if token.tpe == lexer::TokenType::FLOAT {
        (@node).kind = NodeKind::FLOAT
        (@node).value.f = token.value.f
    } else if token.tpe == lexer::TokenType::IDENTIFIER or
        token.tpe == lexer::TokenType::DOUBLE_COLON {
        free(node)
        unget_token(parse_state, token)
        return expect_identifier(parse_state)
    } else if token.tpe == lexer::TokenType::STRING {
        (@node).kind = NodeKind::STRING
        (@node).value.str = token.value.str
    } else if token.tpe == lexer::TokenType::CHAR {
        (@node).kind = NodeKind::CHAR
        (@node).value.i = token.value.ch
    } else if token.tpe == lexer::TokenType::K_TRUE or
        token.tpe == lexer::TokenType::K_FALSE {
        
        var value = 0
        if token.tpe == lexer::TokenType::K_TRUE {
            value = 1
        }

        (@node).kind = NodeKind::BOOLEAN
        (@node).value.i = value
    } else if token.tpe == lexer::TokenType::K_NULL {
        (@node).kind = NodeKind::NULL
    } else if token.tpe == lexer::TokenType::K_UNDEF {
        node.kind = NodeKind::UNDEF
    } else if token.tpe == lexer::TokenType::O_SQUARE {
        free(node)
        unget_token(parse_state, token)
        return expect_array_lit(parse_state)
    } else if token.tpe == lexer::TokenType::O_BRACE {
        free(node)
        unget_token(parse_state, token)
        return expect_struct_lit(parse_state)
    } else {
        free(node)
        // errors::errort(token, parse_state, "Expected literal or identifier")
        return null
    }

    let current_token = peek(parse_state)

    (@node).tpe = null
    (@node).scope = null
    (@node).loc = {
        (@parse_state).filename,
        (@parse_state).module,
        token.line,
        token.column,
        current_token.end_line,
        current_token.end_column,
        (@parse_state).lines
    } !SourceLoc
    return node
}

def expect_func_args(parse_state: *ParseState, node: *Node) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var args = vector::make()
    while token.tpe != lexer::TokenType::C_PAREN and
        token.tpe != lexer::TokenType::EOF {
        if token.tpe == lexer::TokenType::IDENTIFIER {
            token = pop(parse_state)
            if peek(parse_state).tpe == lexer::TokenType::OP_ASSIGN {
                unget_token(parse_state, token)
                break // Start list of named arguments
            }
            unget_token(parse_state, token)
        }

        vector::push(args, expect_expression_no_assign(parse_state))

        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_PAREN {
            if token.tpe != lexer::TokenType::COMMA {
                errors::errort(token, parse_state, "Expected ','")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    var kwargs = vector::make()
    while token.tpe != lexer::TokenType::C_PAREN and
        token.tpe != lexer::TokenType::EOF {

        token = peek(parse_state)
        let line = token.line
        let column = token.column

        let ident = expect_identifier(parse_state)

        expect(parse_state, lexer::TokenType::OP_ASSIGN, "expected '='")
        let expr = expect_expression_no_assign(parse_state)

        let named_arg = make_node(NodeKind::NAMED_ARG, line, column, parse_state)
        (@named_arg).value.named_arg = {
            name = ident,
            value = expr
        } !NodeNamedArg
        vector::push(kwargs, named_arg)

        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_PAREN {
            if token.tpe != lexer::TokenType::COMMA {
                errors::errort(token, parse_state, "Expected ','")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    var call = make_node(NodeKind::FUNC_CALL, line, column, parse_state)
    (@call).value.func_call = {
        left = node,
        args = args,
        kwargs = kwargs
    } !NodeFuncCall

    return call
}

def parse_post_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_term(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::O_PAREN) {
            node = expect_func_args(parse_state, node)
            expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
        } else if next_token(parse_state, lexer::TokenType::O_SQUARE) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::ARRAY_SUBSCRIPT, node, parse_expression(parse_state))
            skip_newline(parse_state)
            expect(parse_state, lexer::TokenType::C_SQUARE, "Expected ']'")
        } else if next_token(parse_state, lexer::TokenType::DOT) {
            node = make_bin_op(parse_state, token, NodeKind::MEMBER_ACCESS, node, expect_identifier(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_pre_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    if next_token(parse_state, lexer::TokenType::K_SIZE_OF) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::SIZE_OF, expect_type(parse_state))
    } else if next_token(parse_state, lexer::TokenType::K_ALIGN_OF) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::ALIGN_OF, expect_type(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_ADD) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::UADD, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SUB) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::USUB, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_MUL) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::PTR, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_DEREF) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::DEREF, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_BNOT) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::BNOT, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::K_NOT) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::NOT, parse_pre_expression(parse_state))
    } else {
        return parse_post_expression(parse_state)
    }
}

def parse_cast_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)    
    var node = parse_pre_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_CAST) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::CAST, node, parse_type(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_bin_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)    
    var node = parse_cast_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_BAND) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::BAND, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BOR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::BOR, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BXOR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::BXOR, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHL) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::SHL, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::SHR, node, parse_cast_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_mul_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_bin_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_MUL) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::MUL, node, parse_bin_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DIV) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::DIV, node, parse_bin_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_MOD) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::MOD, node, parse_bin_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_add_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_mul_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_ADD) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::ADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SUB) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::SUB, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_INC) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::PADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DEC) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::PSUB, node, parse_mul_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_cmp_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_add_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_EQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::EQ, node, parse_add_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_NEQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::NEQ, node, parse_add_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_GEQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::GEQ, node, parse_add_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_LEQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::LEQ, node, parse_add_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_GT) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::GT, node, parse_add_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_LT) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::LT, node, parse_add_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_and_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_cmp_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::K_AND) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::AND, node, parse_cmp_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_or_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_and_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::K_OR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::OR, node, parse_and_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_range_expression(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    var node = parse_or_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_RANGE) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::RANGE, node, parse_or_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_RANGE_INC) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::RANGE_INC, node, parse_or_expression(parse_state))
        } else {
            return node
        }
        token = peek(parse_state)
    }
}

def parse_assign_and_op(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var node = parse_range_expression(parse_state)
    if next_token(parse_state, lexer::TokenType::OP_PADD_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::PADD_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_PSUB_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::PSUB_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_ADD_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::ADD_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SUB_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::SUB_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_MUL_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::MUL_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_DIV_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::DIV_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_MOD_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::MOD_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_AND_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::AND_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_OR_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::OR_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_XOR_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::XOR_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SHL_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::SHL_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SHR_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::SHR_EQ, node, parse_assign_and_op(parse_state))
    }
    return node
}

def parse_type_of(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)

    if token.tpe == lexer::TokenType::K_TYPE_OF {
        return expect_type_of(parse_state)
    } else {
        return parse_assign_and_op(parse_state)
    }
}


def parse_assign(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var node = parse_type_of(parse_state)
    var left = vector::make()
    var right = vector::make()

    vector::push(left, node)
    
    token = peek(parse_state)
    while token.tpe == lexer::TokenType::COMMA {
        pop(parse_state)
        skip_newline(parse_state)
        node = parse_type_of(parse_state)
        vector::push(left, node)
        token = peek(parse_state)
    }

    if token.tpe != lexer::TokenType::OP_ASSIGN {
        if vector::length(left) == 1 {
            return vector::get(left, 0) !*Node
        }
    } else {
        pop(parse_state)
        
        node = parse_assign(parse_state)
        if node and (@node).kind == NodeKind::ASSIGN and vector::length((@node).value.assign.right) == 0 {
            right = (@node).value.assign.left
        } else {
            vector::push(right, node)
            token = peek(parse_state)
            while token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                node = parse_assign(parse_state)
                vector::push(right, node)
                token = peek(parse_state)
            }
        }
    }
    
    var result = make_node(NodeKind::ASSIGN, line, column, parse_state)
    (@result).value.assign = {
        left = left,
        right = right
    } !NodeAssign

    return result
}

def parse_expression(parse_state: *ParseState) -> *Node {
    let node = parse_assign(parse_state)
    let token = peek(parse_state)
    if token.tpe == lexer::TokenType::K_IF {
        return expect_if_expr(parse_state, node)
    }
    return node
}

def expect_expression(parse_state: *ParseState) -> *Node {
    let node = parse_expression(parse_state)
    if not node {
        let token = peek(parse_state)
        errors::errort(token, parse_state, "Expected expression")
    }
    return node
}

def parse_expression_no_assign(parse_state: *ParseState) -> *Node {
    let node = parse_type_of(parse_state)
    let token = peek(parse_state)
    if token.tpe == lexer::TokenType::K_IF {
        return expect_if_expr(parse_state, node)
    }
    return node
}

def expect_expression_no_assign(parse_state: *ParseState) -> *Node {
    let node = parse_expression_no_assign(parse_state)
    if not node {
        let token = peek(parse_state)
        errors::errort(token, parse_state, "Expected expression")
    }
    return node
}

def make_operator_ident(name: string, token: Token, parse_state: *ParseState) -> *Node {
    let ident = make_node(NodeKind::IDENTIFIER, token.line, token.column, parse_state)
    let path = vector::make()
    vector::push(path, util::copy_string(name))
    ident.value.identifier.path = path
    return ident
}

def parse_def(parse_state: *ParseState, share: ShareMarker) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_DEF, "Expected def")
    skip_newline(parse_state)

    token = peek(parse_state)
    var extern = false
    var dllimport = false
    while token.tpe == lexer::TokenType::PRAGMA {
        pop(parse_state)
        if token.value.str == "#extern" {
            extern = true
        } else if token.value.str == "#dllimport" {
            dllimport = true
        } else {
            errors::errort(token, parse_state, "Invalid pragma")
        }
        skip_newline(parse_state)
        token = peek(parse_state)
    }

    var name: *Node = null 
    token = peek(parse_state)
    var operator_token = token
    if token.tpe == lexer::TokenType::IDENTIFIER or
        token.tpe == lexer::TokenType::DOUBLE_COLON {
        name = expect_identifier(parse_state)
    } else {
        token = pop(parse_state)
    }

    //skip_newline(parse_state)
    var params = vector::make()
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_PAREN {
            var varargs = false
            var default = false

            loop {
                token = peek(parse_state)

                let line = token.line
                let column = token.column

                var kw = VarDecl::VAR
                var name: *Node = null
                var tpe: *Node = null
                var value: *Node = null

                if token.tpe == lexer::TokenType::OP_VARARGS {
                    if varargs {
                        errors::errort(token, parse_state, "Only the last parameter is allowed to be varargs")
                    }
                    varargs = true
                    pop(parse_state)
                } else {
                    if token.tpe == lexer::TokenType::K_LET {
                        kw = VarDecl::LET
                        pop(parse_state)
                    } else if token.tpe == lexer::TokenType::K_VAR {
                        kw = VarDecl::VAR
                        pop(parse_state)
                    } else if token.tpe == lexer::TokenType::K_TYPE {
                        kw = VarDecl::TYPE
                        pop(parse_state)
                    }

                    skip_newline(parse_state)
                    name = expect_identifier(parse_state)
                    skip_newline(parse_state)
                    
                    token = peek(parse_state)
                    if token.tpe == lexer::TokenType::COLON {
                        pop(parse_state)
                        tpe = expect_type(parse_state, false)
                        token = peek(parse_state)
                        if token.tpe == lexer::TokenType::OP_VARARGS {
                            if varargs {
                                errors::errort(token, parse_state, "Only the last parameter is allowed to be varargs")
                            }
                            varargs = true
                            pop(parse_state)
                        }
                    }
                    
                    skip_newline(parse_state)
                    token = peek(parse_state)
                    
                    if token.tpe == lexer::TokenType::OP_ASSIGN {
                        default = true
                        pop(parse_state)
                        if kw == VarDecl::TYPE {
                            value = expect_type(parse_state)
                        } else {
                            value = expect_expression_no_assign(parse_state)
                        }
                    } else {
                        if default {
                            errors::errort(token, parse_state, "Argument needs to have a default value")
                        }
                    }
                }

                let param = make_node(NodeKind::PARAMETER, line, column, parse_state)
                (@param).value.param = {
                    varargs = varargs,
                    kw = kw,
                    name = name,
                    tpe = tpe,
                    value = value
                } !NodeParam

                vector::push(params, param)

                token = peek(parse_state)
                if token.tpe == lexer::TokenType::COMMA {
                    pop(parse_state)
                    continue
                } else {
                    expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
                    break
                }
            }
        } else {
            pop(parse_state)
        }     
    }

    var returns = vector::make()
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::ARROW {
        pop(parse_state)
        loop {
            let tpe = expect_type(parse_state)
            vector::push(returns, tpe)

            token = peek(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                continue
            } else {
                break
            }
        }
    }
    
    var body: *vector::Vector = null
    var tokens = @(@parse_state).tokens
    skip_newline(parse_state)
    token = peek(parse_state)
    if token.tpe != lexer::TokenType::O_BRACE {
        @(@parse_state).tokens = tokens
    } else {
        pop(parse_state)
        body = vector::make()
        parse_block(parse_state, body)
        expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")
    }

    if operator_token.tpe == lexer::TokenType::OP_ADD {
        if vector::length(params) == 1 {
            name = make_operator_ident("__pos__", token, parse_state)
        } else {
            name = make_operator_ident("__add__", token, parse_state)
        }
    } else if operator_token.tpe == lexer::TokenType::OP_SUB {
        if vector::length(params) == 1 {
            name = make_operator_ident("__neg__", token, parse_state)
        } else {            
            name = make_operator_ident("__sub__", token, parse_state)
        }
    } else if operator_token.tpe == lexer::TokenType::OP_MUL {
        name = make_operator_ident("__mul__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_DIV {
        name = make_operator_ident("__div__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_MOD {
        name = make_operator_ident("__mod__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_SHR {
        name = make_operator_ident("__rshift__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_SHL {
        name = make_operator_ident("__lshift__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_BAND {
        name = make_operator_ident("__and__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_BOR {
        name = make_operator_ident("__or__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_BXOR {
        name = make_operator_ident("__xor__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_BNOT {
        name = make_operator_ident("__invert__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_LT {
        name = make_operator_ident("__lt__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_GT {
        name = make_operator_ident("__gt__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_LEQ {
        name = make_operator_ident("__le__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_GEQ {
        name = make_operator_ident("__ge__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_EQ {
        name = make_operator_ident("__eq__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_NEQ {
        name = make_operator_ident("__ne__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_SUB_EQ {
        name = make_operator_ident("__isub__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_ADD_EQ {
        name = make_operator_ident("__iadd__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_MUL_EQ {
        name = make_operator_ident("__imul__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_DIV_EQ {
        name = make_operator_ident("__idiv__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_MOD_EQ {
        name = make_operator_ident("__imod__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_SHR_EQ {
        name = make_operator_ident("__irshift__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_SHL_EQ {
        name = make_operator_ident("__ilshift__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_AND_EQ {
        name = make_operator_ident("__iand__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_OR_EQ {
        name = make_operator_ident("__ior__", token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_XOR_EQ {
        name = make_operator_ident("__ixor__", token, parse_state)
    } else if operator_token.tpe != lexer::TokenType::IDENTIFIER and 
        operator_token.tpe != lexer::TokenType::DOUBLE_COLON {
        errors::errort(token, parse_state, "Expected identifier or operator")
    }
    
    var node = make_node(NodeKind::DEF, line, column, parse_state)
    (@node).value.def_ = {
        dllimport = dllimport,
        extern = extern,
        share = share,
        name = name,
        params = params,
        returns = returns,
        body = body
    } !NodeDef
    node.body = body
    return node
}

def parse_vardecl(parse_state: *ParseState, share: ShareMarker, vardecl: VarDecl) -> *Node {
    var tok = pop(parse_state)
    let line = tok.line
    let column = tok.column

    if not (tok.tpe == lexer::TokenType::K_VAR or 
        tok.tpe == lexer::TokenType::K_CONST or 
        tok.tpe == lexer::TokenType::K_LET) {

        return null
    }
    skip_newline(parse_state)
    tok = peek(parse_state)

    var extern = false
    var dllimport = false
    while tok.tpe == lexer::TokenType::PRAGMA {
        pop(parse_state)
        if tok.value.str == "#extern" {
            extern = true
        } else if tok.value.str == "#dllimport" {
            dllimport = true
        } else {
            errors::errort(tok, parse_state, "Invalid pragma")
        }
        skip_newline(parse_state)
        tok = peek(parse_state)
    }

    var vec_left = vector::make()
    loop {
        tok = pop(parse_state)
        if tok.tpe == lexer::TokenType::O_PAREN {
            // Assignment
            let expr = expect_expression_no_assign(parse_state)
            expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
            var node = make_node(NodeKind::ID_ASSIGN, tok.line, tok.column, parse_state)
            (@node).value.expr = expr
            vector::push(vec_left, node)
        } else {
            // Id decl
            unget_token(parse_state, tok)
            var ident = expect_identifier(parse_state)

            tok = peek(parse_state)
            var tpe: *Node = null
            if tok.tpe == lexer::TokenType::COLON {
                // Type
                pop(parse_state)
                tpe = expect_type(parse_state)
            }
            var node = make_node(NodeKind::ID_DECL, tok.line, tok.column, parse_state)
            (@node).value.id_decl = {
                value = ident,
                tpe = tpe
            } !NodeIdDecl
            vector::push(vec_left, node)
        }
        tok = pop(parse_state)
        if tok.tpe == lexer::TokenType::COMMA {
            skip_newline(parse_state)
            continue
        } else if tok.tpe == lexer::TokenType::OP_ASSIGN or
            tok.tpe == lexer::TokenType::NEW_LINE or
            tok.tpe == lexer::TokenType::EOF {
            unget_token(parse_state, tok)
            break
        } else {
            errors::errort(tok, parse_state, "Expected identifier, (expression) or '='")
            return null
        }
    }

    var vec_right = vector::make()
    if tok.tpe == lexer::TokenType::OP_ASSIGN {
        pop(parse_state)
        loop {
            var expr = expect_expression_no_assign(parse_state)
            vector::push(vec_right, expr)
            
            tok = pop(parse_state)
            if tok.tpe == lexer::TokenType::COMMA {
                skip_newline(parse_state)
                continue
            } else if tok.tpe == lexer::TokenType::NEW_LINE or
                tok.tpe == lexer::TokenType::EOF or
                tok.tpe == lexer::TokenType::SEMICOLON {
                unget_token(parse_state, tok)
                break
            }
        }
        //if vector::length(vec_left) != vector::length(vec_right) {
        //    errors::errort(tok, parse_state, "Unbalanced assignment")
        //}
    } else if vardecl == VarDecl::LET or
        vardecl == VarDecl::CONST {
        errors::errort(tok, parse_state, "Expected '='")
        return null
    }

    var node = make_node(NodeKind::VAR_DECL, line, column, parse_state)
    (@node).value.var_decl = {
        extern = extern,
        dllimport = dllimport,
        share = share,
        kw = vardecl,
        left = vec_left,
        right = vec_right
    } !NodeVarDecl

    return node
}

def parse_typedecl(parse_state: *ParseState, share: ShareMarker) -> *Node {
    var token = pop(parse_state)
    let line = token.line
    let column = token.column

    if token.tpe != lexer::TokenType::K_TYPE {
        return null
    }
    var vec_left = vector::make()
    loop {
        let line = token.line
        let column = token.column
        var ident = expect_identifier(parse_state)
    
        token = pop(parse_state)
        if token.tpe == lexer::TokenType::O_PAREN {
            token = peek(parse_state)
            if token.tpe == lexer::TokenType::C_PAREN {
                token = pop(parse_state)
                vector::push(vec_left, ident)
            } else {
                let args = vector::make()
                while token.tpe != lexer::TokenType::C_PAREN and
                        token.tpe != lexer::TokenType::EOF {
                    
                    // TODO We want to take regular values too not just types
                    expect(parse_state, lexer::TokenType::K_TYPE, "Expected 'type'")
                    token = peek(parse_state)
                    let name = expect_identifier(parse_state)
                    let param = make_node(NodeKind::PARAMETER, token.line, token.column, parse_state)
                    param.value.param = {
                        name = name
                    }
                    vector::push(args, param)
                    
                    token = peek(parse_state)
                    if token.tpe == lexer::TokenType::COMMA {
                        skip_newline(parse_state)
                        pop(parse_state)
                        continue
                    } else {
                        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
                        token = pop(parse_state)
                        break
                    }
                }

                let typec = make_node(NodeKind::TYPE_CONSTRUCTOR, line, column, parse_state)
                typec.value.type_constructor = {
                    name = ident,
                    args = args
                } !NodeTypeConstructor
                vector::push(vec_left, typec)
            }
        } else {
            vector::push(vec_left, ident)
        }

        if token.tpe == lexer::TokenType::COMMA {
            skip_newline(parse_state)
            continue
        } else if token.tpe == lexer::TokenType::OP_ASSIGN or
            token.tpe == lexer::TokenType::NEW_LINE or
            token.tpe == lexer::TokenType::EOF {
            unget_token(parse_state, token)
            break
        }
    }

    var vec_right = vector::make()
    if token.tpe == lexer::TokenType::OP_ASSIGN {
        pop(parse_state)
        loop {
            var tpe = expect_type(parse_state)
            vector::push(vec_right, tpe)

            token = pop(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                skip_newline(parse_state)
                continue
            } else if token.tpe == lexer::TokenType::NEW_LINE or
                token.tpe == lexer::TokenType::EOF {
                unget_token(parse_state, token)
                break
            }
        }
    }

    var node = make_node(NodeKind::TYPE_DECL, line, column, parse_state)
    (@node).value.type_decl = {
        share = share,
        left = vec_left,
        right = vec_right
    } !NodeTypeDecl

    return node
}

def expect_loop_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_LOOP, "Expected loop")
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    var body = vector::make()
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

    var node = make_node(NodeKind::LOOP, line, column, parse_state)
    (@node).value.body = body
    node.body = body

    return node
}

def expect_while_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_WHILE, "Expected while")
    skip_newline(parse_state)
    let expr = expect_expression(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    var body = vector::make()
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

    var node = make_node(NodeKind::WHILE, line, column, parse_state)
    (@node).value.while_loop = {
        expr = expr,
        body = body
    } !NodeWhile
    node.body = body

    return node
}

def expect_for_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_FOR, "Expected for")
    skip_newline(parse_state)

    var iddecl: *Node = null
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::K_VAR or
        token.tpe == lexer::TokenType::K_LET {
        
        var kw = VarDecl::VAR
        if token.tpe == lexer::TokenType::K_LET {
            kw = VarDecl::LET
        }

        pop(parse_state)
        let ident = expect_identifier(parse_state)
        iddecl = make_node(NodeKind::FOR_ID_DECL, token.line, token.column, parse_state)
        // TODO Have an optional type here
        (@iddecl).value.for_id_decl = {
            kw = kw,
            ident = ident
        } !NodeForIdDecl
    } else {
        iddecl = expect_identifier(parse_state)
    }

    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::K_IN, "Expected in")
    skip_newline(parse_state)
    var expr = expect_expression(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    var body = vector::make()
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

    var node = make_node(NodeKind::FOR, line, column, parse_state)
    (@node).value.for_loop = {
        iddecl = iddecl,
        expr = expr,
        body = body
    } !NodeFor
    node.body = body

    return node
}

def expect_if_expr(parse_state: *ParseState, if_true: *Node) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_IF, "Expected if")
    let cond = expect_expression_no_assign(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::K_ELSE, "Expected else")
    skip_newline(parse_state)
    let if_false = expect_expression_no_assign(parse_state)

    var node = make_node(NodeKind::IF_EXPR, line, column, parse_state)
    (@node).value.if_expr = {
        cond = cond,
        if_true = if_true,
        if_false = if_false
    } !NodeIfExpr

    return node
}

def expect_if_stmt(parse_state: *ParseState, static_if: bool) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    if static_if {
        if not (token.tpe == lexer::TokenType::PRAGMA and token.value.str == "#if") {
            errors::errort(token, parse_state, "Expected #if")
            return null
        }
        pop(parse_state)
    } else {
        expect(parse_state, lexer::TokenType::K_IF, "Expected if")
    }
    
    skip_newline(parse_state)
    let cond = expect_expression(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    var body = vector::make()
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")
    
    var tokens = @(@parse_state).tokens
    skip_newline(parse_state)

    var else_if = vector::make()
    var else_node: *Node = null

    token = peek(parse_state)
    if token.tpe != lexer::TokenType::K_ELSE {
        @(@parse_state).tokens = tokens
    }
    loop {
        if token.tpe == lexer::TokenType::K_ELSE {
            pop(parse_state)
            skip_newline(parse_state)
            token = peek(parse_state)
            if token.tpe == lexer::TokenType::K_IF {
                pop(parse_state)
                var cond = expect_expression(parse_state)
                
                skip_newline(parse_state)
                expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
                var body = vector::make()
                parse_block(parse_state, body)
                expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

                tokens = @(@parse_state).tokens
                skip_newline(parse_state)

                let elif_node = make_node(NodeKind::ELSE_IF, token.line, token.column, parse_state)
                (@elif_node).value.else_if = {
                    cond = cond,
                    body = body
                } !NodeElseIf
                elif_node.body = body

                vector::push(else_if, elif_node)

                token = peek(parse_state)
            
                if token.tpe != lexer::TokenType::K_ELSE {
                    @(@parse_state).tokens = tokens
                }
            } else {
                skip_newline(parse_state)

                expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
                var body = vector::make()
                parse_block(parse_state, body)
                expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

                else_node = make_node(NodeKind::ELSE, token.line, token.column, parse_state)
                (@else_node).value.body = body
                else_node.body = body
                    
                break
            }
        } else {
            break
        }
    }

    var node_kind = NodeKind::IF
    if static_if {
        node_kind = NodeKind::STATIC_IF
    }

    var node = make_node(node_kind, line, column, parse_state)
    (@node).value.if_ = {
        cond = cond,
        body = body,
        else_if = else_if,
        else_ = else_node
    } !NodeIf
    node.body = body

    return node
}

def expect_switch_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column   

    expect(parse_state, lexer::TokenType::K_SWITCH, "Expected switch")
    skip_newline(parse_state)
    let expr = expect_expression(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    var body = vector::make()
    loop {
        skip_newline(parse_state)
        token = pop(parse_state)
        if token.tpe == lexer::TokenType::C_BRACE or
            token.tpe == lexer::TokenType::EOF {
            break        
        } else if token.tpe == lexer::TokenType::K_CASE {
            let line = token.line
            let column = token.column
            skip_newline(parse_state)

            var body2 = vector::make()
            var expr2 = vector::make()

            loop {
                token = peek(parse_state)
                if token.tpe == lexer::TokenType::COLON {
                    pop(parse_state)
                    break
                } else if token.tpe == lexer::TokenType::COMMA {
                    pop(parse_state)
                } else {
                    vector::push(expr2, expect_expression_no_assign(parse_state))
                }
                skip_newline(parse_state)
            }
            
            skip_newline(parse_state)
            token = peek(parse_state)
            while token.tpe != lexer::TokenType::K_CASE and
                token.tpe != lexer::TokenType::C_BRACE and
                token.tpe != lexer::TokenType::EOF {
                parse_block_stmt(parse_state, body2)
                skip_newline(parse_state)
                token = peek(parse_state)
            }
            var node = make_node(NodeKind::CASE, line, column, parse_state)
            (@node).value.case_ = {
                expr = expr2,
                body = body2
            } !NodeCase
            node.body = body

            vector::push(body, node)
        } else {
            errors::errort(token, parse_state, "Expected case")
        }
    }
    if token.tpe != lexer::TokenType::C_BRACE {
        errors::errort(token, parse_state, "Expected '}'")
    }

    var node = make_node(NodeKind::SWITCH, line, column, parse_state)
    (@node).value.switch_ = {
        expr = expr,
        body = body
    } !NodeSwitch
    node.body = body

    return node
}

def expect_import_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var body = vector::make()
    expect(parse_state, lexer::TokenType::K_IMPORT, "Expected import")
    skip_newline(parse_state)

    loop {
        let line = token.line
        let column = token.column

        let name = expect_identifier(parse_state)
        token = peek(parse_state)
        var alias: *Node = null
        if token.tpe == lexer::TokenType::K_AS {
            pop(parse_state)
            alias = expect_identifier(parse_state) 
        }

        var module = make_node(NodeKind::IMPORT_MODULE, line, column, parse_state)
        (@module).value.import_module = {
            name = name,
            alias = alias
        } !NodeImportModule

        vector::push(body, module)

        token = peek(parse_state)
        if token.tpe == lexer::TokenType::COMMA {
            pop(parse_state)
            skip_newline(parse_state)
            continue
        } else {
            break
        }
    }

    var node = make_node(NodeKind::IMPORT, line, column, parse_state)
    (@node).value.body = body

    return node
}

def expect_return_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_RETURN, "Expected return")

    var body = vector::make()
    token = peek(parse_state)
    while token.tpe != lexer::TokenType::NEW_LINE and
        token.tpe != lexer::TokenType::EOF and
        token.tpe != lexer::TokenType::C_BRACE {

        vector::push(body, expect_expression_no_assign(parse_state))
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::COMMA {
            pop(parse_state)
            skip_newline(parse_state)
            continue
        } else {
            break
        }
    }

    var node = make_node(NodeKind::RETURN, line, column, parse_state)
    (@node).value.body = body
    
    return node
}

def parse_t_term(parse_state: *ParseState) {
    let token = peek(parse_state)
    if token.tpe == lexer::TokenType::SEMICOLON or token.tpe == lexer::TokenType::NEW_LINE {
        pop(parse_state)
    } else if token.tpe != lexer::TokenType::EOF and token.tpe != lexer::TokenType::C_BRACE {
        pop(parse_state)
        errors::errort(token, parse_state, "Missing statement separator")
    }
}

def parse_statement2(parse_state: *ParseState, share: ShareMarker) -> *Node {
    let lh = peek(parse_state)
    var node: *Node = null
    if lh.tpe == lexer::TokenType::K_VAR {
        node = parse_vardecl(parse_state, share, VarDecl::VAR)
    } else if lh.tpe == lexer::TokenType::K_LET {
        node = parse_vardecl(parse_state, share, VarDecl::LET)
    } else if lh.tpe == lexer::TokenType::K_CONST {
        node = parse_vardecl(parse_state, share, VarDecl::CONST)
    } else if lh.tpe == lexer::TokenType::K_TYPE {
        node = parse_typedecl(parse_state, share)
    } else if lh.tpe == lexer::TokenType::K_DEF {
        node = parse_def(parse_state, share)
    }
    return node
}

def expect_defer_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_DEFER, "Expected defer")
    skip_newline(parse_state)
    token = peek(parse_state)
    let body = vector::make()
    if token.tpe == lexer::TokenType::O_BRACE {
        // Multiline defer
        pop(parse_state)
        parse_block(parse_state, body)
        expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")
    } else {
        // Single line defer
        let expr = expect_expression(parse_state)
        vector::push(body, expr)
    }
    let node = make_node(NodeKind::DEFER, line, column, parse_state)
    node.value.body = body
    node.body = body
    return node
}

def expect_assert_stmt(parse_state: *ParseState) -> *Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_ASSERT, "Expected assert")

    var cond: *Node = null
    token = peek(parse_state)
    if token.tpe != lexer::TokenType::NEW_LINE and
        token.tpe != lexer::TokenType::EOF and
        token.tpe != lexer::TokenType::C_BRACE {

        cond = parse_expression_no_assign(parse_state)
    }
   
    var msg: *Node = null
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::COMMA {
        pop(parse_state)
        skip_newline(parse_state)
        msg = expect_expression_no_assign(parse_state)
    }
    let node = make_node(NodeKind::ASSERT, line, column, parse_state)
    node.value.assert_ = {
        cond = cond,
        message = msg
    } !NodeAssert
    return node
}

def parse_statement(parse_state: *ParseState) -> *Node {
    let lh = peek(parse_state)
    var node: *Node = null
    if lh.tpe == lexer::TokenType::K_IMPORT {
        let share = ShareMarker::IMPORT
        let tok = pop(parse_state)
        node = parse_statement2(parse_state, share)
        if not node {
            unget_token(parse_state, tok)
            node = expect_import_stmt(parse_state)
        }
    } else if lh.tpe == lexer::TokenType::K_EXPORT {
        var share = ShareMarker::EXPORT
        pop(parse_state)
        let lh = peek(parse_state)
        if lh.tpe == lexer::TokenType::K_IMPORT {
            share = ShareMarker::BOTH
            pop(parse_state)
        }
        node = parse_statement2(parse_state, share)
        if not node {
            errors::errort(peek(parse_state), parse_state, "Expected def, type, var, let, const")
            return null
        }
    } else if lh.tpe == lexer::TokenType::K_IF {
        node = expect_if_stmt(parse_state, false)
    } else if lh.tpe == lexer::TokenType::PRAGMA and lh.value.str == "#if" {
        node = expect_if_stmt(parse_state, true)
    } else if lh.tpe == lexer::TokenType::K_SWITCH {
        node = expect_switch_stmt(parse_state)  
    } else if lh.tpe == lexer::TokenType::K_LOOP {
        node = expect_loop_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_FOR {
        node = expect_for_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_WHILE {
        node = expect_while_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_RETURN {
        node = expect_return_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_DEFER {
        node = expect_defer_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_ASSERT {
        node = expect_assert_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_BREAK {
        pop(parse_state)
        node = make_node(NodeKind::BREAK, lh.line, lh.column, parse_state)
    } else if lh.tpe == lexer::TokenType::K_CONTINUE {
        pop(parse_state)
        node = make_node(NodeKind::CONTINUE, lh.line, lh.column, parse_state)
    } else if lh.tpe == lexer::TokenType::PRAGMA and lh.value.str == "#error" {
        pop(parse_state)
        node = make_un_op(parse_state, lh, NodeKind::ERROR, expect_expression(parse_state))
    } else {
        node = parse_statement2(parse_state, ShareMarker::NONE)
        if not node {
            node = parse_expression(parse_state)
        }
    }
    parse_t_term(parse_state)
    return node
}

def parse_block_stmt(parse_state: *ParseState, vec: *vector::Vector) {
    let node = parse_statement(parse_state)
    (@parse_state).has_error = false
    if not node {
        // We encountered an error, skip to the next newline
        var lh = peek(parse_state)
        while lh.tpe != lexer::TokenType::NEW_LINE and 
            lh.tpe != lexer::TokenType::EOF and
            lh.tpe != lexer::TokenType::C_BRACE {

            lh = pop(parse_state)
        }
    } else {
        vector::push(vec, node)
    }
}

def parse_block(parse_state: *ParseState, vec: *vector::Vector) {
    skip_newline(parse_state)
    var token = peek(parse_state)
    while token.tpe != lexer::TokenType::EOF and
        token.tpe != lexer::TokenType::C_BRACE {
        parse_block_stmt(parse_state, vec)
        skip_newline(parse_state)
        token = peek(parse_state)
    }
}

export var time_spent: int64 = 0

export def parse(list: *lexer::TokenList, lines: [string], filename: string, module: string) -> *Node {
    debug::trace("Parsing ", module)
    let start = util::millis()

    var parse_state = {
        filename = filename,
        module = module,
        lines = lines,
        tokens = *list
    } !ParseState
    
    var vec = vector::make()
    parse_block(*parse_state, vec)
    var token = peek(*parse_state)
    if token.tpe != lexer::TokenType::EOF {
        errors::errort(token, *parse_state, "Unexpected closing '}'")
    }

    let program_node = make_node(NodeKind::PROGRAM, 0, 0, *parse_state)
    program_node.value.body = vec
    program_node.body = vec

    let end = util::millis()
    time_spent += end - start
    return program_node
}